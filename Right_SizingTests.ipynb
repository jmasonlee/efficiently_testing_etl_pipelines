{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmasonlee/efficiently_testing_etl_pipelines/blob/main/Right_SizingTests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Efficiencies of Right Sizing Tests\n"
      ],
      "metadata": {
        "id": "Bhc_PE_4BrpG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This exercise is meant to give you a practical example on how the number of inputs to a test affect the number of tests you need to write and maintain in order to fully cover your system."
      ],
      "metadata": {
        "id": "qljkG08NDynH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Notebook"
      ],
      "metadata": {
        "id": "aqYjZpizVD3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.system('rm -rf efficiently_testing_etl_pipelines \\\n",
        "&& git clone https://github.com/jmasonlee/efficiently_testing_etl_pipelines.git \\\n",
        "&& cp /content/efficiently_testing_etl_pipelines/efficiencies_of_right_sizing_tests/src/diamond_pricing.py . \\\n",
        "&& cp /content/efficiently_testing_etl_pipelines/efficiencies_of_right_sizing_tests/tests/test_helpers/verification_helpers.py . \\\n",
        "&& rm -rf efficiently_testing_etl_pipelines')\n"
      ],
      "metadata": {
        "id": "i4KRAp6vTEJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Dependencies\n",
        "\n",
        "For the exercise, we will need some special dependencies to allow us to run tests with lots of combinations"
      ],
      "metadata": {
        "id": "_h199h_XEAwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipytest\n",
        "!pip install pyspark\n",
        "!pip install approvaltests"
      ],
      "metadata": {
        "id": "7v0kaWulDXi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise"
      ],
      "metadata": {
        "id": "TATb7BjoCXP6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_BcRiFvBeLs"
      },
      "outputs": [],
      "source": [
        "from diamond_pricing import replace_null_prices_with_floating_averages\n",
        "from verification_helpers import verify_will_replace_null_values_with_floating_averages\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "from _pytest.fixtures import FixtureRequest\n",
        "from pyspark import SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "@pytest.fixture(scope=\"session\")\n",
        "def spark(request: FixtureRequest):\n",
        "    conf = (SparkConf()\n",
        "        .setMaster(\"local\")\n",
        "        .setAppName(\"sample_pyspark_testing_starter\"))\n",
        "\n",
        "    spark = SparkSession \\\n",
        "        .builder \\\n",
        "        .config(conf=conf) \\\n",
        "        .getOrCreate()\n",
        "\n",
        "    request.addfinalizer(lambda: spark.stop())\n",
        "    return spark"
      ],
      "metadata": {
        "id": "V6XwgiHHJrYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ipytest\n",
        "ipytest.autoconfig()"
      ],
      "metadata": {
        "id": "t7iwGQ4Le-Oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "\n",
        "def test_will_replace_null_prices_with_floating_averages(spark: SparkSession) -> None:\n",
        "    price = [327, None]\n",
        "\n",
        "    verify_will_replace_null_values_with_floating_averages(spark, price)\n",
        "    assert False"
      ],
      "metadata": {
        "id": "lfANxIAgIFEz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}