{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmO0At/ArV34jkTtdeIHlR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmasonlee/efficiently_testing_etl_pipelines/blob/main/fixing_a_big_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 0.A: Setup Notebook"
      ],
      "metadata": {
        "id": "aqYjZpizVD3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf efficiently_testing_etl_pipelines\n",
        "!git clone https://github.com/jmasonlee/efficiently_testing_etl_pipelines.git\n",
        "!cp -r /content/efficiently_testing_etl_pipelines/src/ .\n",
        "!cp -r /content/efficiently_testing_etl_pipelines/tests/ .\n",
        "!rm -rf efficiently_testing_etl_pipelines\n",
        "!rm -rf tests/diamond_pricing_test*\n",
        "!rm -rf tests/test_helpers/*verification_helpers.py\n",
        "!rm -rf tests/conftest.py\n",
        "!rm -rf sample_data\n"
      ],
      "metadata": {
        "id": "i4KRAp6vTEJm",
        "outputId": "cd7aecf4-87b3-4ff6-811b-99961c6e94d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'efficiently_testing_etl_pipelines'...\n",
            "remote: Enumerating objects: 687, done.\u001b[K\n",
            "remote: Counting objects: 100% (328/328), done.\u001b[K\n",
            "remote: Compressing objects: 100% (159/159), done.\u001b[K\n",
            "remote: Total 687 (delta 210), reused 259 (delta 162), pack-reused 359\u001b[K\n",
            "Receiving objects: 100% (687/687), 300.78 KiB | 1.60 MiB/s, done.\n",
            "Resolving deltas: 100% (416/416), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 0.B: Setup Tests"
      ],
      "metadata": {
        "id": "5cRRMTtEBYy0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Dependencies\n",
        "\n",
        "For the exercise, we will need some special dependencies to allow us to run lots of tests in a notebook."
      ],
      "metadata": {
        "id": "_h199h_XEAwT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`ipytest` lets us run our tests in a notebook.\n",
        "\n"
      ],
      "metadata": {
        "id": "DVAcSonZmslt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipytest"
      ],
      "metadata": {
        "id": "7v0kaWulDXi-",
        "outputId": "1285718e-e887-4d11-809a-53c6c273de06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipytest in /usr/local/lib/python3.10/dist-packages (0.13.3)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipytest) (7.34.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ipytest) (23.1)\n",
            "Requirement already satisfied: pytest>=5.4 in /usr/local/lib/python3.10/dist-packages (from ipytest) (7.2.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=5.4->ipytest) (23.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=5.4->ipytest) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest>=5.4->ipytest) (1.2.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest>=5.4->ipytest) (1.1.2)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=5.4->ipytest) (2.0.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (0.18.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipytest) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipytest) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipytest) (0.2.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ipytest is what allows us to run our tests in a notebook. This next cell is not needed if you are writing tests in a separate pytest file."
      ],
      "metadata": {
        "id": "3_ILjU8goCNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipytest\n",
        "ipytest.autoconfig()"
      ],
      "metadata": {
        "id": "t7iwGQ4Le-Oe"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are installing `pyspark` because it doesn't come with the base colab environment"
      ],
      "metadata": {
        "id": "HzwfHFGmm2Ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "QNnk84AsmmFQ",
        "outputId": "0793759c-4e6a-4f14-fb7a-1336e1034abe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chispa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_EYg-cC1cD5",
        "outputId": "e13888c7-56bf-406d-d38d-7b988620ccde"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chispa in /usr/local/lib/python3.10/dist-packages (0.9.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a local SparkSession\n",
        "\n",
        "Normally spark runs on a bunch of executors in the cloud. Since we want our tests to be able to run on a single dev machine, we make a fixture that gives us a local spark context."
      ],
      "metadata": {
        "id": "V_OJcnSiBgUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "from _pytest.fixtures import FixtureRequest\n",
        "from pyspark import SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "@pytest.fixture(scope=\"session\")\n",
        "def spark(request: FixtureRequest):\n",
        "    conf = (SparkConf()\n",
        "        .setMaster(\"local\")\n",
        "        .setAppName(\"sample_pyspark_testing_starter\"))\n",
        "\n",
        "    spark = SparkSession \\\n",
        "        .builder \\\n",
        "        .config(conf=conf) \\\n",
        "        .getOrCreate()\n",
        "\n",
        "    request.addfinalizer(lambda: spark.stop())\n",
        "    return spark"
      ],
      "metadata": {
        "id": "xXPLpebJ6iI2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Helpers\n",
        "\n",
        "This is a helper function that retrieves our test output from the expected.json file"
      ],
      "metadata": {
        "id": "actN5s7DCF9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import List, Dict\n",
        "\n",
        "from pyspark.pandas import DataFrame\n",
        "\n",
        "\n",
        "def create_df_from_json(json_file, spark):\n",
        "    return spark.read.option(\"multiline\", \"true\").json(json_file)\n",
        "\n",
        "\n",
        "def data_frame_to_json(df: DataFrame) -> List:\n",
        "    output = [json.loads(item) for item in df.toJSON().collect()]\n",
        "    output.sort(key=lambda item: item[\"id\"])\n",
        "    print(output)\n",
        "    return output\n",
        "\n",
        "def expected_json(name: str) -> Dict:\n",
        "    with open(f\"tests/fixtures/{name}\") as f:\n",
        "        return json.loads(f.read())"
      ],
      "metadata": {
        "id": "VO2-3px25xEl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "def build_indep_vars(df, independent_vars, categorical_vars=None, keep_intermediate=False, summarizer=True):\n",
        "    check_input(categorical_vars, df, independent_vars)\n",
        "\n",
        "    from pyspark.ml import Pipeline\n",
        "    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "    idx = 'index'\n",
        "    vec = 'vector'\n",
        "    if categorical_vars:\n",
        "        string_indexer = [StringIndexer(inputCol=x,\n",
        "                                        outputCol=f\"{x}_{idx}\")\n",
        "                          for x in categorical_vars]\n",
        "\n",
        "        encoder        = [OneHotEncoder(dropLast=True,\n",
        "                                        inputCol =f'{x}_{idx}',\n",
        "                                        outputCol=f'{x}_{vec}')\n",
        "                          for x in categorical_vars]\n",
        "\n",
        "        independent_vars = ['{}_vector'.format(x) if x in categorical_vars else x for x in independent_vars]\n",
        "    else:\n",
        "        string_indexer, encoder = [], []\n",
        "\n",
        "    assembler = VectorAssembler(inputCols=independent_vars,\n",
        "                                outputCol='indep_vars')\n",
        "    pipeline  = Pipeline(stages=string_indexer+encoder+[assembler])\n",
        "    model = pipeline.fit(df)\n",
        "    df = model.transform(df)\n",
        "\n",
        "    if not keep_intermediate:\n",
        "        fcols = [c for c in df.columns if f'_{idx}' not in c[-3:] and f'_{vec}' not in c[-7:]]\n",
        "        df = df[fcols]\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def check_input(categorical_vars, df, independent_vars):\n",
        "    assert (type(\n",
        "        df) is pyspark.sql.dataframe.DataFrame), 'pypark_glm: A pySpark dataframe is required as the first argument.'\n",
        "    assert (type(\n",
        "        independent_vars) is list), 'pyspark_glm: List of independent variable column names must be the third argument.'\n",
        "    for iv in independent_vars:\n",
        "        assert (type(iv) is str), 'pyspark_glm: Independent variables must be column name strings.'\n",
        "        assert (iv in df.columns), 'pyspark_glm: Independent variable name is not a dataframe column.'\n",
        "    if categorical_vars:\n",
        "        for cv in categorical_vars:\n",
        "            assert (type(cv) is str), 'pyspark_glm: Categorical variables must be column name strings.'\n",
        "            assert (cv in df.columns), 'pyspark_glm: Categorical variable name is not a dataframe column.'\n",
        "            assert (cv in independent_vars), 'pyspark_glm: Categorical variables must be independent variables.'\n"
      ],
      "metadata": {
        "id": "eBvHph1aCJiN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import DataFrame, Window, Column\n",
        "from pyspark.sql.functions import log, when, mean, col\n",
        "\n",
        "def replace_null(orig: Column, average: Column):\n",
        "    return when(orig.isNull(), average).otherwise(orig)\n",
        "\n",
        "def transform(df: DataFrame) -> DataFrame:\n",
        "\n",
        "    df = df.withColumn('lprice', log('price'))\n",
        "    window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    df = df[['id', 'carat', 'clarity', 'color', 'price']]\n",
        "    df = build_indep_vars(df, ['carat', 'clarity', 'color'],\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "22lMaALmCTJm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 1: Investigate The Test"
      ],
      "metadata": {
        "id": "MjwHttFB5TB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def test_will_do_the_right_thing(spark: SparkSession):\n",
        "    #ARRANGE - SET UP TEST INPUTS\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    #ACT - RUN THE CODE WE ARE TESTING\n",
        "    actual_df = transform(diamonds_df)\n",
        "\n",
        "    #ASSERT - CHECK THE OUTPUTS ARE CORRECT\n",
        "    assert data_frame_to_json(actual_df) == expected_json(\"expected.json\")"
      ],
      "metadata": {
        "id": "lH1x9ZOi58X7",
        "outputId": "fd21feec-7770-457c-9b66-9f5f6d1e6de9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Setup For the Saff Squeeze"
      ],
      "metadata": {
        "id": "95eTfqjbZfGV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's get ready to improve the test.\n",
        "\n",
        "**our bug**: Diamonds of the same cut and clarity are influencing the calculated price of diamonds with a different color. Only diamonds with the same cut, clarity _**and color**_ should be influencing the calculated price for diamonds with a null price."
      ],
      "metadata": {
        "id": "oDLkPTvpnKGS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 1A - Test for the desired behaviour\n",
        "- [ ] There is a second json file (`expected_correct.json`) where the expected price for the unpriced diamond has been updated to the correct value. Use that file name as the argument passed to `expected_json`\n",
        "- [ ] Run the test. It should fail."
      ],
      "metadata": {
        "id": "ToSNXfVOxzz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def test_will_do_the_right_thing(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "\n",
        "    assert data_frame_to_json(actual_df) == expected_json(\"expected.json\")  # <- Rename the \"expected.json\" file to \"expected_correct.json\""
      ],
      "metadata": {
        "outputId": "b1c682e1-dadb-457d-9dd4-ca8765e6ebb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VKLXAMic975"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 1B - Duplicate the test\n",
        "\n",
        "- [ ] Duplicate the test. Now you should have two copies of the same test.\n",
        "  * One copy will stay the same, so we can make sure that nothing is broken.\n",
        "  * The second copy is what we will change in the next steps.\n",
        "- [ ] Name the second test\n",
        "```\n",
        "test_null_price_is_replaced_based_on_cut_clarity_and_color\n",
        "```\n",
        "- [ ] Run the tests. They should both fail."
      ],
      "metadata": {
        "id": "t32-FfGUyLA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "# Duplicate the test below and rename the duplicate to:\n",
        "# test_null_price_is_replaced_based_on_cut_clarity_and_color\n",
        "\n",
        "########################## START OF THE ORIGINAL TEST ##########################\n",
        "def test_will_do_the_right_thing(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "\n",
        "    assert data_frame_to_json(actual_df) == expected_json(\"expected_correct.json\")\n",
        "########################### END OF THE ORIGINAL TEST ###########################"
      ],
      "metadata": {
        "outputId": "b1c682e1-dadb-457d-9dd4-ca8765e6ebb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7tUmVtwzSBN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Make The Assert Specific"
      ],
      "metadata": {
        "id": "cbCuKHDpso8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Right now, our test compares everything in the output dataframe to everything in a large json file. That's a lot of rows to compare and the assert is wrong anyways!\n",
        "\n",
        "Let's make this test assert on the thing we actually care about - the output price of the diamond!"
      ],
      "metadata": {
        "id": "X-xfpXMwstwN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instructions - Chispa\n",
        "\n",
        "#### With Chispa\n",
        "- [ ] Add these imports to the top of the cell, below the `%%ipytest -qq` line:  \n",
        "`from chispa import assert_column_equality`  \n",
        "`from pySpark.sql.functions import lit`\n",
        "- [ ] Filter the dataframe for the unique id of the diamond we care about:  \n",
        "`actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')`\n",
        "- [ ] Create a new column in our dataframe that contains our expected price:  \n",
        "`actual_df=actual_df.withColumn('expected_price', lit(3333.0))`\n",
        "- [ ] Assert the value in the price column matches the value we want:  \n",
        "`assert_column_equality(actual_df, 'price', 'expected_price')`\n"
      ],
      "metadata": {
        "id": "jz3ygb6GxcYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise - Chispa"
      ],
      "metadata": {
        "id": "vYiG_Qgtv1bs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n"
      ],
      "metadata": {
        "outputId": "0819f609-1177-4f16-b47b-fdeaee466401",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiwYRKD0yXIW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions - Pandas\n",
        "- [ ] import pandas:  \n",
        "`import pandas as pd`\n",
        "- [ ] Filter the dataframe for the unique id of the diamond we care about:  \n",
        "  `actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')`\n",
        "- [ ] Create your expected dataframe using Pandas:  \n",
        " `expected = pd.DataFrame(({'id': [\"DI-26-null-price\"], 'price':[3333.0] }))`\n",
        "- [ ] Select the column you care about:  \n",
        "  `actual_df=actual_df.select(['id', 'price'])\n",
        "- [ ] Assert for dataframe equality using pandas:  \n",
        "  `pd.testing.assert_frame_equal(actual_df, expected)`"
      ],
      "metadata": {
        "id": "wW0OfrWo8Qn4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise - Pandas"
      ],
      "metadata": {
        "id": "TM4QCxCZwEbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n"
      ],
      "metadata": {
        "outputId": "2ae0b4f4-a212-4056-8dc7-30973c18cdaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a_ORvhl9CAd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions - JSON properties\n",
        "\n",
        "- [ ] Filter the dataframe for the unique id of the diamond we care about:  \n",
        "  `actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')`\n",
        "- [ ] Convert your dataframe to JSON:  \n",
        "`actual_df_json = data_frame_to_json(actual_df)`\n",
        "- [ ] Assert the price property of the first object matches your expected price:  \n",
        "`assert actual_df_json[0]['price'] == 3333.0`"
      ],
      "metadata": {
        "id": "lD-3MVVv9D9d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise - JSON properties"
      ],
      "metadata": {
        "id": "F0GvaGLEwMZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "\n"
      ],
      "metadata": {
        "outputId": "069366c2-c919-49ed-ce0b-4bb1bc22cb8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55eVJ0Ug9Pif"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Reduce Duplicate Coverage and Fix the Bug\n",
        "\n",
        "Right now, our test is running the entire transform function. Because there are multiple tests in `diamonds.json`, each test is running the same large block of code over and over again."
      ],
      "metadata": {
        "id": "sw4mvQYw5pkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 3.A: Prep"
      ],
      "metadata": {
        "id": "8kumyMxuNFY_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions\n",
        "Let's get ready to reduce the duplicate coverage.\n",
        "\n",
        "#### 1. Put the transform function where you can work with it\n",
        "- [ ] Run the test. It should be failing.\n",
        "- [ ] Replace the call to the transform function with the body of that function.\n",
        "- [ ] Change the last line of the function body to assign to `actual_df` instead of `df`\n",
        "```\n",
        "df = build_indep_vars(df, ['carat', 'clarity', 'color'],\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "```\n",
        "becomes\n",
        "```\n",
        "actual_df = build_indep_vars(df, ['carat', 'clarity', 'color'],\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "```\n",
        "- [ ] Change the first line of the function body to read from `diamonds_df` instead of `df`\n",
        "```\n",
        " df = df.withColumn('lprice', log('price'))\n",
        "```\n",
        "becomes\n",
        "```\n",
        " df = diamonds_df.withColumn('lprice', log('price'))\n",
        "```\n",
        "- [ ] Run the test. It should still be failing for the same reasons.\n",
        "\n",
        "#### 2. Test FOR the bug\n",
        "- [ ] Change your assert code so that it is testing _for_ the bug.\n",
        "```\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "```\n",
        "becomes\n",
        "```\n",
        "  actual_df=actual_df.withColumn('expected_price', lit(2460.0))\n",
        "```\n",
        "- [ ] Run the test. It should pass.\n",
        "\n",
        "#### 3. Make the assert easier to work with\n",
        "- [ ] Extract your assert code into a one-line helper function:\n",
        "```\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(2460.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "```\n",
        "- [ ] Run the test. It should pass."
      ],
      "metadata": {
        "id": "-2pcPdIhf6ad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise"
      ],
      "metadata": {
        "id": "57xFbUQaoIaq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Code"
      ],
      "metadata": {
        "id": "0ze_hB2VCmC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The `transform` Function"
      ],
      "metadata": {
        "id": "YgzlhOgV-LJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import DataFrame, Window, Column\n",
        "from pyspark.sql.functions import log, when, mean, col\n",
        "\n",
        "def transform(df: DataFrame) -> DataFrame:\n",
        "# The body of the transform function STARTS HERE\n",
        "    df = df.withColumn('lprice', log('price'))  #<-- In the test, this line should be: df = diamonds_df.withColumn('lprice', log('price'))\n",
        "    window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    df = df[['id', 'carat', 'clarity', 'color', 'price']]\n",
        "    df = build_indep_vars(df, ['carat', 'clarity', 'color'], #<-- In the test, this line should be: actual_df = build_indep_vars(df, ['carat', 'clarity', 'color']\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "# The body of the transform function ENDS HERE\n",
        "    return df"
      ],
      "metadata": {
        "id": "EqUboG2Y-HZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Test"
      ],
      "metadata": {
        "id": "DR41JwrwDPhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def test_prep_for_linear_regression(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df) #<-- We will be replacing this line with the body of the transform function\n",
        "\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')"
      ],
      "metadata": {
        "outputId": "61c77c49-d567-4ce4-9852-d8257ec15142",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ci_qnCgB57k9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mF\u001b[0m\u001b[31m                                                                                            [100%]\u001b[0m\n",
            "============================================= FAILURES =============================================\n",
            "\u001b[31m\u001b[1m_________________________________ test_prep_for_linear_regression __________________________________\u001b[0m\n",
            "\n",
            "spark = <pyspark.sql.session.SparkSession object at 0x78015abc36d0>\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_prep_for_linear_regression\u001b[39;49;00m(spark: SparkSession):\u001b[90m\u001b[39;49;00m\n",
            "        diamonds_df = create_df_from_json(\u001b[33m\"\u001b[39;49;00m\u001b[33mtests/fixtures/diamonds.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, spark)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        actual_df = transform(diamonds_df) \u001b[90m#<-- We will be replacing this line with the body of the transform function\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        actual_df=actual_df.filter(actual_df.id == \u001b[33m'\u001b[39;49;00m\u001b[33mDI-26-null-price\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        actual_df=actual_df.withColumn(\u001b[33m'\u001b[39;49;00m\u001b[33mexpected_price\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, lit(\u001b[94m3333.0\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            ">       assert_column_equality(actual_df, \u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mexpected_price\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31m<ipython-input-68-c6ea0e31b630>\u001b[0m:10: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "df = DataFrame[id: string, carat: double, clarity: string, color: string, price: double, clarity_index: double, color_index: double, indep_vars: vector, expected_price: double]\n",
            "col_name1 = 'price', col_name2 = 'expected_price'\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92massert_column_equality\u001b[39;49;00m(df, col_name1, col_name2):\u001b[90m\u001b[39;49;00m\n",
            "        elements = df.select(col_name1, col_name2).collect()\u001b[90m\u001b[39;49;00m\n",
            "        colName1Elements = \u001b[96mlist\u001b[39;49;00m(\u001b[96mmap\u001b[39;49;00m(\u001b[94mlambda\u001b[39;49;00m x: x[\u001b[94m0\u001b[39;49;00m], elements))\u001b[90m\u001b[39;49;00m\n",
            "        colName2Elements = \u001b[96mlist\u001b[39;49;00m(\u001b[96mmap\u001b[39;49;00m(\u001b[94mlambda\u001b[39;49;00m x: x[\u001b[94m1\u001b[39;49;00m], elements))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m colName1Elements != colName2Elements:\u001b[90m\u001b[39;49;00m\n",
            "            zipped = \u001b[96mlist\u001b[39;49;00m(\u001b[96mzip\u001b[39;49;00m(colName1Elements, colName2Elements))\u001b[90m\u001b[39;49;00m\n",
            "            t = PrettyTable([col_name1, col_name2])\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m elements \u001b[95min\u001b[39;49;00m zipped:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m elements[\u001b[94m0\u001b[39;49;00m] == elements[\u001b[94m1\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
            "                    first = bcolors.LightBlue + \u001b[96mstr\u001b[39;49;00m(elements[\u001b[94m0\u001b[39;49;00m]) + bcolors.LightRed\u001b[90m\u001b[39;49;00m\n",
            "                    second = bcolors.LightBlue + \u001b[96mstr\u001b[39;49;00m(elements[\u001b[94m1\u001b[39;49;00m]) + bcolors.LightRed\u001b[90m\u001b[39;49;00m\n",
            "                    t.add_row([first, second])\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    t.add_row([\u001b[96mstr\u001b[39;49;00m(elements[\u001b[94m0\u001b[39;49;00m]), \u001b[96mstr\u001b[39;49;00m(elements[\u001b[94m1\u001b[39;49;00m])])\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mraise\u001b[39;49;00m ColumnsNotEqualError(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m + t.get_string())\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           chispa.column_comparer.ColumnsNotEqualError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           +--------+----------------+\u001b[0m\n",
            "\u001b[1m\u001b[31mE           | price  | expected_price |\u001b[0m\n",
            "\u001b[1m\u001b[31mE           +--------+----------------+\u001b[0m\n",
            "\u001b[1m\u001b[31mE           | 2777.0 |     3333.0     |\u001b[0m\n",
            "\u001b[1m\u001b[31mE           +--------+----------------+\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.10/dist-packages/chispa/column_comparer.py\u001b[0m:24: ColumnsNotEqualError\n",
            "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m t_792e1f981ba74dd7b5b3b3bb63f7a733.py::\u001b[1mtest_prep_for_linear_regression\u001b[0m - chispa.column_comparer.ColumnsNotEqualError: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The original test\n",
        "\n"
      ],
      "metadata": {
        "id": "ojU7wLaKdbBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def test_will_do_the_right_thing(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "    assert data_frame_to_json(actual_df) == expected_json(\"expected_correct.json\")"
      ],
      "metadata": {
        "id": "S5228csId2CS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f751618e-3375-4ae5-b65b-a78f58918fbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mF\u001b[0m\u001b[31m                                                                                            [100%]\u001b[0m\n",
            "============================================= FAILURES =============================================\n",
            "\u001b[31m\u001b[1m___________________________________ test_will_do_the_right_thing ___________________________________\u001b[0m\n",
            "\n",
            "spark = <pyspark.sql.session.SparkSession object at 0x78015ab7cf10>\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_will_do_the_right_thing\u001b[39;49;00m(spark: SparkSession):\u001b[90m\u001b[39;49;00m\n",
            "        diamonds_df = create_df_from_json(\u001b[33m\"\u001b[39;49;00m\u001b[33mtests/fixtures/diamonds.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, spark)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        actual_df = transform(diamonds_df)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m data_frame_to_json(actual_df) == expected_json(\u001b[33m\"\u001b[39;49;00m\u001b[33mexpected_correct.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: assert [{'carat': 0....G', ...}, ...] == [{'carat': 0....G', ...}, ...]\u001b[0m\n",
            "\u001b[1m\u001b[31mE         At index 1 diff: {'id': 'DI-26', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 3333.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}} != {'id': 'DI-26', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 2690.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}\u001b[0m\n",
            "\u001b[1m\u001b[31mE         Use -v to get more diff\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m<ipython-input-69-e9ec4e9326c8>\u001b[0m:7: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "[{'id': '1', 'carat': 0.23, 'clarity': 'SI2', 'color': 'E', 'price': 326.0, 'clarity_index': 3.0, 'color_index': 1.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 5], 'values': [0.23, 1.0]}}, {'id': 'DI-26', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 3333.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}, {'id': 'DI-26', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 3333.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}, {'id': 'DI-26-null-price', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 2777.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}, {'id': 'DI-27', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 2692.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}, {'id': 'DI-28', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'G', 'price': 1665.0, 'clarity_index': 0.0, 'color_index': 3.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1], 'values': [0.21, 1.0]}}, {'id': 'DI-30', 'carat': 0.32, 'clarity': 'I1', 'color': 'D', 'price': 345.0, 'clarity_index': 1.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 2, 4], 'values': [0.32, 1.0, 1.0]}}, {'id': 'minimum_inputs', 'carat': 0.23, 'clarity': 'SI1', 'color': 'F', 'clarity_index': 2.0, 'color_index': 2.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 3, 6], 'values': [0.23, 1.0, 1.0]}}]\n",
            "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m t_792e1f981ba74dd7b5b3b3bb63f7a733.py::\u001b[1mtest_will_do_the_right_thing\u001b[0m - AssertionError: assert [{'carat': 0....G', ...}, ...] == [{'carat': 0....G', ...}, ...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3.B Squeeze the bottom!\n"
      ],
      "metadata": {
        "id": "5oBE2ZEAF2E2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Instructions\n",
        "**our bug**: Diamonds of the same cut and clarity are influencing the calculated price of diamonds with a different color. Only diamonds with the same cut, clarity and color should be influencing the calculated price for diamonds with a null price.\n",
        "\n",
        "**Squeeze the bottom until you find the bug**\n",
        "- [ ] Move your assert up one line at a time.  \n",
        "- [ ] After each move, run your test.  \n",
        "- [ ] If it fails, figure out why it's failing.(You may need to rename columns in the assert)\n",
        "- [ ] If the test passes, the line wasn't important for the bug you wanted to catch. Delete it.\n",
        "- [ ] Continue until you find the source of the bug"
      ],
      "metadata": {
        "id": "PhriAy0jfsTj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise"
      ],
      "metadata": {
        "id": "SyOFZzKVokvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Code"
      ],
      "metadata": {
        "id": "u2EHWBjMetva"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The `transform` Function"
      ],
      "metadata": {
        "id": "9Yne491Uetvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import DataFrame, Window, Column\n",
        "from pyspark.sql.functions import log, when, mean, col\n",
        "\n",
        "def transform(df: DataFrame) -> DataFrame:\n",
        "\n",
        "    df = df.withColumn('lprice', log('price'))\n",
        "    window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    df = df[['id', 'carat', 'clarity', 'color', 'price']]\n",
        "    df = build_indep_vars(df, ['carat', 'clarity', 'color'],\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "-EhWDEgLetvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Test"
      ],
      "metadata": {
        "id": "441Jq5Ude3n7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession, DataFrame, Window, Column\n",
        "from pyspark.sql.functions import lit, log, when, mean, col\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(2460.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    df = diamonds_df.withColumn('lprice', log('price'))\n",
        "    window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    df = df[['id', 'carat', 'clarity', 'color', 'price']]\n",
        "    actual_df = build_indep_vars(df, ['carat', 'clarity', 'color'],\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "outputId": "7e53ee15-5b0f-440c-90fb-2bca0990f9fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFv4b_9xFw-t"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mF\u001b[0m\u001b[31m                                                                                            [100%]\u001b[0m\n",
            "============================================= FAILURES =============================================\n",
            "\u001b[31m\u001b[1m____________________ test_null_price_is_replaced_based_on_cut_clarity_and_color ____________________\u001b[0m\n",
            "\n",
            "spark = <pyspark.sql.session.SparkSession object at 0x78015ad21450>\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_null_price_is_replaced_based_on_cut_clarity_and_color\u001b[39;49;00m(spark: SparkSession):\u001b[90m\u001b[39;49;00m\n",
            "        diamonds_df = create_df_from_json(\u001b[33m\"\u001b[39;49;00m\u001b[33mtests/fixtures/diamonds.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, spark)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        df = diamonds_df.withColumn(\u001b[33m'\u001b[39;49;00m\u001b[33mlprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, log(\u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        window = Window.partitionBy(\u001b[33m'\u001b[39;49;00m\u001b[33mcut\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mclarity\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).orderBy(\u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).rowsBetween(-\u001b[94m3\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        moving_avg = mean(df[\u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]).over(window)\u001b[90m\u001b[39;49;00m\n",
            "        df = df.withColumn(\u001b[33m'\u001b[39;49;00m\u001b[33mmoving_avg\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, moving_avg)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        df = df.withColumn(\u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, when(df.price.isNull(), df.moving_avg).otherwise(df.price))\u001b[90m\u001b[39;49;00m\n",
            "        df = df[[\u001b[33m'\u001b[39;49;00m\u001b[33mid\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcarat\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mclarity\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcolor\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]]\u001b[90m\u001b[39;49;00m\n",
            "        actual_df = build_indep_vars(df, [\u001b[33m'\u001b[39;49;00m\u001b[33mcarat\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mclarity\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcolor\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
            "                                          categorical_vars=[\u001b[33m'\u001b[39;49;00m\u001b[33mclarity\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcolor\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
            "                                          keep_intermediate=\u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "                                          summarizer=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       assert_diamond_has_expected_price(actual_df)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31m<ipython-input-71-b5d8f519d358>\u001b[0m:25: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31m<ipython-input-71-b5d8f519d358>\u001b[0m:8: in assert_diamond_has_expected_price\n",
            "    assert_column_equality(actual_df, \u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mexpected_price\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "df = DataFrame[id: string, carat: double, clarity: string, color: string, price: double, clarity_index: double, color_index: double, indep_vars: vector, expected_price: double]\n",
            "col_name1 = 'price', col_name2 = 'expected_price'\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92massert_column_equality\u001b[39;49;00m(df, col_name1, col_name2):\u001b[90m\u001b[39;49;00m\n",
            "        elements = df.select(col_name1, col_name2).collect()\u001b[90m\u001b[39;49;00m\n",
            "        colName1Elements = \u001b[96mlist\u001b[39;49;00m(\u001b[96mmap\u001b[39;49;00m(\u001b[94mlambda\u001b[39;49;00m x: x[\u001b[94m0\u001b[39;49;00m], elements))\u001b[90m\u001b[39;49;00m\n",
            "        colName2Elements = \u001b[96mlist\u001b[39;49;00m(\u001b[96mmap\u001b[39;49;00m(\u001b[94mlambda\u001b[39;49;00m x: x[\u001b[94m1\u001b[39;49;00m], elements))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m colName1Elements != colName2Elements:\u001b[90m\u001b[39;49;00m\n",
            "            zipped = \u001b[96mlist\u001b[39;49;00m(\u001b[96mzip\u001b[39;49;00m(colName1Elements, colName2Elements))\u001b[90m\u001b[39;49;00m\n",
            "            t = PrettyTable([col_name1, col_name2])\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m elements \u001b[95min\u001b[39;49;00m zipped:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m elements[\u001b[94m0\u001b[39;49;00m] == elements[\u001b[94m1\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
            "                    first = bcolors.LightBlue + \u001b[96mstr\u001b[39;49;00m(elements[\u001b[94m0\u001b[39;49;00m]) + bcolors.LightRed\u001b[90m\u001b[39;49;00m\n",
            "                    second = bcolors.LightBlue + \u001b[96mstr\u001b[39;49;00m(elements[\u001b[94m1\u001b[39;49;00m]) + bcolors.LightRed\u001b[90m\u001b[39;49;00m\n",
            "                    t.add_row([first, second])\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    t.add_row([\u001b[96mstr\u001b[39;49;00m(elements[\u001b[94m0\u001b[39;49;00m]), \u001b[96mstr\u001b[39;49;00m(elements[\u001b[94m1\u001b[39;49;00m])])\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mraise\u001b[39;49;00m ColumnsNotEqualError(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m + t.get_string())\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           chispa.column_comparer.ColumnsNotEqualError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           +--------+----------------+\u001b[0m\n",
            "\u001b[1m\u001b[31mE           | price  | expected_price |\u001b[0m\n",
            "\u001b[1m\u001b[31mE           +--------+----------------+\u001b[0m\n",
            "\u001b[1m\u001b[31mE           | 2777.0 |     2460.0     |\u001b[0m\n",
            "\u001b[1m\u001b[31mE           +--------+----------------+\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.10/dist-packages/chispa/column_comparer.py\u001b[0m:24: ColumnsNotEqualError\n",
            "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m t_792e1f981ba74dd7b5b3b3bb63f7a733.py::\u001b[1mtest_null_price_is_replaced_based_on_cut_clarity_and_color\u001b[0m - chispa.column_comparer.ColumnsNotEqualError: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Original Test"
      ],
      "metadata": {
        "id": "MMVXW7E7gNBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def test_will_do_the_right_thing(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "    assert data_frame_to_json(actual_df) == expected_json(\"expected_correct.json\")"
      ],
      "metadata": {
        "id": "S50HLHD9gALp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "336a3a1d-53c3-433a-e3f0-292f8894445d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mF\u001b[0m\u001b[31m                                                                                            [100%]\u001b[0m\n",
            "============================================= FAILURES =============================================\n",
            "\u001b[31m\u001b[1m___________________________________ test_will_do_the_right_thing ___________________________________\u001b[0m\n",
            "\n",
            "spark = <pyspark.sql.session.SparkSession object at 0x78015ae0d390>\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_will_do_the_right_thing\u001b[39;49;00m(spark: SparkSession):\u001b[90m\u001b[39;49;00m\n",
            "        diamonds_df = create_df_from_json(\u001b[33m\"\u001b[39;49;00m\u001b[33mtests/fixtures/diamonds.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, spark)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        actual_df = transform(diamonds_df)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m data_frame_to_json(actual_df) == expected_json(\u001b[33m\"\u001b[39;49;00m\u001b[33mexpected_correct.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: assert [{'carat': 0....G', ...}, ...] == [{'carat': 0....G', ...}, ...]\u001b[0m\n",
            "\u001b[1m\u001b[31mE         At index 1 diff: {'id': 'DI-26', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 3333.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}} != {'id': 'DI-26', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 2690.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}\u001b[0m\n",
            "\u001b[1m\u001b[31mE         Use -v to get more diff\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m<ipython-input-72-e9ec4e9326c8>\u001b[0m:7: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "[{'id': '1', 'carat': 0.23, 'clarity': 'SI2', 'color': 'E', 'price': 326.0, 'clarity_index': 3.0, 'color_index': 1.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 5], 'values': [0.23, 1.0]}}, {'id': 'DI-26', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 3333.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}, {'id': 'DI-26', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 3333.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}, {'id': 'DI-26-null-price', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 2777.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}, {'id': 'DI-27', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 2692.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}, {'id': 'DI-28', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'G', 'price': 1665.0, 'clarity_index': 0.0, 'color_index': 3.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1], 'values': [0.21, 1.0]}}, {'id': 'DI-30', 'carat': 0.32, 'clarity': 'I1', 'color': 'D', 'price': 345.0, 'clarity_index': 1.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 2, 4], 'values': [0.32, 1.0, 1.0]}}, {'id': 'minimum_inputs', 'carat': 0.23, 'clarity': 'SI1', 'color': 'F', 'clarity_index': 2.0, 'color_index': 2.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 3, 6], 'values': [0.23, 1.0, 1.0]}}]\n",
            "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m t_792e1f981ba74dd7b5b3b3bb63f7a733.py::\u001b[1mtest_will_do_the_right_thing\u001b[0m - AssertionError: assert [{'carat': 0....G', ...}, ...] == [{'carat': 0....G', ...}, ...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3.C Let's fix the bug!\n"
      ],
      "metadata": {
        "id": "H3kdrtuBEbcC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions\n",
        "\n",
        "**Our Bug**: Diamonds of the same cut and clarity are influencing the calculated price of diamonds with a different color. Only diamonds with the same cut, clarity and color should be influencing the calculated price for diamonds with a null price.\n",
        "\n",
        "**Our Desired Behaviour**:  \n",
        "The input diamond with these properties:\n",
        "- id: `\"DI-26-null-price\"`\n",
        "- cut: `\"Good\"`\n",
        "- color: `\"D\"`\n",
        "- clarity: `\"VVS1\"`\n",
        "- price: `null`\n",
        "\n",
        "Should be output with a price of `3333.0` - the average price of the other diamonds with `cut=\"Good\"`, `clarity=\"VVS1\"` and `color=\"D\"`\n",
        "\n",
        "**Fix the bug**\n",
        "#### Test for the behaviour you actually want\n",
        "- [ ] Update your test so that it checks for the good behaviour.  \n",
        "Replace the expected price on this line with `3333.0`:  \n",
        "```\n",
        "actual_df=actual_df.withColumn('expected_price', lit(2460.0))\n",
        "```\n",
        "- [ ] Run your test. It should fail with a `columnsNotEqualError`:  \n",
        "```\n",
        "E           chispa.column_comparer.ColumnsNotEqualError:\n",
        "E           +------------+----------------+\n",
        "E           | moving_avg | expected_price |\n",
        "E           +------------+----------------+\n",
        "E           |   2460.0   |     3333.0     |\n",
        "E           +------------+----------------+\n",
        "```\n",
        "\n",
        "#### Fix the bug\n",
        "- [ ] Fix the code _in your test_ so that the bug is gone. We need to add `'color'` to `'cut'` and `'clarity'` on this line:\n",
        "```\n",
        "window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "```\n",
        "- [ ] Run your test. It should pass.\n",
        "\n",
        "#### Encapsulate the code necessary for the behaviour\n",
        "- [ ] The behaviour belongs to a group of lines working together. Extract them into a method.  \n",
        "These lines can't be separated without changing the behaviour we are testing:  \n",
        "```\n",
        "    window = Window.partitionBy('cut', 'clarity', 'color').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "```  \n",
        "Use them to make a method:\n",
        "```\n",
        "def calculate_avg_price_for_similar_diamonds(df: DataFrame) -> DataFrame:\n",
        "      window = Window.partitionBy('cut', 'clarity', 'color').orderBy('price').rowsBetween(-3, 3)\n",
        "      moving_avg = mean(df['price']).over(window)\n",
        "      df = df.withColumn('moving_avg', moving_avg)\n",
        "      df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "      return df\n",
        "```\n",
        "\n",
        "Replace those lines with a call to the new method in your test:  \n",
        "```\n",
        "actual_df = calculate_avg_price_for_similar_diamonds(actual_df)\n",
        "```\n",
        "- [ ] Run your test. It should pass.\n",
        "\n",
        "#### Move the encapsulated behaviour to the actual code\n",
        "- [ ] Move the new method out of your test and into the transform code.\n",
        "- [ ] Replace the lines in your transform code with the new method call.\n",
        "- [ ] We've changed the original code, so we need to check that everything still works the way we expect. Run the copy of your original large test. It should also pass.\n",
        "- [ ] Run your test. It should pass.\n"
      ],
      "metadata": {
        "id": "mL_lKfL-fdgh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise"
      ],
      "metadata": {
        "id": "mNb7r0copJ3X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Code"
      ],
      "metadata": {
        "id": "69ahdJEigJD7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The `transform` Function"
      ],
      "metadata": {
        "id": "aS6CsJ4IgJEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import DataFrame, Window, Column\n",
        "from pyspark.sql.functions import log, when, mean, col\n",
        "\n",
        "\n",
        "def transform(df: DataFrame) -> DataFrame:\n",
        "\n",
        "    df = df.withColumn('lprice', log('price'))\n",
        "    #THIS IS WHERE THE BEHAVIOUR WE CARE ABOUT STARTS - REPLACE THIS BLOCK\n",
        "    window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    #THIS IS WHERE THE BEHAVIOUR WE CARE ABOUT ENDS - REPLACE THIS BLOCK\n",
        "    df = df[['id', 'carat', 'clarity', 'color', 'price']]\n",
        "    df = build_indep_vars(df, ['carat', 'clarity', 'color'],\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "JkEX3fPYgJEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Test"
      ],
      "metadata": {
        "id": "6ChzdpcnfiMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession, DataFrame, Window, Column\n",
        "from pyspark.sql.functions import lit, log, when, mean, col\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(2460.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    df = diamonds_df.withColumn('lprice', log('price'))\n",
        "\n",
        "    #THIS IS WHERE THE BEHAVIOUR WE CARE ABOUT STARTS - EXTRACT THIS BLOCK\n",
        "    window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    #THIS IS WHERE THE BEHAVIOUR WE CARE ABOUT ENDS\n",
        "\n",
        "    assert_diamond_has_expected_price(df)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "outputId": "9582519c-1f18-413d-8aaa-07a4a604daec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsPa000oHob3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mF\u001b[0m\u001b[31m                                                                                            [100%]\u001b[0m\n",
            "============================================= FAILURES =============================================\n",
            "\u001b[31m\u001b[1m____________________ test_null_price_is_replaced_based_on_cut_clarity_and_color ____________________\u001b[0m\n",
            "\n",
            "spark = <pyspark.sql.session.SparkSession object at 0x78015aa9e4d0>\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_null_price_is_replaced_based_on_cut_clarity_and_color\u001b[39;49;00m(spark: SparkSession):\u001b[90m\u001b[39;49;00m\n",
            "        diamonds_df = create_df_from_json(\u001b[33m\"\u001b[39;49;00m\u001b[33mtests/fixtures/diamonds.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, spark)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        df = diamonds_df.withColumn(\u001b[33m'\u001b[39;49;00m\u001b[33mlprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, log(\u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m#THIS IS WHERE THE BEHAVIOUR WE CARE ABOUT STARTS - EXTRACT THIS BLOCK\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        window = Window.partitionBy(\u001b[33m'\u001b[39;49;00m\u001b[33mcut\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mclarity\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).orderBy(\u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).rowsBetween(-\u001b[94m3\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        moving_avg = mean(df[\u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]).over(window)\u001b[90m\u001b[39;49;00m\n",
            "        df = df.withColumn(\u001b[33m'\u001b[39;49;00m\u001b[33mmoving_avg\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, moving_avg)\u001b[90m\u001b[39;49;00m\n",
            "        df = df.withColumn(\u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, when(df.price.isNull(), df.moving_avg).otherwise(df.price))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[90m#THIS IS WHERE THE BEHAVIOUR WE CARE ABOUT ENDS\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       assert_diamond_has_expected_price(df)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31m<ipython-input-74-49b4676f471a>\u001b[0m:22: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31m<ipython-input-74-49b4676f471a>\u001b[0m:8: in assert_diamond_has_expected_price\n",
            "    assert_column_equality(actual_df, \u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mexpected_price\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "df = DataFrame[carat: double, clarity: string, color: string, cut: string, depth: double, id: string, price: double, table: bigint, x: double, y: double, z: double, lprice: double, moving_avg: double, expected_price: double]\n",
            "col_name1 = 'price', col_name2 = 'expected_price'\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92massert_column_equality\u001b[39;49;00m(df, col_name1, col_name2):\u001b[90m\u001b[39;49;00m\n",
            "        elements = df.select(col_name1, col_name2).collect()\u001b[90m\u001b[39;49;00m\n",
            "        colName1Elements = \u001b[96mlist\u001b[39;49;00m(\u001b[96mmap\u001b[39;49;00m(\u001b[94mlambda\u001b[39;49;00m x: x[\u001b[94m0\u001b[39;49;00m], elements))\u001b[90m\u001b[39;49;00m\n",
            "        colName2Elements = \u001b[96mlist\u001b[39;49;00m(\u001b[96mmap\u001b[39;49;00m(\u001b[94mlambda\u001b[39;49;00m x: x[\u001b[94m1\u001b[39;49;00m], elements))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m colName1Elements != colName2Elements:\u001b[90m\u001b[39;49;00m\n",
            "            zipped = \u001b[96mlist\u001b[39;49;00m(\u001b[96mzip\u001b[39;49;00m(colName1Elements, colName2Elements))\u001b[90m\u001b[39;49;00m\n",
            "            t = PrettyTable([col_name1, col_name2])\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m elements \u001b[95min\u001b[39;49;00m zipped:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m elements[\u001b[94m0\u001b[39;49;00m] == elements[\u001b[94m1\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
            "                    first = bcolors.LightBlue + \u001b[96mstr\u001b[39;49;00m(elements[\u001b[94m0\u001b[39;49;00m]) + bcolors.LightRed\u001b[90m\u001b[39;49;00m\n",
            "                    second = bcolors.LightBlue + \u001b[96mstr\u001b[39;49;00m(elements[\u001b[94m1\u001b[39;49;00m]) + bcolors.LightRed\u001b[90m\u001b[39;49;00m\n",
            "                    t.add_row([first, second])\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    t.add_row([\u001b[96mstr\u001b[39;49;00m(elements[\u001b[94m0\u001b[39;49;00m]), \u001b[96mstr\u001b[39;49;00m(elements[\u001b[94m1\u001b[39;49;00m])])\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mraise\u001b[39;49;00m ColumnsNotEqualError(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m + t.get_string())\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           chispa.column_comparer.ColumnsNotEqualError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           +--------+----------------+\u001b[0m\n",
            "\u001b[1m\u001b[31mE           | price  | expected_price |\u001b[0m\n",
            "\u001b[1m\u001b[31mE           +--------+----------------+\u001b[0m\n",
            "\u001b[1m\u001b[31mE           | 2777.0 |     2460.0     |\u001b[0m\n",
            "\u001b[1m\u001b[31mE           +--------+----------------+\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.10/dist-packages/chispa/column_comparer.py\u001b[0m:24: ColumnsNotEqualError\n",
            "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m t_792e1f981ba74dd7b5b3b3bb63f7a733.py::\u001b[1mtest_null_price_is_replaced_based_on_cut_clarity_and_color\u001b[0m - chispa.column_comparer.ColumnsNotEqualError: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Original Test"
      ],
      "metadata": {
        "id": "jqDYqIPxriN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def test_will_do_the_right_thing(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "    assert data_frame_to_json(actual_df) == expected_json(\"expected_correct.json\")"
      ],
      "metadata": {
        "id": "kVhgeRJEriOG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f5a9a1c-d172-46b4-907a-d2d56d65d350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mF\u001b[0m\u001b[31m                                                                                            [100%]\u001b[0m\n",
            "============================================= FAILURES =============================================\n",
            "\u001b[31m\u001b[1m___________________________________ test_will_do_the_right_thing ___________________________________\u001b[0m\n",
            "\n",
            "spark = <pyspark.sql.session.SparkSession object at 0x78015a824160>\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_will_do_the_right_thing\u001b[39;49;00m(spark: SparkSession):\u001b[90m\u001b[39;49;00m\n",
            "        diamonds_df = create_df_from_json(\u001b[33m\"\u001b[39;49;00m\u001b[33mtests/fixtures/diamonds.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, spark)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        actual_df = transform(diamonds_df)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m data_frame_to_json(actual_df) == expected_json(\u001b[33m\"\u001b[39;49;00m\u001b[33mexpected_correct.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: assert [{'carat': 0....G', ...}, ...] == [{'carat': 0....G', ...}, ...]\u001b[0m\n",
            "\u001b[1m\u001b[31mE         At index 1 diff: {'id': 'DI-26', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 3333.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}} != {'id': 'DI-26', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 2690.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}\u001b[0m\n",
            "\u001b[1m\u001b[31mE         Use -v to get more diff\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m<ipython-input-75-e9ec4e9326c8>\u001b[0m:7: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "[{'id': '1', 'carat': 0.23, 'clarity': 'SI2', 'color': 'E', 'price': 326.0, 'clarity_index': 3.0, 'color_index': 1.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 5], 'values': [0.23, 1.0]}}, {'id': 'DI-26', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 3333.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}, {'id': 'DI-26', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 3333.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}, {'id': 'DI-26-null-price', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 2777.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}, {'id': 'DI-27', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 2692.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}, {'id': 'DI-28', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'G', 'price': 1665.0, 'clarity_index': 0.0, 'color_index': 3.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1], 'values': [0.21, 1.0]}}, {'id': 'DI-30', 'carat': 0.32, 'clarity': 'I1', 'color': 'D', 'price': 345.0, 'clarity_index': 1.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 2, 4], 'values': [0.32, 1.0, 1.0]}}, {'id': 'minimum_inputs', 'carat': 0.23, 'clarity': 'SI1', 'color': 'F', 'clarity_index': 2.0, 'color_index': 2.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 3, 6], 'values': [0.23, 1.0, 1.0]}}]\n",
            "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m t_792e1f981ba74dd7b5b3b3bb63f7a733.py::\u001b[1mtest_will_do_the_right_thing\u001b[0m - AssertionError: assert [{'carat': 0....G', ...}, ...] == [{'carat': 0....G', ...}, ...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Simplify the Top"
      ],
      "metadata": {
        "id": "5K0RWKPdr4fn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We don't want our test to be reading in the entire diamonds.json file in order to test this single behaviour. We are going to simplify things so that we have the absolute minimum number of inputs we need to reproduce the behaviour."
      ],
      "metadata": {
        "id": "YIx97jGHtDeP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of reading from a large JSON file directly, we can make a dataframe with only the values we need in order to reproduce the behaviour\n",
        "\n",
        "**our bug**: Diamonds of the same cut and clarity are influencing the calculated price of diamonds with a different color. Only diamonds with the same cut, clarity and color should be influencing the calculated price for diamonds with a null price.\n",
        "\n",
        "**expected behaviour**: An unpriced diamond with cut=Good, color=D and clarity=VVS1 in a dataset with other diamonds of the same cut, clarity and color all priced at 3333.0, will have it's price set to match the average price of those diamonds. It will ignore prices from diamonds with a different color, cut or clarity"
      ],
      "metadata": {
        "id": "xCqZLEY23Fn4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4A. We are going to be changing our test inputs. let's make sure the ones we need are present."
      ],
      "metadata": {
        "id": "uDBRZaXOHUt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame, Window\n",
        "from pyspark.sql.functions import lit, log, when, mean\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "### FOR REFERENCE: THIS IS THE CODE WE ARE TESTING #############################\n",
        "def calculate_avg_price_for_similar_diamonds(df: DataFrame) -> DataFrame:\n",
        "    window = Window.partitionBy('cut', 'clarity', 'color').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    return df\n",
        "################################################################################\n",
        "\n",
        "\n",
        "def check_we_have_all_the_rows_we_need_for_the_behaviour(actual_df):\n",
        "    # print(\"ACTUAL DATAFRAME:\")\n",
        "    # actual_df.show()\n",
        "    actual_df = actual_df.select('id', 'cut', 'clarity', 'color')\n",
        "    # print(\"ACTUAL DATAFRAME(IMPORTANT COLUMNS):\")\n",
        "    # actual_df.show()\n",
        "\n",
        "    wrong_color_df = actual_df.filter((actual_df.cut == 'Good') & (actual_df.clarity == 'VVS1') & (actual_df.color != 'D'))\n",
        "    # print(\"WRONG COLOR DATAFRAME:\")\n",
        "    # wrong_color_df.show()\n",
        "    assert wrong_color_df.count() >= 1\n",
        "    # assert False\n",
        "\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    check_we_have_all_the_rows_we_need_for_the_behaviour(actual_df)\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = diamonds_df.withColumn('lprice', log('price'))  # <-- Delete this line\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(actual_df) # <-- Change this line to: actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d529d3a-df59-451a-90a2-48b9349330cd",
        "id": "9_PMsYlgHZRi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.B Create the minimum Inputs needed to reproduce the bug\n",
        "- [ ] Delete the line that reads in from diamonds.json\n",
        "- [ ] Replace it with two lines, one that parses the json text file to a string, and the other that converts the json string to spark\n"
      ],
      "metadata": {
        "id": "MTcFz54o2_i0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "### FOR REFERENCE: THIS IS THE CODE WE ARE TESTING #############################\n",
        "def calculate_avg_price_for_similar_diamonds(df: DataFrame) -> DataFrame:\n",
        "    window = Window.partitionBy('cut', 'clarity', 'color').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    return df\n",
        "################################################################################\n",
        "\n",
        "\n",
        "def check_we_have_all_the_rows_we_need_for_the_behaviour(actual_df):\n",
        "    actual_df = actual_df.select('id', 'cut', 'clarity', 'color')\n",
        "\n",
        "    wrong_color_df = actual_df.filter((actual_df.cut == 'Good') & (actual_df.clarity == 'VVS1') & (actual_df.color != 'D'))\n",
        "    assert wrong_color_df.count() >= 1\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    check_we_have_all_the_rows_we_need_for_the_behaviour(actual_df)\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark) # <- Delete this line\n",
        "\n",
        "    #json_text = Path(\"./tests/fixtures/diamonds.json\").read_text()\n",
        "    #diamonds_df = spark.read.option(\"multiline\", \"true\").json(spark.sparkContext.parallelize([json_text]))\n",
        "\n",
        "    actual_df = diamonds_df.withColumn('lprice', log('price'))\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHXKgmUc4dU2",
        "outputId": "d69e5424-f533-4249-c21b-60392ba0159f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4C. Create the minimum Inputs needed to reproduce the bug\n",
        "- [ ] Copy the contents of `tests/fixtures/diamonds.json` to a multiline string.\n",
        "- [ ] Delete the line that reads the input data from a file\n",
        "- [ ] Run your test. It should pass."
      ],
      "metadata": {
        "id": "KGy1pOc4-_S8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "### FOR REFERENCE: THIS IS THE CODE WE ARE TESTING #############################\n",
        "def calculate_avg_price_for_similar_diamonds(df: DataFrame) -> DataFrame:\n",
        "    window = Window.partitionBy('cut', 'clarity', 'color').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    return df\n",
        "################################################################################\n",
        "\n",
        "def check_we_have_all_the_rows_we_need_for_the_behaviour(actual_df):\n",
        "    actual_df = actual_df.select('id', 'cut', 'clarity', 'color')\n",
        "\n",
        "    wrong_color_df = actual_df.filter((actual_df.cut == 'Good') & (actual_df.clarity == 'VVS1') & (actual_df.color != 'D'))\n",
        "    assert wrong_color_df.count() >= 1\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    check_we_have_all_the_rows_we_need_for_the_behaviour(actual_df)\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    json_text = '''\n",
        "      PASTE CONTENTS OF tests/fixtures/diamonds.json HERE\n",
        "    '''\n",
        "    json_text = Path(\"./tests/fixtures/diamonds.json\").read_text()  # <- DELETE THIS LINE\n",
        "    diamonds_df = spark.read.option(\"multiline\", \"true\").json(spark.sparkContext.parallelize([json_text]))\n",
        "\n",
        "    actual_df = diamonds_df.withColumn('lprice', log('price'))\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2451c55-854f-4371-cf59-e99473a32363",
        "id": "Th_x8dR6mKbv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4D. Squeeze the inputs\n",
        "- [ ] Run your test. It should pass.\n",
        "- [ ] Delete the objects from the JSON array one at a time.\n",
        "- [ ] After each deletion, run your test. If it fails, undo the delete\n",
        "- [ ] Move onto the next object\n",
        "- [ ] At the end, you should have the minimum objects needed for our test to test the behaviour\n",
        "\n",
        "**VERY IMPORTANT:** Your test will fail for the wrong reasons if the JSON array ends in a comma.\n",
        "\n",
        "Make sure the last 4 lines of the array always look like this:\n",
        "```\n",
        "    \"z\": null\n",
        "  }\n",
        "]\n",
        "    '''\n",
        " ```\n",
        "\n",
        "NOT this:\n",
        "```\n",
        "    \"z\": null\n",
        "  },\n",
        "]\n",
        "    '''\n",
        "```"
      ],
      "metadata": {
        "id": "AwLe7ZUx_8wR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "### FOR REFERENCE: THIS IS THE CODE WE ARE TESTING #############################\n",
        "def calculate_avg_price_for_similar_diamonds(df: DataFrame) -> DataFrame:\n",
        "    window = Window.partitionBy('cut', 'clarity', 'color').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    return df\n",
        "################################################################################\n",
        "\n",
        "def check_we_have_all_the_rows_we_need_for_the_behaviour(actual_df):\n",
        "    actual_df = actual_df.select('id', 'cut', 'clarity', 'color')\n",
        "\n",
        "    wrong_color_df = actual_df.filter((actual_df.cut == 'Good') & (actual_df.clarity == 'VVS1') & (actual_df.color != 'D'))\n",
        "    assert wrong_color_df.count() >= 1\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    check_we_have_all_the_rows_we_need_for_the_behaviour(actual_df)\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    json_text = '''\n",
        "[\n",
        "  {\n",
        "    \"id\": 1,\n",
        "    \"carat\": 0.23,\n",
        "    \"cut\": \"Ideal\",\n",
        "    \"color\": \"E\",\n",
        "    \"clarity\": \"SI2\",\n",
        "    \"depth\": 61.5,\n",
        "    \"table\": 55,\n",
        "    \"price\": 326,\n",
        "    \"x\": 3.95,\n",
        "    \"y\": 3.98,\n",
        "    \"z\": 2.43\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"minimum_inputs\",\n",
        "    \"carat\": 0.23,\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"F\",\n",
        "    \"clarity\": \"SI1\",\n",
        "    \"depth\": null,\n",
        "    \"table\": null,\n",
        "    \"price\": null,\n",
        "    \"x\": null,\n",
        "    \"y\": null,\n",
        "    \"z\": null\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"DI-26-null-price\",\n",
        "    \"carat\": 0.21,\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"D\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"depth\": null,\n",
        "    \"table\": null,\n",
        "    \"price\": null,\n",
        "    \"x\": null,\n",
        "    \"y\": null,\n",
        "    \"z\": null\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"DI-26\",\n",
        "    \"carat\": 0.21,\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"D\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"depth\": null,\n",
        "    \"table\": null,\n",
        "    \"price\": 3333,\n",
        "    \"x\": null,\n",
        "    \"y\": null,\n",
        "    \"z\": null\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"DI-26\",\n",
        "    \"carat\": 0.21,\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"D\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"depth\": null,\n",
        "    \"table\": null,\n",
        "    \"price\": 3333,\n",
        "    \"x\": null,\n",
        "    \"y\": null,\n",
        "    \"z\": null\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"DI-27\",\n",
        "    \"carat\": 0.21,\n",
        "    \"cut\": \"Very Good\",\n",
        "    \"color\": \"D\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"depth\": null,\n",
        "    \"table\": null,\n",
        "    \"price\": 2692,\n",
        "    \"x\": null,\n",
        "    \"y\": null,\n",
        "    \"z\": null\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"DI-30\",\n",
        "    \"carat\": 0.32,\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"D\",\n",
        "    \"clarity\": \"I1\",\n",
        "    \"depth\": 60.9,\n",
        "    \"table\": 58,\n",
        "    \"price\": 345,\n",
        "    \"x\": 4.38,\n",
        "    \"y\": 4.42,\n",
        "    \"z\": 2.68\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"DI-28\",\n",
        "    \"carat\": 0.21,\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"G\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"depth\": null,\n",
        "    \"table\": null,\n",
        "    \"price\": 1665,\n",
        "    \"x\": null,\n",
        "    \"y\": null,\n",
        "    \"z\": null\n",
        "  }\n",
        "]\n",
        "    '''\n",
        "\n",
        "    diamonds_df = spark.read.option(\"multiline\", \"true\").json(spark.sparkContext.parallelize([json_text]))\n",
        "\n",
        "    actual_df = diamonds_df.withColumn('lprice', log('price'))\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb2296bc-c5ba-47fd-c195-627357beb063",
        "id": "gOlilwetmgPM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4E. Squeeze the inputs\n",
        "- [ ] Run your test. It should pass.\n",
        "- [ ] Delete the properties from each JSON object one at a time.\n",
        "- [ ] After each deletion, run your test. If it fails, undo the delete\n",
        "- [ ] Move onto the next property\n",
        "- [ ] At the end, you should have the minimum objects and properties needed for our test to test the behaviour\n",
        "- [ ] Run your test. It should pass.\n",
        "\n",
        "**VERY IMPORTANT:** Your test will fail for the wrong reasons if the last property in any JSON object ends in a comma.\n",
        "\n",
        "Make sure the last property of each object always looks like this:\n",
        "```\n",
        "    \"z\": null\n",
        "  }\n",
        " ```\n",
        "\n",
        "NOT this:\n",
        "```\n",
        "    \"z\": null,\n",
        "  }\n",
        "```"
      ],
      "metadata": {
        "id": "pDKcNZHkBspK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "### FOR REFERENCE: THIS IS THE CODE WE ARE TESTING #############################\n",
        "def calculate_avg_price_for_similar_diamonds(df: DataFrame) -> DataFrame:\n",
        "    window = Window.partitionBy('cut', 'clarity', 'color').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    return df\n",
        "################################################################################\n",
        "\n",
        "def check_we_have_all_the_rows_we_need_for_the_behaviour(actual_df):\n",
        "    actual_df = actual_df.select('id', 'cut', 'clarity', 'color')\n",
        "\n",
        "    wrong_color_df = actual_df.filter((actual_df.cut == 'Good') & (actual_df.clarity == 'VVS1') & (actual_df.color != 'D'))\n",
        "    assert wrong_color_df.count() >= 1\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    check_we_have_all_the_rows_we_need_for_the_behaviour(actual_df)\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    json_text = '''\n",
        "[\n",
        "  {\n",
        "    \"id\": \"DI-26-null-price\",\n",
        "    \"carat\": 0.21,\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"D\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"depth\": null,\n",
        "    \"table\": null,\n",
        "    \"price\": null,\n",
        "    \"x\": null,\n",
        "    \"y\": null,\n",
        "    \"z\": null\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"DI-26\",\n",
        "    \"carat\": 0.21,\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"D\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"depth\": null,\n",
        "    \"table\": null,\n",
        "    \"price\": 3333,\n",
        "    \"x\": null,\n",
        "    \"y\": null,\n",
        "    \"z\": null\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"DI-28\",\n",
        "    \"carat\": 0.21,\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"G\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"depth\": null,\n",
        "    \"table\": null,\n",
        "    \"price\": 1665,\n",
        "    \"x\": null,\n",
        "    \"y\": null,\n",
        "    \"z\": null\n",
        "  }\n",
        "]\n",
        "    '''\n",
        "\n",
        "    diamonds_df = spark.read.option(\"multiline\", \"true\").json(spark.sparkContext.parallelize([json_text]))\n",
        "\n",
        "    actual_df = diamonds_df.withColumn('lprice', log('price'))\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abd6eec1-da08-4295-a238-932705dcdd36",
        "id": "fQIuk7Aum4Q0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### 4.F Remove lines that aren't related to the behaviour\n",
        "- [ ] Delete:\n",
        "\n",
        "```\n",
        "actual_df = diamonds_df.withColumn('lprice', log('price'))\n",
        "```\n",
        "- [ ] Update the name of the parameter we pass to `calculate_avg_price_for_similar_diamonds` from `actual_df` to `diamonds_df`\n",
        "- [ ] Run your test. It should pass. This means that line wasn't important for our behaviour.\n",
        "\n"
      ],
      "metadata": {
        "id": "GM1rYTV824Z-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "### FOR REFERENCE: THIS IS THE CODE WE ARE TESTING #############################\n",
        "def calculate_avg_price_for_similar_diamonds(df: DataFrame) -> DataFrame:\n",
        "    window = Window.partitionBy('cut', 'clarity', 'color').orderBy('price').rowsBetween(-3, 3)  #<- Remove cut or clarity from this line.\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    return df\n",
        "################################################################################\n",
        "\n",
        "def check_we_have_all_the_rows_we_need_for_the_behaviour(actual_df):\n",
        "    actual_df = actual_df.select('id', 'cut', 'clarity', 'color')\n",
        "\n",
        "    wrong_color_df = actual_df.filter((actual_df.cut == 'Good') & (actual_df.clarity == 'VVS1') & (actual_df.color != 'D'))\n",
        "    assert wrong_color_df.count() >= 1\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    check_we_have_all_the_rows_we_need_for_the_behaviour(actual_df)\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    json_text = '''\n",
        "[\n",
        "  {\n",
        "    \"id\": \"DI-26-null-price\",\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"D\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"price\": null\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"DI-26\",\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"D\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"price\": 3333\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"DI-28\",\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"G\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"price\": 1665,\n",
        "  }\n",
        "]\n",
        "\n",
        "    '''\n",
        "\n",
        "    diamonds_df = spark.read.option(\"multiline\", \"true\").json(spark.sparkContext.parallelize([json_text]))\n",
        "\n",
        "    actual_df = diamonds_df.withColumn('lprice', log('price'))  # <-- Delete this line\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(actual_df) # <-- Change this line to: actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b9dc74b-62e9-43a4-cdd1-720047c1c167",
        "id": "zGMDjRwjnz6B"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mF\u001b[0m\u001b[31m                                                                                            [100%]\u001b[0m\n",
            "============================================= FAILURES =============================================\n",
            "\u001b[31m\u001b[1m____________________ test_null_price_is_replaced_based_on_cut_clarity_and_color ____________________\u001b[0m\n",
            "\n",
            "spark = <pyspark.sql.session.SparkSession object at 0x78015ac5ada0>\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_null_price_is_replaced_based_on_cut_clarity_and_color\u001b[39;49;00m(spark: SparkSession):\u001b[90m\u001b[39;49;00m\n",
            "        json_text = \u001b[33m'''\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m[\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m  \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mid\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m: \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mDI-26-null-price\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mcut\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m: \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mGood\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mcolor\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m: \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mD\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mclarity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m: \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mVVS1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m: null\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m  },\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m  \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mid\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m: \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mDI-26\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mcut\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m: \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mGood\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mcolor\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m: \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mD\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mclarity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m: \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mVVS1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m: 3333\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m  },\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m  \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mid\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m: \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mDI-28\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mcut\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m: \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mGood\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mcolor\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m: \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mG\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mclarity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m: \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mVVS1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m: 1665,\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m  }\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m]\u001b[39;49;00m\u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    \u001b[39;49;00m\u001b[33m'''\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        diamonds_df = spark.read.option(\u001b[33m\"\u001b[39;49;00m\u001b[33mmultiline\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mtrue\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m).json(spark.sparkContext.parallelize([json_text]))\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       actual_df = diamonds_df.withColumn(\u001b[33m'\u001b[39;49;00m\u001b[33mlprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, log(\u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))  \u001b[90m# <-- Delete this line\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31m<ipython-input-110-6a0b9631ee72>\u001b[0m:59: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py\u001b[0m:4789: in withColumn\n",
            "    \u001b[94mreturn\u001b[39;49;00m DataFrame(\u001b[96mself\u001b[39;49;00m._jdf.withColumn(colName, col._jc), \u001b[96mself\u001b[39;49;00m.sparkSession)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m:1322: in __call__\n",
            "    return_value = get_return_value(\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "a = ('xro10478', <py4j.clientserver.JavaClient object at 0x78015bfc13f0>, 'o10475', 'withColumn')\n",
            "kw = {}, converted = AnalysisException()\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mdeco\u001b[39;49;00m(*a: Any, **kw: Any) -> Any:\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m f(*a, **kw)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mexcept\u001b[39;49;00m Py4JJavaError \u001b[94mas\u001b[39;49;00m e:\u001b[90m\u001b[39;49;00m\n",
            "            converted = convert_exception(e.java_exception)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(converted, UnknownException):\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[90m# Hide where the exception came from that shows a non-Pythonic\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[90m# JVM exception message.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">               \u001b[94mraise\u001b[39;49;00m converted \u001b[94mfrom\u001b[39;49;00m \u001b[96mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE               pyspark.errors.exceptions.captured.AnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `price` cannot be resolved. Did you mean one of the following? [`_corrupt_record`].;\u001b[0m\n",
            "\u001b[1m\u001b[31mE               'Project [_corrupt_record#10684, ln('price) AS lprice#10686]\u001b[0m\n",
            "\u001b[1m\u001b[31mE               +- LogicalRDD [_corrupt_record#10684], false\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m:175: AnalysisException\n",
            "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m t_792e1f981ba74dd7b5b3b3bb63f7a733.py::\u001b[1mtest_null_price_is_replaced_based_on_cut_clarity_and_color\u001b[0m - pyspark.errors.exceptions.captured.AnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A col...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4G. Analyze our test set:\n",
        "\n",
        "Our test is called `test_null_price_is_replaced_based_on_cut_clarity_and_color`.\n",
        "Is it complete?\n",
        "\n",
        "Try to delete 'cut' or 'clarity' from the first line of the `calculate_avg_price_for_similar_diamonds` method. If we don't partition by those, what happens?"
      ],
      "metadata": {
        "id": "aqRCL4UyG0oM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "### FOR REFERENCE: THIS IS THE CODE WE ARE TESTING #############################\n",
        "def calculate_avg_price_for_similar_diamonds(df: DataFrame) -> DataFrame:\n",
        "    window = Window.partitionBy('cut', 'clarity', 'color').orderBy('price').rowsBetween(-3, 3)  #<- Remove cut or clarity from this line.\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    return df\n",
        "################################################################################\n",
        "\n",
        "def check_we_have_all_the_rows_we_need_for_the_behaviour(actual_df):\n",
        "    actual_df = actual_df.select('id', 'cut', 'clarity', 'color')\n",
        "\n",
        "    wrong_color_df = actual_df.filter((actual_df.cut == 'Good') & (actual_df.clarity == 'VVS1') & (actual_df.color != 'D'))\n",
        "    assert wrong_color_df.count() >= 1\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    check_we_have_all_the_rows_we_need_for_the_behaviour(actual_df)\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    json_text = '''\n",
        "[\n",
        "  {\n",
        "    \"id\": \"DI-26-null-price\",\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"D\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"price\": null\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"DI-26\",\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"D\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"price\": 3333\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"DI-28\",\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"G\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"price\": 1665,\n",
        "  }\n",
        "]\n",
        "\n",
        "    '''\n",
        "\n",
        "    diamonds_df = spark.read.option(\"multiline\", \"true\").json(spark.sparkContext.parallelize([json_text]))\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51dd594d-2c82-4720-f344-0a862cc1c164",
        "id": "tJEwVpuDQUdH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4H. Add a test input for clarity:\n",
        "\n",
        "We need to add an input for a diamond with a different clarity, but identical cut and color.\n",
        "- [ ] Now that you can see what's important, update the JSON below to set those properties correctly.\n",
        "- [ ] clarity should be `\"S1\"`\n",
        "- [ ] cut and color should be identical to the values in `\"DI-26-null-price\"`\n",
        "- [ ] Try to delete 'clarity' from the first line of the `calculate_avg_price_for_similar_diamonds` function. The test should fail.\n"
      ],
      "metadata": {
        "id": "WIvG00bZI_dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "### FOR REFERENCE: THIS IS THE CODE WE ARE TESTING #############################\n",
        "def calculate_avg_price_for_similar_diamonds(df: DataFrame) -> DataFrame:\n",
        "    window = Window.partitionBy('cut', 'clarity', 'color').orderBy('price').rowsBetween(-3, 3)  #<- Remove clarity from this line.\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    return df\n",
        "################################################################################\n",
        "\n",
        "def check_we_have_all_the_rows_we_need_for_the_behaviour(actual_df):\n",
        "    actual_df = actual_df.select('id', 'cut', 'clarity', 'color')\n",
        "\n",
        "    wrong_color_df = actual_df.filter((actual_df.cut == 'Good') & (actual_df.clarity == 'VVS1') & (actual_df.color != 'D'))\n",
        "    assert wrong_color_df.count() >= 1\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    check_we_have_all_the_rows_we_need_for_the_behaviour(actual_df)\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    json_text = '''\n",
        "[\n",
        "  {\n",
        "    \"id\": \"DI-26-null-price\",\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"D\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"price\": null\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"DI-26\",\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"D\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"price\": 3333\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"DI-28\",\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"G\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"price\": 1665\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"different-clarity\",\n",
        "    \"cut\": #REPLACE ME WITH THE RIGHT VALUE FOR CUT# ,\n",
        "    \"color\": #REPLACE ME WITH THE RIGHT VALUE FOR COLOR#,\n",
        "    \"clarity\": #REPLACE ME WITH THE RIGHT VALUE FOR CLARITY#,\n",
        "    \"price\": 1665\n",
        "  }\n",
        "]\n",
        "\n",
        "    '''\n",
        "\n",
        "    diamonds_df = spark.read.option(\"multiline\", \"true\").json(spark.sparkContext.parallelize([json_text]))\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c0a6c1b-a66c-4d0a-96d5-09c392dbaeed",
        "id": "xjJLNBkbJkIH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4I. Add a test input for cut:\n",
        "\n",
        "We need to add an input for a diamond with a different cut, but identical clarity and color.\n",
        "- [ ] Now that you can see what's important, update the JSON below to set those properties correctly.\n",
        "- [ ] cut should be `\"Very Good\"`\n",
        "- [ ] clarity and color should be identical to the values in `\"DI-26-null-price\"`\n",
        "- [ ] Try to delete 'cut' from the first line of the `calculate_avg_price_for_similar_diamonds` function. The test should fail.\n"
      ],
      "metadata": {
        "id": "gQ5kwCZnK4Ks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "### FOR REFERENCE: THIS IS THE CODE WE ARE TESTING #############################\n",
        "def calculate_avg_price_for_similar_diamonds(df: DataFrame) -> DataFrame:\n",
        "    window = Window.partitionBy('cut', 'clarity', 'color').orderBy('price').rowsBetween(-3, 3)  #<- Remove clarity from this line.\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    return df\n",
        "################################################################################\n",
        "\n",
        "def check_we_have_all_the_rows_we_need_for_the_behaviour(actual_df):\n",
        "    actual_df = actual_df.select('id', 'cut', 'clarity', 'color')\n",
        "\n",
        "    wrong_color_df = actual_df.filter((actual_df.cut == 'Good') & (actual_df.clarity == 'VVS1') & (actual_df.color != 'D'))\n",
        "    assert wrong_color_df.count() >= 1\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    check_we_have_all_the_rows_we_need_for_the_behaviour(actual_df)\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    json_text = '''\n",
        "[\n",
        "  {\n",
        "    \"id\": \"DI-26-null-price\",\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"D\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"price\": null\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"DI-26\",\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"D\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"price\": 3333\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"DI-28\",\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"G\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"price\": 1665\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"different-clarity\",\n",
        "    \"cut\": \"Good\" ,\n",
        "    \"color\": \"D\",\n",
        "    \"clarity\": \"S1\",\n",
        "    \"price\": 1665\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"different-cut\",\n",
        "    \"cut\": #REPLACE ME WITH THE RIGHT VALUE FOR CUT# ,\n",
        "    \"color\": #REPLACE ME WITH THE RIGHT VALUE FOR COLOR#,\n",
        "    \"clarity\": #REPLACE ME WITH THE RIGHT VALUE FOR CLARITY#,\n",
        "    \"price\": 1665\n",
        "  }\n",
        "]\n",
        "\n",
        "    '''\n",
        "\n",
        "    diamonds_df = spark.read.option(\"multiline\", \"true\").json(spark.sparkContext.parallelize([json_text]))\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bfe7c2e-7230-47a8-db3a-919ee8d8b197",
        "id": "RrwYZNguLI1h"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Clean up!"
      ],
      "metadata": {
        "id": "u73U7To0xBvK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This test can still be cleaner and easy to read.\n",
        "\n",
        "It passes, so it satisfies the first rule of simple design - tests pass\n",
        "\n",
        "What about the other 3?"
      ],
      "metadata": {
        "id": "wjYANsWB5gnF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5A: Reveal Intent - Extract the unpriced diamond to a method\n",
        "\n",
        "- [ ]  This is our unpriced diamond. In the next cell, we will pull it out into a method."
      ],
      "metadata": {
        "id": "wE2StiSh5xd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'no-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = spark.createDataFrame([\n",
        "      ##### THE UNPRICED DIAMOND #####\n",
        "      {\"id\": \"no-price\",                       \"price\": None,  \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"},\n",
        "      ##### END OF THE UNPRICED DIAMOND #####\n",
        "      {\"id\": \"with-price\",                     \"price\": 3333.0,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"},\n",
        "      {\"id\": \"with-price-wrong-color\",         \"price\": 2000.0,\"color\": \"G\", \"cut\": \"Good\", \"clarity\": \"VVS1\"},\n",
        "      {\"id\": \"with-price-wrong-clarity\",       \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"S1\"},\n",
        "      {\"id\": \"with-price-wrong-cut\",           \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Very Good\", \"clarity\": \"VVS1\"},\n",
        "    ])\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJjI4Dsr458a",
        "outputId": "de687037-eee1-4117-ef03-9f38a6d3e0ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5B: Reveal Intent - Extract the unpriced diamond to a method\n",
        "\n",
        "- [ ] We've created a new method called unpriced_diamond to return the code creating the unpriced diamond. It is commented out.\n",
        "- [ ] Uncomment it.\n",
        "- [ ] Run the test. It should pass."
      ],
      "metadata": {
        "id": "5aw5dbMc647E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "from typing import Dict\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'no-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "##### UNCOMMENT THIS METHOD\n",
        "#def unpriced_diamond() -> Dict:\n",
        "#  return {\"id\": \"no-price\", \"price\": None,  \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = spark.createDataFrame([\n",
        "      ##### THE UNPRICED DIAMOND #####\n",
        "      unpriced_diamond(),\n",
        "      ##### END OF THE UNPRICED DIAMOND #####\n",
        "      {\"id\": \"with-price\",                     \"price\": 3333.0,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"},\n",
        "      {\"id\": \"with-price-wrong-color\",         \"price\": 2000.0,\"color\": \"G\", \"cut\": \"Good\", \"clarity\": \"VVS1\"},\n",
        "      {\"id\": \"with-price-wrong-clarity\",       \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"S1\"},\n",
        "      {\"id\": \"with-price-wrong-cut\",           \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Very Good\", \"clarity\": \"VVS1\"},\n",
        "    ])\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5caogkF7ASx",
        "outputId": "8c74623f-05ab-4fcf-f19e-94591b624f1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5C: Reveal Intent - Extract the matching diamond to a method\n",
        "\n",
        "- [ ] Look at the second object in the JSON array. This is our matching diamond. In the next cell, we will pull it out into a method."
      ],
      "metadata": {
        "id": "VnOthS9a8M8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "from typing import Dict\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'no-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def unpriced_diamond() -> Dict:\n",
        "  return {\"id\": \"no-price\", \"price\": None,  \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = spark.createDataFrame([\n",
        "      unpriced_diamond(),\n",
        "      ##### THE MATCHING DIAMOND #####\n",
        "      {\"id\": \"with-price\",                     \"price\": 3333.0,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"},\n",
        "      ##### END OF THE MATCHING DIAMOND #####\n",
        "      {\"id\": \"with-price-wrong-color\",         \"price\": 2000.0,\"color\": \"G\", \"cut\": \"Good\", \"clarity\": \"VVS1\"},\n",
        "      {\"id\": \"with-price-wrong-clarity\",       \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"S1\"},\n",
        "      {\"id\": \"with-price-wrong-cut\",           \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Very Good\", \"clarity\": \"VVS1\"},\n",
        "    ])\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCnpkyyJ8c45",
        "outputId": "ea42a2e7-e218-4805-deb0-aed6bf05a2c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5D: Reveal Intent - Extract the matching diamond to a method\n",
        "\n",
        "- [ ] We've created a new method called matching_diamond to return the code creating the matching diamond.It is commented out.\n",
        "- [ ] Uncomment it.\n",
        "- [ ] Notice how we've set up the method interface so it takes a price. This lets us indicate we care about the price of the matching diamond.\n",
        "- [ ] The price of the matching diamond should be `3333.0`. Pass it into the method call.\n",
        "- [ ] Run the test. It should pass."
      ],
      "metadata": {
        "id": "aE3q7gEu9BVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "\n",
        "from typing import Dict\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'no-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def unpriced_diamond() -> Dict:\n",
        "  return {\"id\": \"no-price\", \"price\": None,  \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "#def matching_diamond(price: float) -> Dict:\n",
        "#  return {\"id\": \"with-price\", \"price\": price ,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = spark.createDataFrame([\n",
        "      unpriced_diamond(),\n",
        "      ##### THE MATCHING DIAMOND #####\n",
        "      matching_diamond(), # <- CHANGE THIS LINE TO: matching_diamond(price=3333.0),\n",
        "      ##### END OF THE MATCHING DIAMOND #####\n",
        "      {\"id\": \"with-price-wrong-color\",         \"price\": 2000.0,\"color\": \"G\", \"cut\": \"Good\", \"clarity\": \"VVS1\"},\n",
        "      {\"id\": \"with-price-wrong-clarity\",       \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"S1\"},\n",
        "      {\"id\": \"with-price-wrong-cut\",           \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Very Good\", \"clarity\": \"VVS1\"},\n",
        "    ])\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktPMcHy99MKr",
        "outputId": "8cc109a1-db12-417e-f60f-c567f72edb2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5E: Reveal Intent - Extract the diamond with a different color to a method\n",
        "\n",
        "- [ ] Look at the third object in the JSON array. This is the diamond with a different color. In the next cell, we will pull it out into a method."
      ],
      "metadata": {
        "id": "F39cC4hgDTb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "\n",
        "from typing import Dict\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'no-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def unpriced_diamond() -> Dict:\n",
        "  return {\"id\": \"no-price\", \"price\": None,  \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def matching_diamond(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price\", \"price\": price ,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = spark.createDataFrame([\n",
        "      unpriced_diamond(),\n",
        "      matching_diamond(price=3333.0),\n",
        "      ##### THE DIAMOND WITH A DIFFERENT COLOR #####\n",
        "      {\"id\": \"with-price-wrong-color\",         \"price\": 2000.0,\"color\": \"G\", \"cut\": \"Good\", \"clarity\": \"VVS1\"},\n",
        "      ##### END OF THE DIAMOND WITH A DIFFERENT COLOR #####\n",
        "      {\"id\": \"with-price-wrong-clarity\",       \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"S1\"},\n",
        "      {\"id\": \"with-price-wrong-cut\",           \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Very Good\", \"clarity\": \"VVS1\"},\n",
        "    ])\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n"
      ],
      "metadata": {
        "outputId": "69325f3d-e77f-4cbc-a685-36d1e4a726c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBRWtL5zDugj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5F: Reveal Intent - Extract the diamond with a different color to a method\n",
        "\n",
        "- [ ] We've created a new method called diamond_with_different_color to return the diamond with a different color.\n",
        "- [ ] Notice how we've set up the method interface so we can see we care about the price of the diamond.\n",
        "- [ ] We want to use the price we pass into the method. Replace the hardcoded `2000.0` with `price`\n",
        "- [ ] The price of this diamond should be `2000.0`. Pass it into the method call.\n",
        "- [ ] Run the test. It should pass."
      ],
      "metadata": {
        "id": "8tMW5y32FI3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "\n",
        "from typing import Dict\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'no-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def unpriced_diamond() -> Dict:\n",
        "  return {\"id\": \"no-price\", \"price\": None,  \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def matching_diamond(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price\", \"price\": price ,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def diamond_with_different_color(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price-wrong-color\", \"price\": 2000.0, \"color\": \"G\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}  # <- CHANGE \"price\": 2000.0 TO \"price\": price\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = spark.createDataFrame([\n",
        "      unpriced_diamond(),\n",
        "      matching_diamond(price=3333.0),\n",
        "      ##### THE DIAMOND WITH A DIFFERENT COLOR #####\n",
        "      diamond_with_different_color(), # <- CHANGE THIS LINE TO: diamond_with_different_color(price=2000.0),\n",
        "      ##### END OF THE DIAMOND WITH A DIFFERENT COLOR #####\n",
        "      {\"id\": \"with-price-wrong-clarity\",       \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"S1\"},\n",
        "      {\"id\": \"with-price-wrong-cut\",           \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Very Good\", \"clarity\": \"VVS1\"},\n",
        "    ])\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n"
      ],
      "metadata": {
        "outputId": "a2635672-594b-4cc8-b5c4-60a35c22ef18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yXFRNXJFhSd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5G: Reveal Intent - Extract the diamond with a different clarity to a method\n",
        "\n",
        "- [ ] Look at the fourth object in the JSON array. This is the diamond with a different clarity. In the next cell, we will pull it out into a method."
      ],
      "metadata": {
        "id": "4uJl_hsDQvhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "\n",
        "from typing import Dict\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'no-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def unpriced_diamond() -> Dict:\n",
        "  return {\"id\": \"no-price\", \"price\": None,  \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def matching_diamond(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price\", \"price\": price ,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def diamond_with_different_color(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price-wrong-color\", \"price\": price, \"color\": \"G\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = spark.createDataFrame([\n",
        "      unpriced_diamond(),\n",
        "      matching_diamond(price=3333.0),\n",
        "      diamond_with_different_color(price=2000.0),\n",
        "      ##### THE DIAMOND WITH A DIFFERENT CLARITY #####\n",
        "      {\"id\": \"with-price-wrong-clarity\",       \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"S1\"},\n",
        "      ##### END OF THE DIAMOND WITH A DIFFERENT CLARITY #####\n",
        "      {\"id\": \"with-price-wrong-cut\",           \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Very Good\", \"clarity\": \"VVS1\"},\n",
        "    ])\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n"
      ],
      "metadata": {
        "outputId": "1caf8326-fad9-4e2f-813e-d0617c3a49f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jl2YouSpRD4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5H: Reveal Intent - Extract the diamond with a different clarity to a method\n",
        "\n",
        "- [ ] We've created a new method called diamond_with_different_clarity to return the diamond with a different clarity.\n",
        "- [ ] The method call that would call this method is commented.\n",
        "- [ ] Uncomment it.\n",
        "- [ ] Cut and paste the dict that represents the diamond with a different clarity after the return statement in diamond_with_different_clarity.\n",
        "- [ ] Change the hardcoded \"price\": 2000.0 to \"price\": price\n",
        "- [ ] Run the test. It should pass."
      ],
      "metadata": {
        "id": "TQCkzt92RWe3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "\n",
        "from typing import Dict\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'no-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def unpriced_diamond() -> Dict:\n",
        "  return {\"id\": \"no-price\", \"price\": None,  \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def matching_diamond(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price\", \"price\": price ,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def diamond_with_different_color(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price-wrong-color\", \"price\": price, \"color\": \"G\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def diamond_with_different_clarity(price: float) -> Dict:\n",
        "  return ####### PASTE THE DICT HERE AND CHANGE \"price\": 2000.0 TO \"price\": price #####\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = spark.createDataFrame([\n",
        "      unpriced_diamond(),\n",
        "      matching_diamond(price=3333.0),\n",
        "      diamond_with_different_color(price=2000.0),\n",
        "      ##### THE DIAMOND WITH A DIFFERENT CLARITY #####\n",
        "      # diamond_with_different_clarity(price=2000.0), # <- UNCOMMENT THIS LINE\n",
        "      {\"id\": \"with-price-wrong-clarity\", \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"S1\"}, # <- CUT THIS LINE AND PASTE IT AFTER THE RETURN IN diamond_with_different_clarity\n",
        "      ##### END OF THE DIAMOND WITH A DIFFERENT CLARITY #####\n",
        "      {\"id\": \"with-price-wrong-cut\",           \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Very Good\", \"clarity\": \"VVS1\"},\n",
        "    ])\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n"
      ],
      "metadata": {
        "outputId": "3e0f7527-6623-465a-9ed6-7150f151b447",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4u90QE5RyhS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5I: Reveal Intent - Extract the diamond with a different cut to a method\n",
        "\n",
        "- [ ] Look at the fifth object in the JSON array. This is the diamond with a different cut. In the next cell, we will pull it out into a method."
      ],
      "metadata": {
        "id": "oKv6s0nQTDhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "\n",
        "from typing import Dict\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'no-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def unpriced_diamond() -> Dict:\n",
        "  return {\"id\": \"no-price\", \"price\": None,  \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def matching_diamond(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price\", \"price\": price ,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def diamond_with_different_color(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price-wrong-color\", \"price\": price, \"color\": \"G\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def diamond_with_different_clarity(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price-wrong-color\", \"price\": price, \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"S1\"}\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = spark.createDataFrame([\n",
        "      unpriced_diamond(),\n",
        "      matching_diamond(price=3333.0),\n",
        "      diamond_with_different_color(price=2000.0),\n",
        "      diamond_with_different_clarity(price=2000.0),\n",
        "      ##### THE DIAMOND WITH A DIFFERENT CUT #####\n",
        "      {\"id\": \"with-price-wrong-cut\",           \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Very Good\", \"clarity\": \"VVS1\"},\n",
        "      ##### END OF THE DIAMOND WITH A DIFFERENT CUT #####\n",
        "    ])\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n"
      ],
      "metadata": {
        "outputId": "1caf8326-fad9-4e2f-813e-d0617c3a49f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8P8yPdfTeQS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5J: Reveal Intent - Extract the diamond with a different cut to a method\n",
        "\n",
        "- [ ] We've created a new method called diamond_with_different_cut to return the diamond with a different cut.\n",
        "- [ ] Notice how we've set up the method interface so we can see we care about the price of the diamond.\n",
        "- [ ] Replace the Dict in between the comments with a method call to the new method.\n",
        "- [ ] Run the test. It should pass."
      ],
      "metadata": {
        "id": "9nObySWVT6gl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "\n",
        "from typing import Dict\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'no-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def unpriced_diamond() -> Dict:\n",
        "  return {\"id\": \"no-price\", \"price\": None,  \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def matching_diamond(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price\", \"price\": price ,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def diamond_with_different_color(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price-wrong-color\", \"price\": price, \"color\": \"G\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def diamond_with_different_clarity(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price-wrong-color\", \"price\": price, \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"S1\"}\n",
        "\n",
        "def diamond_with_different_cut(price: float) -> Dict:\n",
        "  return  {\"id\": \"with-price-wrong-cut\",           \"price\": price,\"color\": \"D\", \"cut\": \"Very Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = spark.createDataFrame([\n",
        "      unpriced_diamond(),\n",
        "      matching_diamond(price=3333.0),\n",
        "      diamond_with_different_color(price=2000.0),\n",
        "      diamond_with_different_clarity(price=2000.0),\n",
        "      ##### THE DIAMOND WITH A DIFFERENT CUT #####\n",
        "      {\"id\": \"with-price-wrong-cut\", \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Very Good\", \"clarity\": \"VVS1\"},  # <- DELETE THIS\n",
        "      # CALL diamond_with_different_cut(price=2000.0) HERE\n",
        "      ##### END OF THE DIAMOND WITH A DIFFERENT CUT #####\n",
        "    ])\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n"
      ],
      "metadata": {
        "outputId": "3e0f7527-6623-465a-9ed6-7150f151b447",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_PBu4T_T_IP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5K: Reveal Intent - Make it obvious which price we want\n",
        "\n",
        "- [ ] Pass the price as an argument to your assert helper function\n",
        "- [ ] Use it in place of the hardcoded 3333.0 when you create the `expected_price` column\n",
        "- [ ] Run the test. It should pass."
      ],
      "metadata": {
        "id": "XwIvmhGrJ46K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "\n",
        "from typing import Dict\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None: # <- CHANGE THIS LINE TO: def assert_diamond_has_expected_price(actual_df: DataFrame, price: float) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'no-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0)) # <- CHANGE THIS LINE TO: actual_df=actual_df.withColumn('expected_price', lit(price))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def unpriced_diamond() -> Dict:\n",
        "  return {\"id\": \"no-price\", \"price\": None,  \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def matching_diamond(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price\", \"price\": price ,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def diamond_with_different_color(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price-wrong-color\", \"price\": price, \"color\": \"G\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def diamond_with_different_clarity(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price-wrong-color\", \"price\": price, \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"S1\"}\n",
        "\n",
        "def diamond_with_different_cut(price: float) -> Dict:\n",
        "  return  {\"id\": \"with-price-wrong-cut\",  \"price\": price, \"color\": \"D\", \"cut\": \"Very Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = spark.createDataFrame([\n",
        "      unpriced_diamond(),\n",
        "      matching_diamond(price=3333.0),\n",
        "      diamond_with_different_color(price=2000.0),\n",
        "      diamond_with_different_clarity(price=2000.0),\n",
        "      diamond_with_different_cut(price=2000.0)\n",
        "    ])\n",
        "\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)  # <- CHANGE THIS LINE TO: assert_diamond_has_expected_price(actual_df, price=3333.0)\n"
      ],
      "metadata": {
        "outputId": "750e20c2-e7fc-4afc-dd34-9bf780cb0dba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9nUrsnKJ0qv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5L: Remove Duplication - Use the Mismatched Diamond Function\n",
        "\n",
        "There is duplication in the `diamond_with_different_color`, `diamond_with_different_clarity` and `diamond_with_different_cut` methods.\n",
        "- [ ] There is a new method `mismatched_diamond` that minimizes duplication. Have each of these methods call that method.\n",
        "- [ ] Run the test. It should pass."
      ],
      "metadata": {
        "id": "yNkX4CfqMn-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "\n",
        "from typing import Dict\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame, price: float) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'no-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(price))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def unpriced_diamond() -> Dict:\n",
        "  return {\"id\": \"no-price\", \"price\": None,  \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def matching_diamond(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price\", \"price\": price ,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def diamond_with_different_color(price: float) -> Dict:\n",
        "  # CHANGE THE LINE BELOW TO: return mismatched_diamond(price=price, different_columns={\"color\": \"G\"})\n",
        "  return {\"id\": \"with-price-wrong-color\", \"price\": price, \"color\": \"G\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def diamond_with_different_clarity(price: float) -> Dict:\n",
        "  # CHANGE THE LINE BELOW TO: return mismatched_diamond(price=price, different_columns={\"clarity\": \"S1\"})\n",
        "  return {\"id\": \"with-price-wrong-color\", \"price\": price, \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"S1\"}\n",
        "\n",
        "def diamond_with_different_cut(price: float) -> Dict:\n",
        "  # CHANGE THE LINE BELOW TO: return mismatched_diamond(price=price, different_columns={\"cut\": \"Very Good\"})\n",
        "  return  {\"id\": \"with-price-wrong-cut\",  \"price\": price, \"color\": \"D\", \"cut\": \"Very Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def mismatched_diamond(price: float, different_columns: Dict) -> Dict:\n",
        "  diamond = {\"id\": \"with-price\", \"price\": price ,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "  diamond = diamond | different_columns\n",
        "  return diamond\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = spark.createDataFrame([\n",
        "      unpriced_diamond(),\n",
        "      matching_diamond(price=3333.0),\n",
        "      diamond_with_different_color(price=2000.0),\n",
        "      diamond_with_different_clarity(price=2000.0),\n",
        "      diamond_with_different_cut(price=2000.0)\n",
        "    ])\n",
        "\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df, price=3333.0)\n"
      ],
      "metadata": {
        "outputId": "cf3b44d4-3216-4b81-9f21-bfa9191f641e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDv6GixHg2BM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5M: Remove Duplication - Inline the duplicate functions\n",
        "\n",
        "There is duplication in the `diamond_with_different_color`, `diamond_with_different_clarity` and `diamond_with_different_cut` methods.\n",
        "- [ ] Replace the call to each of these functions in the test with their call to `mismatched_diamond`\n",
        "- [ ] Delete the duplicated functions"
      ],
      "metadata": {
        "id": "SVYtHusOp-n4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "\n",
        "from typing import Dict\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame, price: float) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'no-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(price))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def unpriced_diamond() -> Dict:\n",
        "  return {\"id\": \"no-price\", \"price\": None,  \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def matching_diamond(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price\", \"price\": price ,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "##### DELETE THESE FUNCTIONS #####\n",
        "def diamond_with_different_color(price: float) -> Dict:\n",
        "  return mismatched_diamond(price=price, different_columns={\"color\": \"G\"})\n",
        "\n",
        "def diamond_with_different_clarity(price: float) -> Dict:\n",
        "  return mismatched_diamond(price=price, different_columns={\"clarity\": \"S1\"})\n",
        "\n",
        "def diamond_with_different_cut(price: float) -> Dict:\n",
        "  return mismatched_diamond(price=price, different_columns={\"cut\": \"Very Good\"})\n",
        "##################################\n",
        "\n",
        "\n",
        "def mismatched_diamond(price: float, different_columns: Dict) -> Dict:\n",
        "  diamond = {\"id\": \"with-price\", \"price\": price ,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "  diamond = diamond | different_columns\n",
        "  return diamond\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = spark.createDataFrame([\n",
        "      unpriced_diamond(),\n",
        "      matching_diamond(price=3333.0),\n",
        "      # CHANGE THE LINE BELOW TO: mismatched_diamond(price=2000.0, different_columns={\"color\": \"G\"})\n",
        "      diamond_with_different_color(price=2000.0),\n",
        "      # CHANGE THE LINE BELOW TO: mismatched_diamond(price=2000.0, different_columns={\"clarity\": \"S1\"})\n",
        "      diamond_with_different_clarity(price=2000.0),\n",
        "      # CHANGE THE LINE BELOW TO: mismatched_diamond(price=2000.0, different_columns={\"cut\": \"Very Good\"})\n",
        "      diamond_with_different_cut(price=2000.0)\n",
        "    ])\n",
        "\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df, price=3333.0)\n"
      ],
      "metadata": {
        "outputId": "cdaa0a11-938a-4b1b-8d3a-30196cbf7caa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKXNeMc_qhKy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}