{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkjZHWuu+4S6WLd2XV1LFe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmasonlee/efficiently_testing_etl_pipelines/blob/main/fixing_a_big_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 0.A: Setup Notebook"
      ],
      "metadata": {
        "id": "aqYjZpizVD3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf efficiently_testing_etl_pipelines\n",
        "!git clone https://github.com/jmasonlee/efficiently_testing_etl_pipelines.git\n",
        "!cp -r /content/efficiently_testing_etl_pipelines/src/ .\n",
        "!cp -r /content/efficiently_testing_etl_pipelines/tests/ .\n",
        "!rm -rf efficiently_testing_etl_pipelines\n",
        "!rm -rf tests/diamond_pricing_test*\n",
        "!rm -rf tests/test_helpers/*verification_helpers.py\n",
        "!rm -rf tests/conftest.py\n",
        "!rm -rf sample_data\n"
      ],
      "metadata": {
        "id": "i4KRAp6vTEJm",
        "outputId": "4520154c-ed9e-4654-f596-629c3534e973",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'efficiently_testing_etl_pipelines'...\n",
            "remote: Enumerating objects: 629, done.\u001b[K\n",
            "remote: Counting objects: 100% (270/270), done.\u001b[K\n",
            "remote: Compressing objects: 100% (193/193), done.\u001b[K\n",
            "remote: Total 629 (delta 174), reused 111 (delta 70), pack-reused 359\u001b[K\n",
            "Receiving objects: 100% (629/629), 271.00 KiB | 3.98 MiB/s, done.\n",
            "Resolving deltas: 100% (380/380), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 0.B: Setup Tests"
      ],
      "metadata": {
        "id": "5cRRMTtEBYy0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Dependencies\n",
        "\n",
        "For the exercise, we will need some special dependencies to allow us to run lots of tests in a notebook."
      ],
      "metadata": {
        "id": "_h199h_XEAwT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`ipytest` lets us run our tests in a notebook.\n",
        "\n"
      ],
      "metadata": {
        "id": "DVAcSonZmslt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipytest"
      ],
      "metadata": {
        "id": "7v0kaWulDXi-",
        "outputId": "0c324c21-7816-457e-92b6-9bad05e578d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipytest\n",
            "  Downloading ipytest-0.13.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipytest) (7.34.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ipytest) (23.1)\n",
            "Requirement already satisfied: pytest>=5.4 in /usr/local/lib/python3.10/dist-packages (from ipytest) (7.2.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=5.4->ipytest) (23.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=5.4->ipytest) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest>=5.4->ipytest) (1.2.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest>=5.4->ipytest) (1.1.2)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=5.4->ipytest) (2.0.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->ipytest)\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipytest) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipytest) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipytest) (0.2.6)\n",
            "Installing collected packages: jedi, ipytest\n",
            "Successfully installed ipytest-0.13.3 jedi-0.18.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ipytest is what allows us to run our tests in a notebook. This next cell is not needed if you are writing tests in a separate pytest file."
      ],
      "metadata": {
        "id": "3_ILjU8goCNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipytest\n",
        "ipytest.autoconfig()"
      ],
      "metadata": {
        "id": "t7iwGQ4Le-Oe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are installing `pyspark` because it doesn't come with the base colab environment"
      ],
      "metadata": {
        "id": "HzwfHFGmm2Ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "QNnk84AsmmFQ",
        "outputId": "c4719543-3a79-4e4b-8ead-9f71af7bf2dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285398 sha256=aeff8d6806c7acdd46694a55842c1f7d77cce8f67b6c965eaa6f6eab57fa0523\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chispa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_EYg-cC1cD5",
        "outputId": "91e27086-44b3-4763-82e7-5941b32b56cb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chispa\n",
            "  Downloading chispa-0.9.2-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: chispa\n",
            "Successfully installed chispa-0.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a local SparkSession\n",
        "\n",
        "Normally spark runs on a bunch of executors in the cloud. Since we want our tests to be able to run on a single dev machine, we make a fixture that gives us a local spark context."
      ],
      "metadata": {
        "id": "V_OJcnSiBgUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "from _pytest.fixtures import FixtureRequest\n",
        "from pyspark import SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "@pytest.fixture(scope=\"session\")\n",
        "def spark(request: FixtureRequest):\n",
        "    conf = (SparkConf()\n",
        "        .setMaster(\"local\")\n",
        "        .setAppName(\"sample_pyspark_testing_starter\"))\n",
        "\n",
        "    spark = SparkSession \\\n",
        "        .builder \\\n",
        "        .config(conf=conf) \\\n",
        "        .getOrCreate()\n",
        "\n",
        "    request.addfinalizer(lambda: spark.stop())\n",
        "    return spark"
      ],
      "metadata": {
        "id": "xXPLpebJ6iI2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Helpers\n",
        "\n",
        "This is a helper function that retrieves our test output from the expected.json file"
      ],
      "metadata": {
        "id": "actN5s7DCF9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import List, Dict\n",
        "\n",
        "from pyspark.pandas import DataFrame\n",
        "\n",
        "\n",
        "def create_df_from_json(json_file, spark):\n",
        "    return spark.read.option(\"multiline\", \"true\").json(json_file)\n",
        "\n",
        "\n",
        "def data_frame_to_json(df: DataFrame) -> List:\n",
        "    output = [json.loads(item) for item in df.toJSON().collect()]\n",
        "    output.sort(key=lambda item: item[\"id\"])\n",
        "    print(output)\n",
        "    return output\n",
        "\n",
        "def expected_json(name: str) -> Dict:\n",
        "    with open(f\"tests/fixtures/{name}\") as f:\n",
        "        return json.loads(f.read())"
      ],
      "metadata": {
        "id": "VO2-3px25xEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d9316d1-da26-45c1-d21f-113fdc7e56b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "def build_indep_vars(df, independent_vars, categorical_vars=None, keep_intermediate=False, summarizer=True):\n",
        "    check_input(categorical_vars, df, independent_vars)\n",
        "\n",
        "    from pyspark.ml import Pipeline\n",
        "    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "    idx = 'index'\n",
        "    vec = 'vector'\n",
        "    if categorical_vars:\n",
        "        string_indexer = [StringIndexer(inputCol=x,\n",
        "                                        outputCol=f\"{x}_{idx}\")\n",
        "                          for x in categorical_vars]\n",
        "\n",
        "        encoder        = [OneHotEncoder(dropLast=True,\n",
        "                                        inputCol =f'{x}_{idx}',\n",
        "                                        outputCol=f'{x}_{vec}')\n",
        "                          for x in categorical_vars]\n",
        "\n",
        "        independent_vars = ['{}_vector'.format(x) if x in categorical_vars else x for x in independent_vars]\n",
        "    else:\n",
        "        string_indexer, encoder = [], []\n",
        "\n",
        "    assembler = VectorAssembler(inputCols=independent_vars,\n",
        "                                outputCol='indep_vars')\n",
        "    pipeline  = Pipeline(stages=string_indexer+encoder+[assembler])\n",
        "    model = pipeline.fit(df)\n",
        "    df = model.transform(df)\n",
        "\n",
        "    if not keep_intermediate:\n",
        "        fcols = [c for c in df.columns if f'_{idx}' not in c[-3:] and f'_{vec}' not in c[-7:]]\n",
        "        df = df[fcols]\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def check_input(categorical_vars, df, independent_vars):\n",
        "    assert (type(\n",
        "        df) is pyspark.sql.dataframe.DataFrame), 'pypark_glm: A pySpark dataframe is required as the first argument.'\n",
        "    assert (type(\n",
        "        independent_vars) is list), 'pyspark_glm: List of independent variable column names must be the third argument.'\n",
        "    for iv in independent_vars:\n",
        "        assert (type(iv) is str), 'pyspark_glm: Independent variables must be column name strings.'\n",
        "        assert (iv in df.columns), 'pyspark_glm: Independent variable name is not a dataframe column.'\n",
        "    if categorical_vars:\n",
        "        for cv in categorical_vars:\n",
        "            assert (type(cv) is str), 'pyspark_glm: Categorical variables must be column name strings.'\n",
        "            assert (cv in df.columns), 'pyspark_glm: Categorical variable name is not a dataframe column.'\n",
        "            assert (cv in independent_vars), 'pyspark_glm: Categorical variables must be independent variables.'\n"
      ],
      "metadata": {
        "id": "eBvHph1aCJiN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import DataFrame, Window, Column\n",
        "from pyspark.sql.functions import log, when, mean, col\n",
        "\n",
        "def replace_null(orig: Column, average: Column):\n",
        "    return when(orig.isNull(), average).otherwise(orig)\n",
        "\n",
        "def transform(df: DataFrame) -> DataFrame:\n",
        "\n",
        "    df = df.withColumn('lprice', log('price'))\n",
        "    window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    df = df[['id', 'carat', 'clarity', 'color', 'price']]\n",
        "    df = build_indep_vars(df, ['carat', 'clarity', 'color'],\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "22lMaALmCTJm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 0.C: Run The Test"
      ],
      "metadata": {
        "id": "MjwHttFB5TB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def test_will_do_the_right_thing(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "    assert data_frame_to_json(actual_df) == expected_json(\"expected.json\")"
      ],
      "metadata": {
        "id": "lH1x9ZOi58X7",
        "outputId": "e6b75d09-700c-43d4-b128-bbc8c5e1c13c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Setup For the Saff Squeeze"
      ],
      "metadata": {
        "id": "95eTfqjbZfGV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instructions\n",
        "Let's get ready to improve the test.\n",
        "\n",
        "**our bug**: Diamonds of the same cut and clarity are influencing the calculated price of diamonds with a different color. Only diamonds with the same cut, clarity _**and color**_ should be influencing the calculated price for diamonds with a null price.\n",
        "\n",
        "**expected behaviour**:\n",
        "An unpriced diamond with cut=Good, color=D and clarity=VVS1 in a dataset with other diamonds of the same cut, clarity and color all priced at 2690.0, will have it's price set to match the average of all the prices for diamonds of the same cut, clarity and color - or 2690.0.\n",
        "\n",
        "\n",
        "\n",
        "- [ ] Change the test to check for the behaviour we want.\n",
        "There is a second json file (`expected_correct.json`) where the expected price for the unpriced diamond has been updated to the correct value. Use that file name as the argument passed to `expected_json`\n",
        "- [ ] Run the test. It should fail.\n",
        "- [ ] Duplicate the test. Now you should have two copies of the same test.\n",
        "One copy will stay the same, so we can make sure that nothing is broken. The second copy is what we will change in the next steps.\n",
        "- [ ] Rename the test.\n",
        "Pick a name that tells you what behaviour you are verifying with the test you are using for the Saff Squeeze. I chose `test_null_price_is_replaced_based_on_cut_clarity_and_color`, but names are hard. You might be able to think of a better one :-)\n",
        "- [ ] Run the tests. They should both fail because our diamond is being returned with a price of 2460.0, when we expect 2690.0"
      ],
      "metadata": {
        "id": "oDLkPTvpnKGS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise"
      ],
      "metadata": {
        "id": "Wv_k7gBEvpm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def test_will_do_the_right_thing(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "    assert data_frame_to_json(actual_df) == expected_json(\"expected.json\")"
      ],
      "metadata": {
        "outputId": "3cdc7802-3939-444f-b6d3-10dd9460b6a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VKLXAMic975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Make The Assert Specific"
      ],
      "metadata": {
        "id": "cbCuKHDpso8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Right now, our test compares everything in the output dataframe to everything in a large json file. That's a lot of rows to compare and the assert is wrong anyways!\n",
        "\n",
        "Let's make this test assert on the thing we actually care about - the output price of the diamond!"
      ],
      "metadata": {
        "id": "X-xfpXMwstwN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instructions - Chispa\n",
        "\n",
        "#### With Chispa\n",
        "- [ ] Add these imports to the top of the cell, below the `%%ipytest -qq` line:  \n",
        "`from chispa import assert_column_equality`  \n",
        "`from pySpark.sql.functions import lit`\n",
        "- [ ] Filter the dataframe for the unique id of the diamond we care about:  \n",
        "`actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')`\n",
        "- [ ] Create a new column in our dataframe that contains our expected price:  \n",
        "`actual_df=actual_df.withColumn('expected_price', lit(2690.0))`\n",
        "- [ ] Assert the value in the price column matches the value we want:  \n",
        "`assert_column_equality(actual_df, 'price', 'expected_price')`\n"
      ],
      "metadata": {
        "id": "jz3ygb6GxcYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise - Chispa"
      ],
      "metadata": {
        "id": "vYiG_Qgtv1bs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n"
      ],
      "metadata": {
        "outputId": "4c816535-dd6e-417d-9aa5-61ed763d8cf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiwYRKD0yXIW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions - Pandas\n",
        "- [ ] import pandas:  \n",
        "`import pandas as pd`\n",
        "- [ ] Filter the dataframe for the unique id of the diamond we care about:  \n",
        "  `actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')`\n",
        "- [ ] Create your expected dataframe using Pandas:  \n",
        " `expected = pd.DataFrame(({'id': [\"DI-26-null-price\"], 'price':[2690.0] }))`\n",
        "- [ ] Select the column you care about:  \n",
        "  `actual_df=actual_df.select(['id', 'price'])\n",
        "- [ ] Assert for dataframe equality using pandas:  \n",
        "  `pd.testing.assert_frame_equal(actual_df, expected)`"
      ],
      "metadata": {
        "id": "wW0OfrWo8Qn4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise - Pandas"
      ],
      "metadata": {
        "id": "TM4QCxCZwEbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n"
      ],
      "metadata": {
        "outputId": "59fcd2dc-fcf1-4d79-cca8-f1aaa43a0c42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a_ORvhl9CAd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions - JSON properties\n",
        "\n",
        "- [ ] Filter the dataframe for the unique id of the diamond we care about:  \n",
        "  `actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')`\n",
        "- [ ] Convert your dataframe to JSON:  \n",
        "`actual_df_json = data_frame_to_json(actual_df)`\n",
        "- [ ] Assert the price property of the first object matches your expected price:  \n",
        "`assert actual_df_json[0]['price'] == 2690.0`"
      ],
      "metadata": {
        "id": "lD-3MVVv9D9d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise - JSON properties"
      ],
      "metadata": {
        "id": "F0GvaGLEwMZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "\n"
      ],
      "metadata": {
        "outputId": "ef5afbc8-7590-4119-e1c6-dd53152f85cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55eVJ0Ug9Pif"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Reduce Duplicate Coverage and Fix the Bug\n",
        "\n",
        "Right now, our test is running the entire transform function. Because there are multiple tests in `diamonds.json`, each test is running the same large block of code over and over again."
      ],
      "metadata": {
        "id": "sw4mvQYw5pkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 3.A: Prep"
      ],
      "metadata": {
        "id": "8kumyMxuNFY_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions\n",
        "Let's get ready to reduce the duplicate coverage.\n",
        "\n",
        "#### 1. Put the transform function where you can work with it\n",
        "- [ ] Run the test. It should be failing.\n",
        "- [ ] Replace the call to the transform function with the body of that function.\n",
        "- [ ] Change the last line of the function body to assign to `actual_df` instead of `df`\n",
        "```\n",
        "df = build_indep_vars(df, ['carat', 'clarity', 'color'],\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "```\n",
        "becomes\n",
        "```\n",
        "actual_df = build_indep_vars(df, ['carat', 'clarity', 'color'],\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "```\n",
        "- [ ] Change the first line of the function body to read from `diamonds_df` instead of `df`\n",
        "```\n",
        " df = df.withColumn('lprice', log('price'))\n",
        "```\n",
        "becomes\n",
        "```\n",
        " df = diamonds_df.withColumn('lprice', log('price'))\n",
        "```\n",
        "- [ ] Run the test. It should still be failing for the same reasons.\n",
        "\n",
        "#### 2. Test FOR the bug\n",
        "- [ ] Change your assert code so that it is testing _for_ the bug.\n",
        "```\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(2690.0))\n",
        "```\n",
        "becomes\n",
        "```\n",
        "  actual_df=actual_df.withColumn('expected_price', lit(2460.0))\n",
        "```\n",
        "- [ ] Run the test. It should pass.\n",
        "\n",
        "#### 3. Make the assert easier to work with\n",
        "- [ ] Extract your assert code into a one-line helper function:\n",
        "```\n",
        "def assert_diamond_has_expected_price(actual_df):\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(2460.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "```\n",
        "- [ ] Run the test. It should pass."
      ],
      "metadata": {
        "id": "-2pcPdIhf6ad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise"
      ],
      "metadata": {
        "id": "57xFbUQaoIaq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Code"
      ],
      "metadata": {
        "id": "0ze_hB2VCmC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The `transform` Function"
      ],
      "metadata": {
        "id": "YgzlhOgV-LJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import DataFrame, Window, Column\n",
        "from pyspark.sql.functions import log, when, mean, col\n",
        "\n",
        "\n",
        "def transform(df: DataFrame) -> DataFrame:\n",
        "# The body of the transform function STARTS HERE\n",
        "    df = df.withColumn('lprice', log('price'))  #<-- In the test, this line should be: df = diamonds_df.withColumn('lprice', log('price'))\n",
        "    window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    df = df[['id', 'carat', 'clarity', 'color', 'price']]\n",
        "    df = build_indep_vars(df, ['carat', 'clarity', 'color'], #<-- In the test, this line should be: actual_df = build_indep_vars(df, ['carat', 'clarity', 'color']\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "# The body of the transform function ENDS HERE\n",
        "    return df"
      ],
      "metadata": {
        "id": "EqUboG2Y-HZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Test"
      ],
      "metadata": {
        "id": "DR41JwrwDPhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def test_prep_for_linear_regression(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df) #<-- We will be replacing this line with the body of the transform function\n",
        "\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(2690.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')"
      ],
      "metadata": {
        "outputId": "cbe1c4c7-be34-4af1-e671-5b07796ddcb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ci_qnCgB57k9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mF\u001b[0m\u001b[31m                                                                                            [100%]\u001b[0m\n",
            "============================================= FAILURES =============================================\n",
            "\u001b[31m\u001b[1m_________________________________ test_prep_for_linear_regression __________________________________\u001b[0m\n",
            "\n",
            "spark = <pyspark.sql.session.SparkSession object at 0x7fd3843987c0>\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_prep_for_linear_regression\u001b[39;49;00m(spark: SparkSession):\u001b[90m\u001b[39;49;00m\n",
            "        diamonds_df = create_df_from_json(\u001b[33m\"\u001b[39;49;00m\u001b[33mtests/fixtures/diamonds.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, spark)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        actual_df = transform(diamonds_df)\u001b[90m\u001b[39;49;00m\n",
            "        actual_df.show()\u001b[90m\u001b[39;49;00m\n",
            "        actual_df=actual_df.filter(actual_df.id == \u001b[33m'\u001b[39;49;00m\u001b[33mDI-26-null-price\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        actual_df=actual_df.withColumn(\u001b[33m'\u001b[39;49;00m\u001b[33mexpected_price\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, lit(\u001b[94m2690.0\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            ">       assert_column_equality(actual_df, \u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mexpected_price\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31m<ipython-input-90-613d013a3b70>\u001b[0m:10: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "df = DataFrame[id: string, carat: double, clarity: string, color: string, price: double, clarity_index: double, color_index: double, indep_vars: vector, expected_price: double]\n",
            "col_name1 = 'price', col_name2 = 'expected_price'\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92massert_column_equality\u001b[39;49;00m(df, col_name1, col_name2):\u001b[90m\u001b[39;49;00m\n",
            "        elements = df.select(col_name1, col_name2).collect()\u001b[90m\u001b[39;49;00m\n",
            "        colName1Elements = \u001b[96mlist\u001b[39;49;00m(\u001b[96mmap\u001b[39;49;00m(\u001b[94mlambda\u001b[39;49;00m x: x[\u001b[94m0\u001b[39;49;00m], elements))\u001b[90m\u001b[39;49;00m\n",
            "        colName2Elements = \u001b[96mlist\u001b[39;49;00m(\u001b[96mmap\u001b[39;49;00m(\u001b[94mlambda\u001b[39;49;00m x: x[\u001b[94m1\u001b[39;49;00m], elements))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m colName1Elements != colName2Elements:\u001b[90m\u001b[39;49;00m\n",
            "            zipped = \u001b[96mlist\u001b[39;49;00m(\u001b[96mzip\u001b[39;49;00m(colName1Elements, colName2Elements))\u001b[90m\u001b[39;49;00m\n",
            "            t = PrettyTable([col_name1, col_name2])\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m elements \u001b[95min\u001b[39;49;00m zipped:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m elements[\u001b[94m0\u001b[39;49;00m] == elements[\u001b[94m1\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
            "                    first = bcolors.LightBlue + \u001b[96mstr\u001b[39;49;00m(elements[\u001b[94m0\u001b[39;49;00m]) + bcolors.LightRed\u001b[90m\u001b[39;49;00m\n",
            "                    second = bcolors.LightBlue + \u001b[96mstr\u001b[39;49;00m(elements[\u001b[94m1\u001b[39;49;00m]) + bcolors.LightRed\u001b[90m\u001b[39;49;00m\n",
            "                    t.add_row([first, second])\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    t.add_row([\u001b[96mstr\u001b[39;49;00m(elements[\u001b[94m0\u001b[39;49;00m]), \u001b[96mstr\u001b[39;49;00m(elements[\u001b[94m1\u001b[39;49;00m])])\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mraise\u001b[39;49;00m ColumnsNotEqualError(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m + t.get_string())\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           chispa.column_comparer.ColumnsNotEqualError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           +--------+----------------+\u001b[0m\n",
            "\u001b[1m\u001b[31mE           | price  | expected_price |\u001b[0m\n",
            "\u001b[1m\u001b[31mE           +--------+----------------+\u001b[0m\n",
            "\u001b[1m\u001b[31mE           | 2460.0 |     2690.0     |\u001b[0m\n",
            "\u001b[1m\u001b[31mE           +--------+----------------+\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.10/dist-packages/chispa/column_comparer.py\u001b[0m:24: ColumnsNotEqualError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "+----------------+-----+-------+-----+------+-------------+-----------+--------------------+\n",
            "|              id|carat|clarity|color| price|clarity_index|color_index|          indep_vars|\n",
            "+----------------+-----+-------+-----+------+-------------+-----------+--------------------+\n",
            "|           DI-30| 0.32|     I1|    D| 345.0|          1.0|        0.0|(7,[0,2,4],[0.32,...|\n",
            "|  minimum_inputs| 0.23|    SI1|    F|  null|          2.0|        2.0|(7,[0,3,6],[0.23,...|\n",
            "|DI-26-null-price| 0.21|   VVS1|    D|2460.0|          0.0|        0.0|(7,[0,1,4],[0.21,...|\n",
            "|           DI-28| 0.21|   VVS1|    G|2000.0|          0.0|        3.0|(7,[0,1],[0.21,1.0])|\n",
            "|           DI-26| 0.21|   VVS1|    D|2690.0|          0.0|        0.0|(7,[0,1,4],[0.21,...|\n",
            "|           DI-26| 0.21|   VVS1|    D|2690.0|          0.0|        0.0|(7,[0,1,4],[0.21,...|\n",
            "|               1| 0.23|    SI2|    E| 326.0|          3.0|        1.0|(7,[0,5],[0.23,1.0])|\n",
            "|           DI-27| 0.21|   VVS1|    D|2692.0|          0.0|        0.0|(7,[0,1,4],[0.21,...|\n",
            "+----------------+-----+-------+-----+------+-------------+-----------+--------------------+\n",
            "\n",
            "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m t_dd33edcfd11b45fcb600db307d7bac98.py::\u001b[1mtest_prep_for_linear_regression\u001b[0m - chispa.column_comparer.ColumnsNotEqualError: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The original test\n",
        "\n"
      ],
      "metadata": {
        "id": "ojU7wLaKdbBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def test_will_do_the_right_thing(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "    assert data_frame_to_json(actual_df) == expected_json(\"expected_correct.json\")"
      ],
      "metadata": {
        "id": "S5228csId2CS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3.B Squeeze the bottom!\n"
      ],
      "metadata": {
        "id": "5oBE2ZEAF2E2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Instructions\n",
        "**our bug**: Diamonds of the same cut and clarity are influencing the calculated price of diamonds with a different color. Only diamonds with the same cut, clarity and color should be influencing the calculated price for diamonds with a null price.\n",
        "\n",
        "**Squeeze the bottom until you find the bug**\n",
        "- [ ] Move your assert up one line at a time.  \n",
        "- [ ] After each move, run your test.  \n",
        "- [ ] If it fails, figure out why it's failing.(You may need to rename columns in the assert)\n",
        "- [ ] If the test passes, the line wasn't important for the bug you wanted to catch. Delete it.\n",
        "- [ ] Continue until you find the source of the bug"
      ],
      "metadata": {
        "id": "PhriAy0jfsTj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise"
      ],
      "metadata": {
        "id": "SyOFZzKVokvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Code"
      ],
      "metadata": {
        "id": "u2EHWBjMetva"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The `transform` Function"
      ],
      "metadata": {
        "id": "9Yne491Uetvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import DataFrame, Window, Column\n",
        "from pyspark.sql.functions import log, when, mean, col\n",
        "\n",
        "def transform(df: DataFrame) -> DataFrame:\n",
        "\n",
        "    df = df.withColumn('lprice', log('price'))\n",
        "    window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    df = df[['id', 'carat', 'clarity', 'color', 'price']]\n",
        "    df = build_indep_vars(df, ['carat', 'clarity', 'color'],\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "-EhWDEgLetvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Test"
      ],
      "metadata": {
        "id": "441Jq5Ude3n7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession, DataFrame, Window, Column\n",
        "from pyspark.sql.functions import lit, log, when, mean, col\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df):\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(2460.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def test_prep_for_linear_regression(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = diamonds_df.withColumn('lprice', log('price'))\n",
        "    window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(actual_df['price']).over(window)\n",
        "    actual_df = actual_df.withColumn('moving_avg', moving_avg)\n",
        "\n",
        "    actual_df = actual_df.withColumn('price', replace_null(col('price'), col('moving_avg')))\n",
        "    actual_df = actual_df[['id', 'carat', 'clarity', 'color', 'price']]\n",
        "    actual_df = build_indep_vars(actual_df, ['carat', 'clarity', 'color'],\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "outputId": "32e5b753-bc49-4041-8e45-3e6b0de61d92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFv4b_9xFw-t"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Original Test"
      ],
      "metadata": {
        "id": "MMVXW7E7gNBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def test_will_do_the_right_thing(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "    assert data_frame_to_json(actual_df) == expected_json(\"expected_correct.json\")"
      ],
      "metadata": {
        "id": "S50HLHD9gALp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3.C Let's fix the bug!\n"
      ],
      "metadata": {
        "id": "H3kdrtuBEbcC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions\n",
        "\n",
        "**Our Bug**: Diamonds of the same cut and clarity are influencing the calculated price of diamonds with a different color. Only diamonds with the same cut, clarity and color should be influencing the calculated price for diamonds with a null price.\n",
        "\n",
        "**Our Desired Behaviour**:  \n",
        "The input diamond with these properties:\n",
        "- id: `\"DI-26-null-price\"`\n",
        "- cut: `\"Good\"`\n",
        "- color: `\"D\"`\n",
        "- clarity: `\"VVS1\"`\n",
        "- price: `null`\n",
        "\n",
        "Should be output with a price of `2690.0` - the average price of the other diamonds with `cut=\"Good\"`, `clarity=\"VVS1\"` and `color=\"D\"`\n",
        "\n",
        "**Fix the bug**\n",
        "#### Test for the behaviour you actually want\n",
        "- [ ] Update your test so that it checks for the good behaviour.  \n",
        "Replace the expected price on this line with `2690.0`:  \n",
        "```\n",
        "actual_df=actual_df.withColumn('expected_price', lit(2460.0))\n",
        "```\n",
        "- [ ] Run your test. It should fail with a `columnsNotEqualError`:  \n",
        "```\n",
        "E           chispa.column_comparer.ColumnsNotEqualError:\n",
        "E           +------------+----------------+\n",
        "E           | moving_avg | expected_price |\n",
        "E           +------------+----------------+\n",
        "E           |   2460.0   |     2690.0     |\n",
        "E           +------------+----------------+\n",
        "```\n",
        "\n",
        "#### Fix the bug\n",
        "- [ ] Fix the code _in your test_ so that the bug is gone. We need to add `'color'` to `'cut'` and `'clarity'` on this line:\n",
        "```\n",
        "window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "```\n",
        "- [ ] Run your test. It should pass.\n",
        "\n",
        "#### Encapsulate the code necessary for the behaviour\n",
        "- [ ] The behaviour belongs to a group of lines working together. Extract them into a method.  \n",
        "These lines can't be separated without changing the behaviour we are testing:  \n",
        "```\n",
        "    window = Window.partitionBy('cut', 'clarity', 'color').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "```  \n",
        "Use them to make a method:\n",
        "```\n",
        "def calculate_avg_price_for_similar_diamonds(df: DataFrame) -> DataFrame:\n",
        "      window = Window.partitionBy('cut', 'clarity', 'color').orderBy('price').rowsBetween(-3, 3)\n",
        "      moving_avg = mean(df['price']).over(window)\n",
        "      df = df.withColumn('moving_avg', moving_avg)\n",
        "      df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "      return df\n",
        "```\n",
        "\n",
        "Replace those lines with a call to the new method in your test:  \n",
        "```\n",
        "actual_df = calculate_avg_price_for_similar_diamonds(actual_df)\n",
        "```\n",
        "- [ ] Run your test. It should pass.\n",
        "\n",
        "#### Move the encapsulated behaviour to the actual code\n",
        "- [ ] Move the new method out of your test and into the transform code.\n",
        "- [ ] Replace the lines in your transform code with the new method call.\n",
        "- [ ] We've changed the original code, so we need to check that everything still works the way we expect. Run the copy of your original large test. It should also pass.\n",
        "- [ ] Run your test. It should pass.\n"
      ],
      "metadata": {
        "id": "mL_lKfL-fdgh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise"
      ],
      "metadata": {
        "id": "mNb7r0copJ3X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Code"
      ],
      "metadata": {
        "id": "69ahdJEigJD7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The `transform` Function"
      ],
      "metadata": {
        "id": "aS6CsJ4IgJEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import DataFrame, Window, Column\n",
        "from pyspark.sql.functions import log, when, mean, col\n",
        "\n",
        "\n",
        "def transform(df: DataFrame) -> DataFrame:\n",
        "\n",
        "    df = df.withColumn('lprice', log('price'))\n",
        "    window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    df = df[['id', 'carat', 'clarity', 'color', 'price']]\n",
        "    df = build_indep_vars(df, ['carat', 'clarity', 'color'],\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "JkEX3fPYgJEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Test"
      ],
      "metadata": {
        "id": "6ChzdpcnfiMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession, DataFrame, Window, Column\n",
        "from pyspark.sql.functions import lit, log, when, mean, col\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df):\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(2460.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def test_prep_for_linear_regression(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    df = diamonds_df.withColumn('lprice', log('price'))\n",
        "    window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "\n",
        "    assert_diamond_has_expected_price(df)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "outputId": "5d02b372-017d-4dbc-d581-308517c0acf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsPa000oHob3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Original Test"
      ],
      "metadata": {
        "id": "jqDYqIPxriN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def test_will_do_the_right_thing(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "    assert data_frame_to_json(actual_df) == expected_json(\"expected_correct.json\")"
      ],
      "metadata": {
        "id": "kVhgeRJEriOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Simplify the Top"
      ],
      "metadata": {
        "id": "5K0RWKPdr4fn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instructions\n",
        "\n",
        "We don't want our test to be reading in the entire diamonds.json file in order to test this single behaviour. We are going to simplify things so that we have the absolute minimum number of inputs we need to reproduce the behaviour.\n",
        "\n",
        "- [ ] We can see that we only care about the moving_avg column, and not the price column. It should be safe to delete this line:\n",
        "```\n",
        "actual_df = diamonds_df.withColumn('lprice', log('price'))\n",
        "```\n",
        "- [ ] Run the test to make sure everything still works\n"
      ],
      "metadata": {
        "id": "YIx97jGHtDeP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise"
      ],
      "metadata": {
        "id": "vDHmd40SxTvX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Code"
      ],
      "metadata": {
        "id": "iTePGQi3uIrZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The `transform` Function"
      ],
      "metadata": {
        "id": "5mMyb3YruIra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import DataFrame, Window, Column\n",
        "from pyspark.sql.functions import log, when, mean, col\n",
        "\n",
        "def calculate_avg_price_for_similar_diamonds(diamonds_df: DataFrame) -> DataFrame:\n",
        "    window = Window.partitionBy('cut', 'clarity', 'color').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(diamonds_df['price']).over(window)\n",
        "    diamonds_df = diamonds_df.withColumn('moving_avg', moving_avg)\n",
        "    return diamonds_df\n",
        "\n",
        "def transform(df: DataFrame) -> DataFrame:\n",
        "\n",
        "    df = df.withColumn('lprice', log('price'))\n",
        "    df = calculate_avg_price_for_similar_diamonds(df)\n",
        "\n",
        "    df_new = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    df = df[['id', 'carat', 'clarity', 'color', 'price']]\n",
        "    df = build_indep_vars(df, ['carat', 'clarity', 'color'],\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "KEoj9ZIiuIra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Test"
      ],
      "metadata": {
        "id": "G__NWc_YuIra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession, DataFrame, Window, Column\n",
        "from pyspark.sql.functions import lit, log, when, mean, col\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df):\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(2460.0))\n",
        "    assert_column_equality(actual_df, 'moving_avg', 'expected_price')\n",
        "\n",
        "def test_prep_for_linear_regression(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = diamonds_df.withColumn('lprice', log('price'))\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(actual_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "outputId": "faacd446-2e11-4fe0-ba7d-85729a9c9e53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hGpGRswuIra"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Original Test"
      ],
      "metadata": {
        "id": "ZADhPscWuIrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def test_will_do_the_right_thing(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "    assert data_frame_to_json(actual_df) == expected_json(\"expected_correct.json\")"
      ],
      "metadata": {
        "id": "2w5WFSwSuIrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Clean up!"
      ],
      "metadata": {
        "id": "u73U7To0xBvK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise"
      ],
      "metadata": {
        "id": "RorP6P6LxhX0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Code"
      ],
      "metadata": {
        "id": "B_TBjELMxhYB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The `transform` Function"
      ],
      "metadata": {
        "id": "GXnL3PNkxhYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import DataFrame, Window, Column\n",
        "from pyspark.sql.functions import log, when, mean, col\n",
        "\n",
        "def calculate_avg_price_for_similar_diamonds(diamonds_df: DataFrame) -> DataFrame:\n",
        "    window = Window.partitionBy('cut', 'clarity', 'color').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(diamonds_df['price']).over(window)\n",
        "    diamonds_df = diamonds_df.withColumn('moving_avg', moving_avg)\n",
        "    return diamonds_df\n",
        "\n",
        "def transform(df: DataFrame) -> DataFrame:\n",
        "\n",
        "    df = df.withColumn('lprice', log('price'))\n",
        "    df = calculate_avg_price_for_similar_diamonds(df)\n",
        "\n",
        "    df_new = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    df = df[['id', 'carat', 'clarity', 'color', 'price']]\n",
        "    df = build_indep_vars(df, ['carat', 'clarity', 'color'],\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "hau-wpfrxhYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Test"
      ],
      "metadata": {
        "id": "lj7GrNhlxhYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession, DataFrame, Window, Column\n",
        "from pyspark.sql.functions import lit, log, when, mean, col\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df):\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(2460.0))\n",
        "    assert_column_equality(actual_df, 'moving_avg', 'expected_price')\n",
        "\n",
        "def test_prep_for_linear_regression(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = diamonds_df.withColumn('lprice', log('price'))\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(actual_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "outputId": "faacd446-2e11-4fe0-ba7d-85729a9c9e53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRM1pZ5SxhYC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Original Test"
      ],
      "metadata": {
        "id": "Ed0A_dZMxhYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def test_will_do_the_right_thing(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "    assert data_frame_to_json(actual_df) == expected_json(\"expected_correct.json\")"
      ],
      "metadata": {
        "id": "NEmagolUxhYD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}