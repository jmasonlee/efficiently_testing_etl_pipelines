{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/jrtOPRFlNruAI26IEywh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmasonlee/efficiently_testing_etl_pipelines/blob/main/fixing_a_big_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 0.A: Setup Notebook"
      ],
      "metadata": {
        "id": "aqYjZpizVD3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf efficiently_testing_etl_pipelines\n",
        "!git clone https://github.com/jmasonlee/efficiently_testing_etl_pipelines.git\n",
        "!cp -r /content/efficiently_testing_etl_pipelines/src/ .\n",
        "!cp -r /content/efficiently_testing_etl_pipelines/tests/ .\n",
        "!rm -rf efficiently_testing_etl_pipelines\n",
        "!rm -rf tests/diamond_pricing_test*\n",
        "!rm -rf tests/test_helpers/*verification_helpers.py\n",
        "!rm -rf tests/conftest.py\n",
        "!rm -rf sample_data\n"
      ],
      "metadata": {
        "id": "i4KRAp6vTEJm",
        "outputId": "827e5db3-e03b-4c25-d994-5ed3b5b3f5c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'efficiently_testing_etl_pipelines'...\n",
            "remote: Enumerating objects: 587, done.\u001b[K\n",
            "remote: Counting objects: 100% (228/228), done.\u001b[K\n",
            "remote: Compressing objects: 100% (151/151), done.\u001b[K\n",
            "remote: Total 587 (delta 146), reused 111 (delta 70), pack-reused 359\u001b[K\n",
            "Receiving objects: 100% (587/587), 258.76 KiB | 3.32 MiB/s, done.\n",
            "Resolving deltas: 100% (352/352), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "def build_indep_vars(df, independent_vars, categorical_vars=None, keep_intermediate=False, summarizer=True):\n",
        "    check_input(categorical_vars, df, independent_vars)\n",
        "\n",
        "    from pyspark.ml import Pipeline\n",
        "    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "    idx = 'index'\n",
        "    vec = 'vector'\n",
        "    if categorical_vars:\n",
        "        string_indexer = [StringIndexer(inputCol=x,\n",
        "                                        outputCol=f\"{x}_{idx}\")\n",
        "                          for x in categorical_vars]\n",
        "\n",
        "        encoder        = [OneHotEncoder(dropLast=True,\n",
        "                                        inputCol =f'{x}_{idx}',\n",
        "                                        outputCol=f'{x}_{vec}')\n",
        "                          for x in categorical_vars]\n",
        "\n",
        "        independent_vars = ['{}_vector'.format(x) if x in categorical_vars else x for x in independent_vars]\n",
        "    else:\n",
        "        string_indexer, encoder = [], []\n",
        "\n",
        "    assembler = VectorAssembler(inputCols=independent_vars,\n",
        "                                outputCol='indep_vars')\n",
        "    pipeline  = Pipeline(stages=string_indexer+encoder+[assembler])\n",
        "    model = pipeline.fit(df)\n",
        "    df = model.transform(df)\n",
        "\n",
        "    if not keep_intermediate:\n",
        "        fcols = [c for c in df.columns if f'_{idx}' not in c[-3:] and f'_{vec}' not in c[-7:]]\n",
        "        df = df[fcols]\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def check_input(categorical_vars, df, independent_vars):\n",
        "    assert (type(\n",
        "        df) is pyspark.sql.dataframe.DataFrame), 'pypark_glm: A pySpark dataframe is required as the first argument.'\n",
        "    assert (type(\n",
        "        independent_vars) is list), 'pyspark_glm: List of independent variable column names must be the third argument.'\n",
        "    for iv in independent_vars:\n",
        "        assert (type(iv) is str), 'pyspark_glm: Independent variables must be column name strings.'\n",
        "        assert (iv in df.columns), 'pyspark_glm: Independent variable name is not a dataframe column.'\n",
        "    if categorical_vars:\n",
        "        for cv in categorical_vars:\n",
        "            assert (type(cv) is str), 'pyspark_glm: Categorical variables must be column name strings.'\n",
        "            assert (cv in df.columns), 'pyspark_glm: Categorical variable name is not a dataframe column.'\n",
        "            assert (cv in independent_vars), 'pyspark_glm: Categorical variables must be independent variables.'\n"
      ],
      "metadata": {
        "id": "eBvHph1aCJiN"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import DataFrame, Window, Column\n",
        "from pyspark.sql.functions import log, when, mean, col\n",
        "\n",
        "def replace_null(orig: Column, average: Column):\n",
        "    return when(orig.isNull(), average).otherwise(orig)\n",
        "\n",
        "def transform(df: DataFrame) -> DataFrame:\n",
        "\n",
        "    df = df.withColumn('lprice', log('price'))\n",
        "    window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "\n",
        "    df_new = df.withColumn('price', when(df.price.isNull(), moving_avg).otherwise(df.price))\n",
        "    df = df[['id', 'carat', 'clarity', 'color', 'price']]\n",
        "    df = build_indep_vars(df, ['carat', 'clarity', 'color'],\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "22lMaALmCTJm"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 0.B: Setup Tests"
      ],
      "metadata": {
        "id": "5cRRMTtEBYy0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Dependencies\n",
        "\n",
        "For the exercise, we will need some special dependencies to allow us to run lots of tests in a notebook."
      ],
      "metadata": {
        "id": "_h199h_XEAwT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`ipytest` lets us run our tests in a notebook.\n",
        "\n"
      ],
      "metadata": {
        "id": "DVAcSonZmslt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipytest"
      ],
      "metadata": {
        "id": "7v0kaWulDXi-",
        "outputId": "8adcb9c3-a04d-4823-9662-9c6bfaedc408",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipytest in /usr/local/lib/python3.10/dist-packages (0.13.3)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipytest) (7.34.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ipytest) (23.1)\n",
            "Requirement already satisfied: pytest>=5.4 in /usr/local/lib/python3.10/dist-packages (from ipytest) (7.2.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=5.4->ipytest) (23.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=5.4->ipytest) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest>=5.4->ipytest) (1.2.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest>=5.4->ipytest) (1.1.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=5.4->ipytest) (2.0.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (0.18.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (3.0.38)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipytest) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipytest) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipytest) (0.2.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ipytest is what allows us to run our tests in a notebook. This next cell is not needed if you are writing tests in a separate pytest file."
      ],
      "metadata": {
        "id": "3_ILjU8goCNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipytest\n",
        "ipytest.autoconfig()"
      ],
      "metadata": {
        "id": "t7iwGQ4Le-Oe"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are installing `pyspark` because it doesn't come with the base colab environment"
      ],
      "metadata": {
        "id": "HzwfHFGmm2Ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "QNnk84AsmmFQ",
        "outputId": "a3beaa8e-630c-4cfe-9b51-780c1a57bf41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chispa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_EYg-cC1cD5",
        "outputId": "a52386e5-dafe-4dda-9cc0-5e753912a3cf"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chispa in /usr/local/lib/python3.10/dist-packages (0.9.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a local SparkSession\n",
        "\n",
        "Normally spark runs on a bunch of executors in the cloud. Since we want our tests to be able to run on a single dev machine, we make a fixture that gives us a local spark context."
      ],
      "metadata": {
        "id": "V_OJcnSiBgUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "from _pytest.fixtures import FixtureRequest\n",
        "from pyspark import SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "@pytest.fixture(scope=\"session\")\n",
        "def spark(request: FixtureRequest):\n",
        "    conf = (SparkConf()\n",
        "        .setMaster(\"local\")\n",
        "        .setAppName(\"sample_pyspark_testing_starter\"))\n",
        "\n",
        "    spark = SparkSession \\\n",
        "        .builder \\\n",
        "        .config(conf=conf) \\\n",
        "        .getOrCreate()\n",
        "\n",
        "    request.addfinalizer(lambda: spark.stop())\n",
        "    return spark"
      ],
      "metadata": {
        "id": "xXPLpebJ6iI2"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Helpers\n",
        "\n",
        "This is a helper function that retrieves our test output from the expected.json file"
      ],
      "metadata": {
        "id": "actN5s7DCF9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import List, Dict\n",
        "\n",
        "from pyspark.pandas import DataFrame\n",
        "\n",
        "\n",
        "def create_df_from_json(json_file, spark):\n",
        "    return spark.read.option(\"multiline\", \"true\").json(json_file)\n",
        "\n",
        "\n",
        "def data_frame_to_json(df: DataFrame) -> List:\n",
        "    output = [json.loads(item) for item in df.toJSON().collect()]\n",
        "    output.sort(key=lambda item: item[\"id\"])\n",
        "    print(output)\n",
        "    return output\n",
        "\n",
        "def expected_json(name: str) -> Dict:\n",
        "    with open(f\"tests/fixtures/{name}\") as f:\n",
        "        return json.loads(f.read())"
      ],
      "metadata": {
        "id": "VO2-3px25xEl"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 0.C: Run The Test"
      ],
      "metadata": {
        "id": "MjwHttFB5TB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def test_will_do_the_right_thing(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "    assert data_frame_to_json(actual_df) == expected_json(\"expected.json\")"
      ],
      "metadata": {
        "id": "lH1x9ZOi58X7",
        "outputId": "3cdc7802-3939-444f-b6d3-10dd9460b6a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Setup For the Saff Squeeze\n",
        "\n",
        "- [ ] Update the test so that it actually fails for the right reasons. Change `\"expected.json\"` to `\"expected_correct.json\"`\n",
        "- [ ] Run the test. It should fail.\n",
        "- [ ] Duplicate the test you want to change. Copy and paste it in the cell below, so that you have two copies of the same test.\n",
        "- [ ] Name the new test something useful. Since we want to make sure we are correctly calculating the new price, I am calling my new test `test_imputes_average_price_based_on_color_cut_and_clarity`"
      ],
      "metadata": {
        "id": "95eTfqjbZfGV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's get ready to improve the test.\n",
        "\n",
        "**our bug**: Diamonds of the same cut and clarity are influencing the calculated price of diamonds with a different color. Only diamonds with the same cut, clarity _**and color**_ should be influencing the calculated price for diamonds with a null price.\n",
        "\n",
        "**expected behaviour**:\n",
        "An unpriced diamond with cut=Good, color=D and clarity=VVS1 in a dataset with other diamonds of the same cut, clarity and color all priced at 2690.0, will have it's price set to match the average of all the prices for diamonds of the same cut, clarity and color - or 2690.0.\n",
        "\n",
        "\n",
        "\n",
        "- [ ] Change the test to check for the behaviour we want.\n",
        "There is a second json file (`expected_correct.json`) where the expected price for the unpriced diamond has been updated to the correct value. Use that file name as the argument passed to `expected_json`\n",
        "- [ ] Run the test. It should fail.\n",
        "- [ ] Duplicate the test. Now you should have two copies of the same test.\n",
        "One copy will stay the same, so we can make sure that nothing is broken. The second copy is what we will change in the next steps.\n",
        "- [ ] Rename the test.\n",
        "Pick a name that tells you what behaviour you are verifying with the test you are using for the Saff Squeeze. I chose `test_null_price_is_replaced_based_on_cut_clarity_and_color`, but names are hard. You might be able to think of a better one :-)\n",
        "- [ ] Run the tests. They should both fail because our diamond is being returned with a price of 2460.0, when we expect 2690.0"
      ],
      "metadata": {
        "id": "oDLkPTvpnKGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def test_will_do_the_right_thing(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "    assert data_frame_to_json(actual_df) == expected_json(\"expected.json\")"
      ],
      "metadata": {
        "outputId": "3cdc7802-3939-444f-b6d3-10dd9460b6a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VKLXAMic975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Make The Assert Specific"
      ],
      "metadata": {
        "id": "cbCuKHDpso8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Right now, our test compares everything in the output dataframe to everything in a large json file. That's a lot of rows to compare and the assert is wrong anyways!\n",
        "\n",
        "Let's make this test assert on the thing we actually care about - the output price of the diamond!"
      ],
      "metadata": {
        "id": "X-xfpXMwstwN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's make our assert specific!\n",
        "### We can do the next step in one of 3 ways:\n",
        "#### With Chispa\n",
        "- [ ] Add these imports to the top of the cell, below the `%%ipytest -qq` line:  \n",
        "`from chispa import assert_column_equality`  \n",
        "`from pySpark.sql.functions import lit`\n",
        "- [ ] Filter the dataframe for the unique id of the diamond we care about:  \n",
        "`actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')`\n",
        "- [ ] Create a new column in our dataframe that contains our expected price:  \n",
        "`actual_df=actual_df.withColumn('expected_price', lit(2690.0))`\n",
        "- [ ] Assert the value in the price column matches the value we want:  \n",
        "`assert_column_equality(actual_df, 'price', 'expected_price')`\n"
      ],
      "metadata": {
        "id": "jz3ygb6GxcYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n"
      ],
      "metadata": {
        "outputId": "29eea17c-b32a-4e20-8a58-8d0ffd614fd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiwYRKD0yXIW"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With Pandas\n",
        "- [ ] import pandas:  \n",
        "`import pandas as pd`\n",
        "- [ ] Filter the dataframe for the unique id of the diamond we care about:  \n",
        "  `actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')`\n",
        "- [ ] Create your expected dataframe using Pandas:  \n",
        " `expected = pd.DataFrame(({'id': [\"DI-26-null-price\"], 'price':[2690.0] }))`\n",
        "- [ ] Select the column you care about:  \n",
        "  `actual_df=actual_df.select(['id', 'price'])\n",
        "- [ ] Assert for dataframe equality using pandas:  \n",
        "  `pd.testing.assert_frame_equal(actual_df, expected)`"
      ],
      "metadata": {
        "id": "wW0OfrWo8Qn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n"
      ],
      "metadata": {
        "outputId": "59fcd2dc-fcf1-4d79-cca8-f1aaa43a0c42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a_ORvhl9CAd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Assert on properties\n",
        "\n",
        "- [ ] Filter the dataframe for the unique id of the diamond we care about:  \n",
        "  `actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')`\n",
        "- [ ] Convert your dataframe to JSON:  \n",
        "`actual_df_json = data_frame_to_json(actual_df)`\n",
        "- [ ] Assert the price property of the first object matches your expected price:  \n",
        "`assert actual_df_json[0]['price'] == 2690.0`"
      ],
      "metadata": {
        "id": "lD-3MVVv9D9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "\n"
      ],
      "metadata": {
        "outputId": "ef5afbc8-7590-4119-e1c6-dd53152f85cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55eVJ0Ug9Pif"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Reduce Duplicate Coverage and Fix the Bug\n",
        "\n",
        "Right now, our test is running the entire transform function. Because there are multiple tests in `diamonds.json`, each test is running the same large block of code over and over again."
      ],
      "metadata": {
        "id": "sw4mvQYw5pkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 3.A: Prep"
      ],
      "metadata": {
        "id": "8kumyMxuNFY_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions\n",
        "Let's get ready to reduce the duplicate coverage.\n",
        "\n",
        "- [ ] Run the test. It should be failing.\n",
        "- [ ] Replace the line that calls the transform function with the body of the transform function.  \n",
        "- [ ] Rename `df` to `actual_df`, except the first place it's used. (Find and Replace is `ctrl-m-h`).  \n",
        "This line:  \n",
        "`df = df.withColumn('lprice', log('price'))`  \n",
        "should become  \n",
        "`actual_df = diamonds_df.withColumn('lprice', log('price'))`\n",
        "- [ ] Change your assert code so that it is testing _for_ the bug.\n",
        "```\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(2690.0))\n",
        "```\n",
        "becomes\n",
        "```\n",
        "  actual_df=actual_df.withColumn('expected_price', lit(2460.0))\n",
        "```\n",
        "- [ ] Run the test. It should still be failing for the same reasons.\n",
        "- [ ] Extract your assert code into a one-line helper function:\n",
        "```\n",
        "def assert_diamond_has_expected_price(actual_df):\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(2460.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "```\n",
        "- [ ] Run the test. It should still be failing for the same reasons."
      ],
      "metadata": {
        "id": "-2pcPdIhf6ad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise"
      ],
      "metadata": {
        "id": "57xFbUQaoIaq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Code\n",
        "\n",
        "Execute both of these cells so that they are available in our test cell\n"
      ],
      "metadata": {
        "id": "0ze_hB2VCmC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The `transform` Function"
      ],
      "metadata": {
        "id": "YgzlhOgV-LJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import DataFrame, Window, Column\n",
        "from pyspark.sql.functions import log, when, mean, col\n",
        "\n",
        "def replace_null(orig: Column, average: Column):\n",
        "    return when(orig.isNull(), average).otherwise(orig)\n",
        "\n",
        "def transform(df: DataFrame) -> DataFrame:\n",
        "\n",
        "    df = df.withColumn('lprice', log('price'))\n",
        "    window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "\n",
        "    df_new = df.withColumn('price', when(df.price.isNull(), moving_avg).otherwise(df.price))\n",
        "    df = df[['id', 'carat', 'clarity', 'color', 'price']]\n",
        "    df = build_indep_vars(df, ['carat', 'clarity', 'color'],\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "EqUboG2Y-HZE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Test"
      ],
      "metadata": {
        "id": "DR41JwrwDPhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def test_prep_for_linear_regression(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(2690.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')"
      ],
      "metadata": {
        "outputId": "ac28cc35-5113-4aa0-e247-dbfcac799b3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ci_qnCgB57k9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mF\u001b[0m\u001b[31m                                                                                            [100%]\u001b[0m\n",
            "============================================= FAILURES =============================================\n",
            "\u001b[31m\u001b[1m_________________________________ test_prep_for_linear_regression __________________________________\u001b[0m\n",
            "\n",
            "spark = <pyspark.sql.session.SparkSession object at 0x7fd38587cb50>\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_prep_for_linear_regression\u001b[39;49;00m(spark: SparkSession):\u001b[90m\u001b[39;49;00m\n",
            "        diamonds_df = create_df_from_json(\u001b[33m\"\u001b[39;49;00m\u001b[33mtests/fixtures/diamonds.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, spark)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        actual_df = transform(diamonds_df)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        actual_df=actual_df.filter(actual_df.id == \u001b[33m'\u001b[39;49;00m\u001b[33mDI-26-null-price\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        actual_df=actual_df.withColumn(\u001b[33m'\u001b[39;49;00m\u001b[33mexpected_price\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, lit(\u001b[94m2960.0\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            ">       assert_column_equality(actual_df, \u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mexpected_price\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31m<ipython-input-14-37d07c01815e>\u001b[0m:15: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "df = DataFrame[id: string, carat: double, clarity: string, color: string, price: double, clarity_index: double, color_index: double, indep_vars: vector, expected_price: double]\n",
            "col_name1 = 'price', col_name2 = 'expected_price'\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92massert_column_equality\u001b[39;49;00m(df, col_name1, col_name2):\u001b[90m\u001b[39;49;00m\n",
            "        elements = df.select(col_name1, col_name2).collect()\u001b[90m\u001b[39;49;00m\n",
            "        colName1Elements = \u001b[96mlist\u001b[39;49;00m(\u001b[96mmap\u001b[39;49;00m(\u001b[94mlambda\u001b[39;49;00m x: x[\u001b[94m0\u001b[39;49;00m], elements))\u001b[90m\u001b[39;49;00m\n",
            "        colName2Elements = \u001b[96mlist\u001b[39;49;00m(\u001b[96mmap\u001b[39;49;00m(\u001b[94mlambda\u001b[39;49;00m x: x[\u001b[94m1\u001b[39;49;00m], elements))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m colName1Elements != colName2Elements:\u001b[90m\u001b[39;49;00m\n",
            "            zipped = \u001b[96mlist\u001b[39;49;00m(\u001b[96mzip\u001b[39;49;00m(colName1Elements, colName2Elements))\u001b[90m\u001b[39;49;00m\n",
            "            t = PrettyTable([col_name1, col_name2])\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m elements \u001b[95min\u001b[39;49;00m zipped:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m elements[\u001b[94m0\u001b[39;49;00m] == elements[\u001b[94m1\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
            "                    first = bcolors.LightBlue + \u001b[96mstr\u001b[39;49;00m(elements[\u001b[94m0\u001b[39;49;00m]) + bcolors.LightRed\u001b[90m\u001b[39;49;00m\n",
            "                    second = bcolors.LightBlue + \u001b[96mstr\u001b[39;49;00m(elements[\u001b[94m1\u001b[39;49;00m]) + bcolors.LightRed\u001b[90m\u001b[39;49;00m\n",
            "                    t.add_row([first, second])\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    t.add_row([\u001b[96mstr\u001b[39;49;00m(elements[\u001b[94m0\u001b[39;49;00m]), \u001b[96mstr\u001b[39;49;00m(elements[\u001b[94m1\u001b[39;49;00m])])\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mraise\u001b[39;49;00m ColumnsNotEqualError(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m + t.get_string())\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           chispa.column_comparer.ColumnsNotEqualError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           +--------+----------------+\u001b[0m\n",
            "\u001b[1m\u001b[31mE           | price  | expected_price |\u001b[0m\n",
            "\u001b[1m\u001b[31mE           +--------+----------------+\u001b[0m\n",
            "\u001b[1m\u001b[31mE           | 2460.0 |     2960.0     |\u001b[0m\n",
            "\u001b[1m\u001b[31mE           +--------+----------------+\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.10/dist-packages/chispa/column_comparer.py\u001b[0m:24: ColumnsNotEqualError\n",
            "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m t_dd33edcfd11b45fcb600db307d7bac98.py::\u001b[1mtest_prep_for_linear_regression\u001b[0m - chispa.column_comparer.ColumnsNotEqualError: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The original test\n",
        "\n"
      ],
      "metadata": {
        "id": "ojU7wLaKdbBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def test_will_do_the_right_thing(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "    assert data_frame_to_json(actual_df) == expected_json(\"expected_correct.json\")"
      ],
      "metadata": {
        "id": "S5228csId2CS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3.B Squeeze the bottom!\n"
      ],
      "metadata": {
        "id": "5oBE2ZEAF2E2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Instructions\n",
        "**our bug**: Diamonds of the same cut and clarity are influencing the calculated price of diamonds with a different color. Only diamonds with the same cut, clarity and color should be influencing the calculated price for diamonds with a null price.\n",
        "\n",
        "**Squeeze the bottom until you find the bug**\n",
        "- [ ] Move your assert up one line at a time.  \n",
        "- [ ] After each move, run your tests.  \n",
        "- [ ] If it fails, figure out why it's failing.(You may need to rename columns in the assert)\n",
        "- [ ]If the test passes, the line wasn't important for the bug you wanted to catch. Delete it.\n",
        "- [ ] Continue until you find the source of the bug"
      ],
      "metadata": {
        "id": "PhriAy0jfsTj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise"
      ],
      "metadata": {
        "id": "SyOFZzKVokvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Code"
      ],
      "metadata": {
        "id": "u2EHWBjMetva"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The `transform` Function"
      ],
      "metadata": {
        "id": "9Yne491Uetvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import DataFrame, Window, Column\n",
        "from pyspark.sql.functions import log, when, mean, col\n",
        "\n",
        "def replace_null(orig: Column, average: Column):\n",
        "    return when(orig.isNull(), average).otherwise(orig)\n",
        "\n",
        "def transform(df: DataFrame) -> DataFrame:\n",
        "\n",
        "    df = df.withColumn('lprice', log('price'))\n",
        "    window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "\n",
        "    df_new = df.withColumn('price', when(df.price.isNull(), moving_avg).otherwise(df.price))\n",
        "    df = df[['id', 'carat', 'clarity', 'color', 'price']]\n",
        "    df = build_indep_vars(df, ['carat', 'clarity', 'color'],\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "-EhWDEgLetvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Test"
      ],
      "metadata": {
        "id": "441Jq5Ude3n7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession, DataFrame, Window, Column\n",
        "from pyspark.sql.functions import lit, log, when, mean, col\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df):\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(2460.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def test_prep_for_linear_regression(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = diamonds_df.withColumn('lprice', log('price'))\n",
        "    window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(actual_df['price']).over(window)\n",
        "    actual_df = actual_df.withColumn('moving_avg', moving_avg)\n",
        "\n",
        "    actual_df = actual_df.withColumn('price', replace_null(col('price'), col('moving_avg')))\n",
        "    actual_df = actual_df[['id', 'carat', 'clarity', 'color', 'price']]\n",
        "    actual_df = build_indep_vars(actual_df, ['carat', 'clarity', 'color'],\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "outputId": "dd8f563d-241c-4681-e2f2-6a99d54ade0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFv4b_9xFw-t"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Original Test"
      ],
      "metadata": {
        "id": "MMVXW7E7gNBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def test_will_do_the_right_thing(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "    assert data_frame_to_json(actual_df) == expected_json(\"expected_correct.json\")"
      ],
      "metadata": {
        "id": "S50HLHD9gALp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3.C Let's fix the bug!\n"
      ],
      "metadata": {
        "id": "H3kdrtuBEbcC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions\n",
        "\n",
        "**Our Bug**: Diamonds of the same cut and clarity are influencing the calculated price of diamonds with a different color. Only diamonds with the same cut, clarity and color should be influencing the calculated price for diamonds with a null price.\n",
        "\n",
        "**Our Desired Behaviour**:  \n",
        "The input diamond with these properties:\n",
        "- id: `\"DI-26-null-price\"`\n",
        "- cut: `\"Good\"`\n",
        "- color: `\"D\"`\n",
        "- clarity: `\"VVS1\"`\n",
        "- price: `null`\n",
        "\n",
        "Should be output with a price of `2690.0` - the average price of the other diamonds with `cut=\"Good\"`, `clarity=\"VVS1\"` and `color=\"D\"`\n",
        "\n",
        "**Fix the bug**\n",
        "- [ ] Update your test so that it checks for the good behaviour.  \n",
        "Replace the expected price on this line with `2690.0`:  \n",
        "```\n",
        "actual_df=actual_df.withColumn('expected_price', lit(2460.0))\n",
        "```\n",
        "- [ ] Run your test. It should fail with a `columnsNotEqualError`:  \n",
        "```\n",
        "E           chispa.column_comparer.ColumnsNotEqualError:\n",
        "E           +------------+----------------+\n",
        "E           | moving_avg | expected_price |\n",
        "E           +------------+----------------+\n",
        "E           |   2460.0   |     2690.0     |\n",
        "E           +------------+----------------+\n",
        "```\n",
        "- [ ] Fix the code _in your test_ so that the bug is gone.\n",
        "- [ ] Run your test. It should pass.\n",
        "- [ ] The behaviour belongs to a group of lines working together. Extract them into a method.  \n",
        "These lines can't be separated:  \n",
        "```\n",
        "    window = Window.partitionBy('cut', 'clarity', 'color').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(actual_df['price']).over(window)\n",
        "    actual_df = actual_df.withColumn('moving_avg', moving_avg)\n",
        "```  \n",
        "Use them to make a method:\n",
        "```\n",
        "def calculate_avg_price_for_similar_diamonds(diamonds_df: DataFrame) -> DataFrame:\n",
        "      window = Window.partitionBy('cut', 'clarity', 'color').orderBy('price').rowsBetween(-3, 3)\n",
        "      moving_avg = mean(diamonds_df['price']).over(window)\n",
        "      diamonds_df = diamonds_df.withColumn('moving_avg', moving_avg)\n",
        "      return diamonds_df\n",
        "```\n",
        "Replace those lines with a call to the new method in your test:  \n",
        "```\n",
        "actual_df = calculate_avg_price_for_similar_diamonds(actual_df)\n",
        "```\n",
        "- [ ] Move the new method out of your test and into the transform code.\n",
        "- [ ] Replace the 3 lines in your transform code with the new method call.\n",
        "- [ ] Run your test. It should pass.\n",
        "- [ ] Run the copy of your original large test. It should also pass."
      ],
      "metadata": {
        "id": "mL_lKfL-fdgh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise"
      ],
      "metadata": {
        "id": "mNb7r0copJ3X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Code"
      ],
      "metadata": {
        "id": "69ahdJEigJD7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The `transform` Function"
      ],
      "metadata": {
        "id": "aS6CsJ4IgJEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import DataFrame, Window, Column\n",
        "from pyspark.sql.functions import log, when, mean, col\n",
        "\n",
        "def replace_null(orig: Column, average: Column):\n",
        "    return when(orig.isNull(), average).otherwise(orig)\n",
        "\n",
        "def transform(df: DataFrame) -> DataFrame:\n",
        "\n",
        "    df = df.withColumn('lprice', log('price'))\n",
        "    window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "\n",
        "    df_new = df.withColumn('price', when(df.price.isNull(), moving_avg).otherwise(df.price))\n",
        "    df = df[['id', 'carat', 'clarity', 'color', 'price']]\n",
        "    df = build_indep_vars(df, ['carat', 'clarity', 'color'],\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "JkEX3fPYgJEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Test"
      ],
      "metadata": {
        "id": "6ChzdpcnfiMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession, DataFrame, Window, Column\n",
        "from pyspark.sql.functions import lit, log, when, mean, col\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df):\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(2460.0))\n",
        "    assert_column_equality(actual_df, 'moving_avg', 'expected_price')\n",
        "\n",
        "def test_prep_for_linear_regression(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = diamonds_df.withColumn('lprice', log('price'))\n",
        "    window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(actual_df['price']).over(window)\n",
        "    actual_df = actual_df.withColumn('moving_avg', moving_avg)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "outputId": "0adbd272-c0a5-4e4d-d539-03bacab36006",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsPa000oHob3"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}