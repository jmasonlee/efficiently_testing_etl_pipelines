{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNX/1BHUrZ+6IaxzYnXUGN/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmasonlee/efficiently_testing_etl_pipelines/blob/main/fixing_a_big_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 0.A: Setup Notebook"
      ],
      "metadata": {
        "id": "aqYjZpizVD3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf efficiently_testing_etl_pipelines\n",
        "!git clone https://github.com/jmasonlee/efficiently_testing_etl_pipelines.git\n",
        "!cp -r /content/efficiently_testing_etl_pipelines/src/ .\n",
        "!cp -r /content/efficiently_testing_etl_pipelines/tests/ .\n",
        "!rm -rf efficiently_testing_etl_pipelines\n",
        "!rm -rf tests/diamond_pricing_test*\n",
        "!rm -rf tests/test_helpers/*verification_helpers.py\n",
        "!rm -rf tests/conftest.py\n",
        "!rm -rf sample_data\n"
      ],
      "metadata": {
        "id": "i4KRAp6vTEJm",
        "outputId": "8462e222-1a3e-45a8-bf74-0c8be3c7c3b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'efficiently_testing_etl_pipelines'...\n",
            "remote: Enumerating objects: 664, done.\u001b[K\n",
            "remote: Counting objects: 100% (305/305), done.\u001b[K\n",
            "remote: Compressing objects: 100% (136/136), done.\u001b[K\n",
            "remote: Total 664 (delta 196), reused 259 (delta 162), pack-reused 359\u001b[K\n",
            "Receiving objects: 100% (664/664), 287.11 KiB | 3.99 MiB/s, done.\n",
            "Resolving deltas: 100% (402/402), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 0.B: Setup Tests"
      ],
      "metadata": {
        "id": "5cRRMTtEBYy0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Dependencies\n",
        "\n",
        "For the exercise, we will need some special dependencies to allow us to run lots of tests in a notebook."
      ],
      "metadata": {
        "id": "_h199h_XEAwT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`ipytest` lets us run our tests in a notebook.\n",
        "\n"
      ],
      "metadata": {
        "id": "DVAcSonZmslt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipytest"
      ],
      "metadata": {
        "id": "7v0kaWulDXi-",
        "outputId": "a230bc92-98b3-4ef3-aaf2-aeb5bb316ccc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipytest\n",
            "  Downloading ipytest-0.13.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipytest) (7.34.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ipytest) (23.1)\n",
            "Requirement already satisfied: pytest>=5.4 in /usr/local/lib/python3.10/dist-packages (from ipytest) (7.2.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=5.4->ipytest) (23.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=5.4->ipytest) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest>=5.4->ipytest) (1.2.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest>=5.4->ipytest) (1.1.2)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=5.4->ipytest) (2.0.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->ipytest)\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipytest) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipytest) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipytest) (0.2.6)\n",
            "Installing collected packages: jedi, ipytest\n",
            "Successfully installed ipytest-0.13.3 jedi-0.18.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ipytest is what allows us to run our tests in a notebook. This next cell is not needed if you are writing tests in a separate pytest file."
      ],
      "metadata": {
        "id": "3_ILjU8goCNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipytest\n",
        "ipytest.autoconfig()"
      ],
      "metadata": {
        "id": "t7iwGQ4Le-Oe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are installing `pyspark` because it doesn't come with the base colab environment"
      ],
      "metadata": {
        "id": "HzwfHFGmm2Ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "QNnk84AsmmFQ",
        "outputId": "c44ba2da-d413-4589-853d-e35513b95aa4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285398 sha256=95b0199d2c831f775e2fd026d3048c454d35b05cbac25d03b8e17dd2fb36560f\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chispa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_EYg-cC1cD5",
        "outputId": "d9a5c5e1-e683-4fb9-ab83-88b614fa069d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chispa\n",
            "  Downloading chispa-0.9.2-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: chispa\n",
            "Successfully installed chispa-0.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a local SparkSession\n",
        "\n",
        "Normally spark runs on a bunch of executors in the cloud. Since we want our tests to be able to run on a single dev machine, we make a fixture that gives us a local spark context."
      ],
      "metadata": {
        "id": "V_OJcnSiBgUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "from _pytest.fixtures import FixtureRequest\n",
        "from pyspark import SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "@pytest.fixture(scope=\"session\")\n",
        "def spark(request: FixtureRequest):\n",
        "    conf = (SparkConf()\n",
        "        .setMaster(\"local\")\n",
        "        .setAppName(\"sample_pyspark_testing_starter\"))\n",
        "\n",
        "    spark = SparkSession \\\n",
        "        .builder \\\n",
        "        .config(conf=conf) \\\n",
        "        .getOrCreate()\n",
        "\n",
        "    request.addfinalizer(lambda: spark.stop())\n",
        "    return spark"
      ],
      "metadata": {
        "id": "xXPLpebJ6iI2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Helpers\n",
        "\n",
        "This is a helper function that retrieves our test output from the expected.json file"
      ],
      "metadata": {
        "id": "actN5s7DCF9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import List, Dict\n",
        "\n",
        "from pyspark.pandas import DataFrame\n",
        "\n",
        "\n",
        "def create_df_from_json(json_file, spark):\n",
        "    return spark.read.option(\"multiline\", \"true\").json(json_file)\n",
        "\n",
        "\n",
        "def data_frame_to_json(df: DataFrame) -> List:\n",
        "    output = [json.loads(item) for item in df.toJSON().collect()]\n",
        "    output.sort(key=lambda item: item[\"id\"])\n",
        "    print(output)\n",
        "    return output\n",
        "\n",
        "def expected_json(name: str) -> Dict:\n",
        "    with open(f\"tests/fixtures/{name}\") as f:\n",
        "        return json.loads(f.read())"
      ],
      "metadata": {
        "id": "VO2-3px25xEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de9106b7-64ad-41dc-beaf-4f5ecb11de6a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "def build_indep_vars(df, independent_vars, categorical_vars=None, keep_intermediate=False, summarizer=True):\n",
        "    check_input(categorical_vars, df, independent_vars)\n",
        "\n",
        "    from pyspark.ml import Pipeline\n",
        "    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "    idx = 'index'\n",
        "    vec = 'vector'\n",
        "    if categorical_vars:\n",
        "        string_indexer = [StringIndexer(inputCol=x,\n",
        "                                        outputCol=f\"{x}_{idx}\")\n",
        "                          for x in categorical_vars]\n",
        "\n",
        "        encoder        = [OneHotEncoder(dropLast=True,\n",
        "                                        inputCol =f'{x}_{idx}',\n",
        "                                        outputCol=f'{x}_{vec}')\n",
        "                          for x in categorical_vars]\n",
        "\n",
        "        independent_vars = ['{}_vector'.format(x) if x in categorical_vars else x for x in independent_vars]\n",
        "    else:\n",
        "        string_indexer, encoder = [], []\n",
        "\n",
        "    assembler = VectorAssembler(inputCols=independent_vars,\n",
        "                                outputCol='indep_vars')\n",
        "    pipeline  = Pipeline(stages=string_indexer+encoder+[assembler])\n",
        "    model = pipeline.fit(df)\n",
        "    df = model.transform(df)\n",
        "\n",
        "    if not keep_intermediate:\n",
        "        fcols = [c for c in df.columns if f'_{idx}' not in c[-3:] and f'_{vec}' not in c[-7:]]\n",
        "        df = df[fcols]\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def check_input(categorical_vars, df, independent_vars):\n",
        "    assert (type(\n",
        "        df) is pyspark.sql.dataframe.DataFrame), 'pypark_glm: A pySpark dataframe is required as the first argument.'\n",
        "    assert (type(\n",
        "        independent_vars) is list), 'pyspark_glm: List of independent variable column names must be the third argument.'\n",
        "    for iv in independent_vars:\n",
        "        assert (type(iv) is str), 'pyspark_glm: Independent variables must be column name strings.'\n",
        "        assert (iv in df.columns), 'pyspark_glm: Independent variable name is not a dataframe column.'\n",
        "    if categorical_vars:\n",
        "        for cv in categorical_vars:\n",
        "            assert (type(cv) is str), 'pyspark_glm: Categorical variables must be column name strings.'\n",
        "            assert (cv in df.columns), 'pyspark_glm: Categorical variable name is not a dataframe column.'\n",
        "            assert (cv in independent_vars), 'pyspark_glm: Categorical variables must be independent variables.'\n"
      ],
      "metadata": {
        "id": "eBvHph1aCJiN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import DataFrame, Window, Column\n",
        "from pyspark.sql.functions import log, when, mean, col\n",
        "\n",
        "def replace_null(orig: Column, average: Column):\n",
        "    return when(orig.isNull(), average).otherwise(orig)\n",
        "\n",
        "def transform(df: DataFrame) -> DataFrame:\n",
        "\n",
        "    df = df.withColumn('lprice', log('price'))\n",
        "    window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    df = df[['id', 'carat', 'clarity', 'color', 'price']]\n",
        "    df = build_indep_vars(df, ['carat', 'clarity', 'color'],\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "22lMaALmCTJm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 0.C: Run The Test"
      ],
      "metadata": {
        "id": "MjwHttFB5TB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def test_will_do_the_right_thing(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "    assert data_frame_to_json(actual_df) == expected_json(\"expected.json\")"
      ],
      "metadata": {
        "id": "lH1x9ZOi58X7",
        "outputId": "e6b75d09-700c-43d4-b128-bbc8c5e1c13c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Setup For the Saff Squeeze"
      ],
      "metadata": {
        "id": "95eTfqjbZfGV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instructions\n",
        "Let's get ready to improve the test.\n",
        "\n",
        "**our bug**: Diamonds of the same cut and clarity are influencing the calculated price of diamonds with a different color. Only diamonds with the same cut, clarity _**and color**_ should be influencing the calculated price for diamonds with a null price.\n",
        "\n",
        "**expected behaviour**:\n",
        "An unpriced diamond with cut=Good, color=D and clarity=VVS1 in a dataset with other diamonds of the same cut, clarity and color all priced at 3333.0, will have it's price set to match the average of all the prices for diamonds of the same cut, clarity and color - or 3333.0.\n",
        "\n",
        "\n",
        "\n",
        "- [ ] Change the test to check for the behaviour we want.\n",
        "There is a second json file (`expected_correct.json`) where the expected price for the unpriced diamond has been updated to the correct value. Use that file name as the argument passed to `expected_json`\n",
        "- [ ] Run the test. It should fail.\n",
        "- [ ] Duplicate the test. Now you should have two copies of the same test.\n",
        "One copy will stay the same, so we can make sure that nothing is broken. The second copy is what we will change in the next steps.\n",
        "- [ ] Rename the test.\n",
        "Pick a name that tells you what behaviour you are verifying with the test you are using for the Saff Squeeze. I chose `test_null_price_is_replaced_based_on_cut_clarity_and_color`, but names are hard. You might be able to think of a better one :-)\n",
        "- [ ] Run the tests. They should both fail because our diamond is being returned with a price of 2460.0, when we expect 3333.0"
      ],
      "metadata": {
        "id": "oDLkPTvpnKGS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise"
      ],
      "metadata": {
        "id": "Wv_k7gBEvpm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def test_will_do_the_right_thing(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "    assert data_frame_to_json(actual_df) == expected_json(\"expected.json\")"
      ],
      "metadata": {
        "outputId": "3cdc7802-3939-444f-b6d3-10dd9460b6a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VKLXAMic975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Make The Assert Specific"
      ],
      "metadata": {
        "id": "cbCuKHDpso8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Right now, our test compares everything in the output dataframe to everything in a large json file. That's a lot of rows to compare and the assert is wrong anyways!\n",
        "\n",
        "Let's make this test assert on the thing we actually care about - the output price of the diamond!"
      ],
      "metadata": {
        "id": "X-xfpXMwstwN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instructions - Chispa\n",
        "\n",
        "#### With Chispa\n",
        "- [ ] Add these imports to the top of the cell, below the `%%ipytest -qq` line:  \n",
        "`from chispa import assert_column_equality`  \n",
        "`from pySpark.sql.functions import lit`\n",
        "- [ ] Filter the dataframe for the unique id of the diamond we care about:  \n",
        "`actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')`\n",
        "- [ ] Create a new column in our dataframe that contains our expected price:  \n",
        "`actual_df=actual_df.withColumn('expected_price', lit(3333.0))`\n",
        "- [ ] Assert the value in the price column matches the value we want:  \n",
        "`assert_column_equality(actual_df, 'price', 'expected_price')`\n"
      ],
      "metadata": {
        "id": "jz3ygb6GxcYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise - Chispa"
      ],
      "metadata": {
        "id": "vYiG_Qgtv1bs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n"
      ],
      "metadata": {
        "outputId": "4c816535-dd6e-417d-9aa5-61ed763d8cf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiwYRKD0yXIW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions - Pandas\n",
        "- [ ] import pandas:  \n",
        "`import pandas as pd`\n",
        "- [ ] Filter the dataframe for the unique id of the diamond we care about:  \n",
        "  `actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')`\n",
        "- [ ] Create your expected dataframe using Pandas:  \n",
        " `expected = pd.DataFrame(({'id': [\"DI-26-null-price\"], 'price':[3333.0] }))`\n",
        "- [ ] Select the column you care about:  \n",
        "  `actual_df=actual_df.select(['id', 'price'])\n",
        "- [ ] Assert for dataframe equality using pandas:  \n",
        "  `pd.testing.assert_frame_equal(actual_df, expected)`"
      ],
      "metadata": {
        "id": "wW0OfrWo8Qn4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise - Pandas"
      ],
      "metadata": {
        "id": "TM4QCxCZwEbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n"
      ],
      "metadata": {
        "outputId": "59fcd2dc-fcf1-4d79-cca8-f1aaa43a0c42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a_ORvhl9CAd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions - JSON properties\n",
        "\n",
        "- [ ] Filter the dataframe for the unique id of the diamond we care about:  \n",
        "  `actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')`\n",
        "- [ ] Convert your dataframe to JSON:  \n",
        "`actual_df_json = data_frame_to_json(actual_df)`\n",
        "- [ ] Assert the price property of the first object matches your expected price:  \n",
        "`assert actual_df_json[0]['price'] == 3333.0`"
      ],
      "metadata": {
        "id": "lD-3MVVv9D9d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise - JSON properties"
      ],
      "metadata": {
        "id": "F0GvaGLEwMZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "\n"
      ],
      "metadata": {
        "outputId": "ef5afbc8-7590-4119-e1c6-dd53152f85cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55eVJ0Ug9Pif"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Reduce Duplicate Coverage and Fix the Bug\n",
        "\n",
        "Right now, our test is running the entire transform function. Because there are multiple tests in `diamonds.json`, each test is running the same large block of code over and over again."
      ],
      "metadata": {
        "id": "sw4mvQYw5pkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 3.A: Prep"
      ],
      "metadata": {
        "id": "8kumyMxuNFY_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions\n",
        "Let's get ready to reduce the duplicate coverage.\n",
        "\n",
        "#### 1. Put the transform function where you can work with it\n",
        "- [ ] Run the test. It should be failing.\n",
        "- [ ] Replace the call to the transform function with the body of that function.\n",
        "- [ ] Change the last line of the function body to assign to `actual_df` instead of `df`\n",
        "```\n",
        "df = build_indep_vars(df, ['carat', 'clarity', 'color'],\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "```\n",
        "becomes\n",
        "```\n",
        "actual_df = build_indep_vars(df, ['carat', 'clarity', 'color'],\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "```\n",
        "- [ ] Change the first line of the function body to read from `diamonds_df` instead of `df`\n",
        "```\n",
        " df = df.withColumn('lprice', log('price'))\n",
        "```\n",
        "becomes\n",
        "```\n",
        " df = diamonds_df.withColumn('lprice', log('price'))\n",
        "```\n",
        "- [ ] Run the test. It should still be failing for the same reasons.\n",
        "\n",
        "#### 2. Test FOR the bug\n",
        "- [ ] Change your assert code so that it is testing _for_ the bug.\n",
        "```\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "```\n",
        "becomes\n",
        "```\n",
        "  actual_df=actual_df.withColumn('expected_price', lit(2460.0))\n",
        "```\n",
        "- [ ] Run the test. It should pass.\n",
        "\n",
        "#### 3. Make the assert easier to work with\n",
        "- [ ] Extract your assert code into a one-line helper function:\n",
        "```\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(2460.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "```\n",
        "- [ ] Run the test. It should pass."
      ],
      "metadata": {
        "id": "-2pcPdIhf6ad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise"
      ],
      "metadata": {
        "id": "57xFbUQaoIaq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Code"
      ],
      "metadata": {
        "id": "0ze_hB2VCmC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The `transform` Function"
      ],
      "metadata": {
        "id": "YgzlhOgV-LJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import DataFrame, Window, Column\n",
        "from pyspark.sql.functions import log, when, mean, col\n",
        "\n",
        "def transform(df: DataFrame) -> DataFrame:\n",
        "# The body of the transform function STARTS HERE\n",
        "    df = df.withColumn('lprice', log('price'))  #<-- In the test, this line should be: df = diamonds_df.withColumn('lprice', log('price'))\n",
        "    window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    df = df[['id', 'carat', 'clarity', 'color', 'price']]\n",
        "    df = build_indep_vars(df, ['carat', 'clarity', 'color'], #<-- In the test, this line should be: actual_df = build_indep_vars(df, ['carat', 'clarity', 'color']\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "# The body of the transform function ENDS HERE\n",
        "    return df"
      ],
      "metadata": {
        "id": "EqUboG2Y-HZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Test"
      ],
      "metadata": {
        "id": "DR41JwrwDPhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def test_prep_for_linear_regression(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df) #<-- We will be replacing this line with the body of the transform function\n",
        "\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')"
      ],
      "metadata": {
        "outputId": "22e66bc1-5529-4a77-af18-1a5b5553ff17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ci_qnCgB57k9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The original test\n",
        "\n"
      ],
      "metadata": {
        "id": "ojU7wLaKdbBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def test_will_do_the_right_thing(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "    assert data_frame_to_json(actual_df) == expected_json(\"expected_correct.json\")"
      ],
      "metadata": {
        "id": "S5228csId2CS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c83dad69-694d-4dbf-9efb-182a374456be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mF\u001b[0m\u001b[31m                                                                                            [100%]\u001b[0m\n",
            "============================================= FAILURES =============================================\n",
            "\u001b[31m\u001b[1m___________________________________ test_will_do_the_right_thing ___________________________________\u001b[0m\n",
            "\n",
            "spark = <pyspark.sql.session.SparkSession object at 0x7f23801641c0>\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_will_do_the_right_thing\u001b[39;49;00m(spark: SparkSession):\u001b[90m\u001b[39;49;00m\n",
            "        diamonds_df = create_df_from_json(\u001b[33m\"\u001b[39;49;00m\u001b[33mtests/fixtures/diamonds.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, spark)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        actual_df = transform(diamonds_df)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m data_frame_to_json(actual_df) == expected_json(\u001b[33m\"\u001b[39;49;00m\u001b[33mexpected_correct.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: assert [{'carat': 0....G', ...}, ...] == [{'carat': 0....G', ...}, ...]\u001b[0m\n",
            "\u001b[1m\u001b[31mE         At index 3 diff: {'id': 'DI-26-null-price', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 2460.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}} != {'id': 'DI-26-null-price', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 2690.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}\u001b[0m\n",
            "\u001b[1m\u001b[31mE         Use -v to get more diff\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m<ipython-input-30-e9ec4e9326c8>\u001b[0m:7: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "[{'id': '1', 'carat': 0.23, 'clarity': 'SI2', 'color': 'E', 'price': 326.0, 'clarity_index': 3.0, 'color_index': 1.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 5], 'values': [0.23, 1.0]}}, {'id': 'DI-26', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 2690.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}, {'id': 'DI-26', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 2690.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}, {'id': 'DI-26-null-price', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 2460.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}, {'id': 'DI-27', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 2692.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}, {'id': 'DI-28', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'G', 'price': 2000.0, 'clarity_index': 0.0, 'color_index': 3.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1], 'values': [0.21, 1.0]}}, {'id': 'DI-30', 'carat': 0.32, 'clarity': 'I1', 'color': 'D', 'price': 345.0, 'clarity_index': 1.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 2, 4], 'values': [0.32, 1.0, 1.0]}}, {'id': 'minimum_inputs', 'carat': 0.23, 'clarity': 'SI1', 'color': 'F', 'clarity_index': 2.0, 'color_index': 2.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 3, 6], 'values': [0.23, 1.0, 1.0]}}]\n",
            "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m t_ee962cedc29f445183386cd214ffa279.py::\u001b[1mtest_will_do_the_right_thing\u001b[0m - AssertionError: assert [{'carat': 0....G', ...}, ...] == [{'carat': 0....G', ...}, ...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3.B Squeeze the bottom!\n"
      ],
      "metadata": {
        "id": "5oBE2ZEAF2E2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Instructions\n",
        "**our bug**: Diamonds of the same cut and clarity are influencing the calculated price of diamonds with a different color. Only diamonds with the same cut, clarity and color should be influencing the calculated price for diamonds with a null price.\n",
        "\n",
        "**Squeeze the bottom until you find the bug**\n",
        "- [ ] Move your assert up one line at a time.  \n",
        "- [ ] After each move, run your test.  \n",
        "- [ ] If it fails, figure out why it's failing.(You may need to rename columns in the assert)\n",
        "- [ ] If the test passes, the line wasn't important for the bug you wanted to catch. Delete it.\n",
        "- [ ] Continue until you find the source of the bug"
      ],
      "metadata": {
        "id": "PhriAy0jfsTj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise"
      ],
      "metadata": {
        "id": "SyOFZzKVokvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Code"
      ],
      "metadata": {
        "id": "u2EHWBjMetva"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The `transform` Function"
      ],
      "metadata": {
        "id": "9Yne491Uetvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import DataFrame, Window, Column\n",
        "from pyspark.sql.functions import log, when, mean, col\n",
        "\n",
        "def transform(df: DataFrame) -> DataFrame:\n",
        "\n",
        "    df = df.withColumn('lprice', log('price'))\n",
        "    window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    df = df[['id', 'carat', 'clarity', 'color', 'price']]\n",
        "    df = build_indep_vars(df, ['carat', 'clarity', 'color'],\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "-EhWDEgLetvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Test"
      ],
      "metadata": {
        "id": "441Jq5Ude3n7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession, DataFrame, Window, Column\n",
        "from pyspark.sql.functions import lit, log, when, mean, col\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(2460.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    df = diamonds_df.withColumn('lprice', log('price'))\n",
        "    window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    df = df[['id', 'carat', 'clarity', 'color', 'price']]\n",
        "    actual_df = build_indep_vars(df, ['carat', 'clarity', 'color'],\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "outputId": "72947746-5d94-4fc4-a2e7-8e8c0bf99daa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFv4b_9xFw-t"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mF\u001b[0m\u001b[31m                                                                                            [100%]\u001b[0m\n",
            "============================================= FAILURES =============================================\n",
            "\u001b[31m\u001b[1m____________________ test_null_price_is_replaced_based_on_cut_clarity_and_color ____________________\u001b[0m\n",
            "\n",
            "spark = <pyspark.sql.session.SparkSession object at 0x7f238031aa70>\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_null_price_is_replaced_based_on_cut_clarity_and_color\u001b[39;49;00m(spark: SparkSession):\u001b[90m\u001b[39;49;00m\n",
            "        diamonds_df = create_df_from_json(\u001b[33m\"\u001b[39;49;00m\u001b[33mtests/fixtures/diamonds.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, spark)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        df = diamonds_df.withColumn(\u001b[33m'\u001b[39;49;00m\u001b[33mlprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, log(\u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        window = Window.partitionBy(\u001b[33m'\u001b[39;49;00m\u001b[33mcut\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mclarity\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).orderBy(\u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).rowsBetween(-\u001b[94m3\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        moving_avg = mean(df[\u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]).over(window)\u001b[90m\u001b[39;49;00m\n",
            ">       df = df.withColumn(\u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, when(df.price.isNull(), df.moving_avg).otherwise(df.price))\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31m<ipython-input-42-86bea1a0250f>\u001b[0m:16: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "self = DataFrame[carat: double, clarity: string, color: string, cut: string, depth: double, id: string, price: bigint, table: bigint, x: double, y: double, z: double, lprice: double]\n",
            "name = 'moving_avg'\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92m__getattr__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, name: \u001b[96mstr\u001b[39;49;00m) -> Column:\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    .. versionadded:: 1.3.0\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    .. versionchanged:: 3.4.0\u001b[39;49;00m\n",
            "    \u001b[33m        Supports Spark Connect.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Parameters\u001b[39;49;00m\n",
            "    \u001b[33m    ----------\u001b[39;49;00m\n",
            "    \u001b[33m    name : str\u001b[39;49;00m\n",
            "    \u001b[33m        Column name to return as :class:`Column`.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Returns\u001b[39;49;00m\n",
            "    \u001b[33m    -------\u001b[39;49;00m\n",
            "    \u001b[33m    :class:`Column`\u001b[39;49;00m\n",
            "    \u001b[33m        Requested column.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Examples\u001b[39;49;00m\n",
            "    \u001b[33m    --------\u001b[39;49;00m\n",
            "    \u001b[33m    >>> df = spark.createDataFrame([\u001b[39;49;00m\n",
            "    \u001b[33m    ...     (2, \"Alice\"), (5, \"Bob\")], schema=[\"age\", \"name\"])\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    Retrieve a column instance.\u001b[39;49;00m\n",
            "    \u001b[33m\u001b[39;49;00m\n",
            "    \u001b[33m    >>> df.select(df.age).show()\u001b[39;49;00m\n",
            "    \u001b[33m    +---+\u001b[39;49;00m\n",
            "    \u001b[33m    |age|\u001b[39;49;00m\n",
            "    \u001b[33m    +---+\u001b[39;49;00m\n",
            "    \u001b[33m    |  2|\u001b[39;49;00m\n",
            "    \u001b[33m    |  5|\u001b[39;49;00m\n",
            "    \u001b[33m    +---+\u001b[39;49;00m\n",
            "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m name \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.columns:\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mraise\u001b[39;49;00m \u001b[96mAttributeError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[33m\"\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m object has no attribute \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m % (\u001b[96mself\u001b[39;49;00m.\u001b[91m__class__\u001b[39;49;00m.\u001b[91m__name__\u001b[39;49;00m, name)\u001b[90m\u001b[39;49;00m\n",
            "            )\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           AttributeError: 'DataFrame' object has no attribute 'moving_avg'\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py\u001b[0m:2977: AttributeError\n",
            "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m t_ee962cedc29f445183386cd214ffa279.py::\u001b[1mtest_null_price_is_replaced_based_on_cut_clarity_and_color\u001b[0m - AttributeError: 'DataFrame' object has no attribute 'moving_avg'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Original Test"
      ],
      "metadata": {
        "id": "MMVXW7E7gNBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def test_will_do_the_right_thing(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "    assert data_frame_to_json(actual_df) == expected_json(\"expected_correct.json\")"
      ],
      "metadata": {
        "id": "S50HLHD9gALp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4e74297-09c4-405e-f4b7-448a5252420c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mF\u001b[0m\u001b[31m                                                                                            [100%]\u001b[0m\n",
            "============================================= FAILURES =============================================\n",
            "\u001b[31m\u001b[1m___________________________________ test_will_do_the_right_thing ___________________________________\u001b[0m\n",
            "\n",
            "spark = <pyspark.sql.session.SparkSession object at 0x7f23803e5d80>\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_will_do_the_right_thing\u001b[39;49;00m(spark: SparkSession):\u001b[90m\u001b[39;49;00m\n",
            "        diamonds_df = create_df_from_json(\u001b[33m\"\u001b[39;49;00m\u001b[33mtests/fixtures/diamonds.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, spark)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        actual_df = transform(diamonds_df)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m data_frame_to_json(actual_df) == expected_json(\u001b[33m\"\u001b[39;49;00m\u001b[33mexpected_correct.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: assert [{'carat': 0....G', ...}, ...] == [{'carat': 0....G', ...}, ...]\u001b[0m\n",
            "\u001b[1m\u001b[31mE         At index 3 diff: {'id': 'DI-26-null-price', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 2460.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}} != {'id': 'DI-26-null-price', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 2690.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}\u001b[0m\n",
            "\u001b[1m\u001b[31mE         Use -v to get more diff\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m<ipython-input-15-e9ec4e9326c8>\u001b[0m:7: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "[{'id': '1', 'carat': 0.23, 'clarity': 'SI2', 'color': 'E', 'price': 326.0, 'clarity_index': 3.0, 'color_index': 1.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 5], 'values': [0.23, 1.0]}}, {'id': 'DI-26', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 2690.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}, {'id': 'DI-26', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 2690.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}, {'id': 'DI-26-null-price', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 2460.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}, {'id': 'DI-27', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 2692.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}, {'id': 'DI-28', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'G', 'price': 2000.0, 'clarity_index': 0.0, 'color_index': 3.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1], 'values': [0.21, 1.0]}}, {'id': 'DI-30', 'carat': 0.32, 'clarity': 'I1', 'color': 'D', 'price': 345.0, 'clarity_index': 1.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 2, 4], 'values': [0.32, 1.0, 1.0]}}, {'id': 'minimum_inputs', 'carat': 0.23, 'clarity': 'SI1', 'color': 'F', 'clarity_index': 2.0, 'color_index': 2.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 3, 6], 'values': [0.23, 1.0, 1.0]}}]\n",
            "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m t_ee962cedc29f445183386cd214ffa279.py::\u001b[1mtest_will_do_the_right_thing\u001b[0m - AssertionError: assert [{'carat': 0....G', ...}, ...] == [{'carat': 0....G', ...}, ...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3.C Let's fix the bug!\n"
      ],
      "metadata": {
        "id": "H3kdrtuBEbcC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions\n",
        "\n",
        "**Our Bug**: Diamonds of the same cut and clarity are influencing the calculated price of diamonds with a different color. Only diamonds with the same cut, clarity and color should be influencing the calculated price for diamonds with a null price.\n",
        "\n",
        "**Our Desired Behaviour**:  \n",
        "The input diamond with these properties:\n",
        "- id: `\"DI-26-null-price\"`\n",
        "- cut: `\"Good\"`\n",
        "- color: `\"D\"`\n",
        "- clarity: `\"VVS1\"`\n",
        "- price: `null`\n",
        "\n",
        "Should be output with a price of `3333.0` - the average price of the other diamonds with `cut=\"Good\"`, `clarity=\"VVS1\"` and `color=\"D\"`\n",
        "\n",
        "**Fix the bug**\n",
        "#### Test for the behaviour you actually want\n",
        "- [ ] Update your test so that it checks for the good behaviour.  \n",
        "Replace the expected price on this line with `3333.0`:  \n",
        "```\n",
        "actual_df=actual_df.withColumn('expected_price', lit(2460.0))\n",
        "```\n",
        "- [ ] Run your test. It should fail with a `columnsNotEqualError`:  \n",
        "```\n",
        "E           chispa.column_comparer.ColumnsNotEqualError:\n",
        "E           +------------+----------------+\n",
        "E           | moving_avg | expected_price |\n",
        "E           +------------+----------------+\n",
        "E           |   2460.0   |     3333.0     |\n",
        "E           +------------+----------------+\n",
        "```\n",
        "\n",
        "#### Fix the bug\n",
        "- [ ] Fix the code _in your test_ so that the bug is gone. We need to add `'color'` to `'cut'` and `'clarity'` on this line:\n",
        "```\n",
        "window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "```\n",
        "- [ ] Run your test. It should pass.\n",
        "\n",
        "#### Encapsulate the code necessary for the behaviour\n",
        "- [ ] The behaviour belongs to a group of lines working together. Extract them into a method.  \n",
        "These lines can't be separated without changing the behaviour we are testing:  \n",
        "```\n",
        "    window = Window.partitionBy('cut', 'clarity', 'color').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "```  \n",
        "Use them to make a method:\n",
        "```\n",
        "def calculate_avg_price_for_similar_diamonds(df: DataFrame) -> DataFrame:\n",
        "      window = Window.partitionBy('cut', 'clarity', 'color').orderBy('price').rowsBetween(-3, 3)\n",
        "      moving_avg = mean(df['price']).over(window)\n",
        "      df = df.withColumn('moving_avg', moving_avg)\n",
        "      df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "      return df\n",
        "```\n",
        "\n",
        "Replace those lines with a call to the new method in your test:  \n",
        "```\n",
        "actual_df = calculate_avg_price_for_similar_diamonds(actual_df)\n",
        "```\n",
        "- [ ] Run your test. It should pass.\n",
        "\n",
        "#### Move the encapsulated behaviour to the actual code\n",
        "- [ ] Move the new method out of your test and into the transform code.\n",
        "- [ ] Replace the lines in your transform code with the new method call.\n",
        "- [ ] We've changed the original code, so we need to check that everything still works the way we expect. Run the copy of your original large test. It should also pass.\n",
        "- [ ] Run your test. It should pass.\n"
      ],
      "metadata": {
        "id": "mL_lKfL-fdgh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise"
      ],
      "metadata": {
        "id": "mNb7r0copJ3X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Code"
      ],
      "metadata": {
        "id": "69ahdJEigJD7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The `transform` Function"
      ],
      "metadata": {
        "id": "aS6CsJ4IgJEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import DataFrame, Window, Column\n",
        "from pyspark.sql.functions import log, when, mean, col\n",
        "\n",
        "\n",
        "def transform(df: DataFrame) -> DataFrame:\n",
        "\n",
        "    df = df.withColumn('lprice', log('price'))\n",
        "    #THIS IS WHERE THE BEHAVIOUR WE CARE ABOUT STARTS - REPLACE THIS BLOCK\n",
        "    window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    #THIS IS WHERE THE BEHAVIOUR WE CARE ABOUT ENDS - REPLACE THIS BLOCK\n",
        "    df = df[['id', 'carat', 'clarity', 'color', 'price']]\n",
        "    df = build_indep_vars(df, ['carat', 'clarity', 'color'],\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "JkEX3fPYgJEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Test"
      ],
      "metadata": {
        "id": "6ChzdpcnfiMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession, DataFrame, Window, Column\n",
        "from pyspark.sql.functions import lit, log, when, mean, col\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(2460.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    df = diamonds_df.withColumn('lprice', log('price'))\n",
        "\n",
        "    #THIS IS WHERE THE BEHAVIOUR WE CARE ABOUT STARTS - EXTRACT THIS BLOCK\n",
        "    window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    #THIS IS WHERE THE BEHAVIOUR WE CARE ABOUT ENDS\n",
        "\n",
        "    assert_diamond_has_expected_price(df)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "outputId": "655d6894-1ed6-4464-a3c2-9a345c4ecac5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsPa000oHob3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Original Test"
      ],
      "metadata": {
        "id": "jqDYqIPxriN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def test_will_do_the_right_thing(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "    assert data_frame_to_json(actual_df) == expected_json(\"expected_correct.json\")"
      ],
      "metadata": {
        "id": "kVhgeRJEriOG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae37fb81-7cc6-4422-8222-ac755d513d4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mF\u001b[0m\u001b[31m                                                                                            [100%]\u001b[0m\n",
            "============================================= FAILURES =============================================\n",
            "\u001b[31m\u001b[1m___________________________________ test_will_do_the_right_thing ___________________________________\u001b[0m\n",
            "\n",
            "spark = <pyspark.sql.session.SparkSession object at 0x7f238031bdc0>\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_will_do_the_right_thing\u001b[39;49;00m(spark: SparkSession):\u001b[90m\u001b[39;49;00m\n",
            "        diamonds_df = create_df_from_json(\u001b[33m\"\u001b[39;49;00m\u001b[33mtests/fixtures/diamonds.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, spark)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        actual_df = transform(diamonds_df)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m data_frame_to_json(actual_df) == expected_json(\u001b[33m\"\u001b[39;49;00m\u001b[33mexpected_correct.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       AssertionError: assert [{'carat': 0....G', ...}, ...] == [{'carat': 0....G', ...}, ...]\u001b[0m\n",
            "\u001b[1m\u001b[31mE         At index 3 diff: {'id': 'DI-26-null-price', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 2460.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}} != {'id': 'DI-26-null-price', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 2690.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}\u001b[0m\n",
            "\u001b[1m\u001b[31mE         Use -v to get more diff\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m<ipython-input-18-e9ec4e9326c8>\u001b[0m:7: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "[{'id': '1', 'carat': 0.23, 'clarity': 'SI2', 'color': 'E', 'price': 326.0, 'clarity_index': 3.0, 'color_index': 1.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 5], 'values': [0.23, 1.0]}}, {'id': 'DI-26', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 2690.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}, {'id': 'DI-26', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 2690.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}, {'id': 'DI-26-null-price', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 2460.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}, {'id': 'DI-27', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 2692.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}, {'id': 'DI-28', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'G', 'price': 2000.0, 'clarity_index': 0.0, 'color_index': 3.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1], 'values': [0.21, 1.0]}}, {'id': 'DI-30', 'carat': 0.32, 'clarity': 'I1', 'color': 'D', 'price': 345.0, 'clarity_index': 1.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 2, 4], 'values': [0.32, 1.0, 1.0]}}, {'id': 'minimum_inputs', 'carat': 0.23, 'clarity': 'SI1', 'color': 'F', 'clarity_index': 2.0, 'color_index': 2.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 3, 6], 'values': [0.23, 1.0, 1.0]}}]\n",
            "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m t_ee962cedc29f445183386cd214ffa279.py::\u001b[1mtest_will_do_the_right_thing\u001b[0m - AssertionError: assert [{'carat': 0....G', ...}, ...] == [{'carat': 0....G', ...}, ...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Simplify the Top"
      ],
      "metadata": {
        "id": "5K0RWKPdr4fn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We don't want our test to be reading in the entire diamonds.json file in order to test this single behaviour. We are going to simplify things so that we have the absolute minimum number of inputs we need to reproduce the behaviour."
      ],
      "metadata": {
        "id": "YIx97jGHtDeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame, Window\n",
        "from pyspark.sql.functions import lit, log, when, mean\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "### FOR REFERENCE: THIS IS THE CODE WE ARE TESTING\n",
        "def calculate_avg_price_for_similar_diamonds(df: DataFrame) -> DataFrame:\n",
        "    window = Window.partitionBy('cut', 'clarity', 'color').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    return df\n",
        "\n",
        "def check_we_have_all_the_rows_we_need_for_the_behaviour(actual_df):\n",
        "    actual_df = actual_df.select('id', 'cut', 'clarity', 'color')\n",
        "    # print(\"ACTUAL_DF\")\n",
        "    # actual_df.show()\n",
        "    null_price_df = actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    # print(\"NULL_PRICE_DF\")\n",
        "    # null_price_df.show()\n",
        "    mismatched_properties_df = actual_df.crossJoin(null_price_df.select(\n",
        "        col('id').alias('null_id'),\n",
        "        col('cut').alias('null_cut'),\n",
        "        col('clarity').alias('null_clarity'),\n",
        "        col('color').alias('null_color')\n",
        "    ))\n",
        "\n",
        "    # print(\"MISMATCHED_PROPERTIES_DF\")\n",
        "    # mismatched_properties_df.show()\n",
        "    mismatched_properties_df = mismatched_properties_df.filter(mismatched_properties_df.null_id != mismatched_properties_df.id)\n",
        "    # print(\"MISMATCHED_PROPERTIES_DF - WITHOUT THE NULL PRICE ROW\")\n",
        "    # mismatched_properties_df.show()\n",
        "    mismatched_properties_df = mismatched_properties_df.filter(mismatched_properties_df.null_clarity == mismatched_properties_df.clarity)\n",
        "    # print(\"MISMATCHED_PROPERTIES_DF - WITH MATCHING CLARITY\")\n",
        "    # mismatched_properties_df.show()\n",
        "    mismatched_properties_df = mismatched_properties_df.filter(mismatched_properties_df.null_cut == mismatched_properties_df.cut)\n",
        "    # print(\"MISMATCHED_PROPERTIES_DF - WITH MATCHING CUT\")\n",
        "    # mismatched_properties_df.show()\n",
        "    mismatched_properties_df = mismatched_properties_df.filter(mismatched_properties_df.null_color != mismatched_properties_df.color)\n",
        "    # print(\"MISMATCHED_PROPERTIES_DF - WITH MISMATCHED COLOR ROWS\")\n",
        "    # mismatched_properties_df.show()\n",
        "    assert mismatched_properties_df.count() >= 1\n",
        "    # assert False\n",
        "\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    check_we_have_all_the_rows_we_need_for_the_behaviour(actual_df)\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = diamonds_df.withColumn('lprice', log('price'))  # <-- Delete this line\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(actual_df) # <-- Change this line to: actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb74c3c2-c567-4f86-93ec-9e25f2546432",
        "id": "9bs0g_ZB5-cQ"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### 4.A Remove lines that aren't related to the behaviour\n",
        "- [ ] We can see that we only care about the price column, and this line makes a column called `'lprice'`. It should be safe to delete:\n",
        "```\n",
        "actual_df = diamonds_df.withColumn('lprice', log('price'))\n",
        "```\n",
        "- [ ] Update the name of the parameter we pass to `calculate_avg_price_for_similar_diamonds` from `actual_df` to `diamonds_df`\n",
        "- [ ] Run your test. It should pass.\n",
        "\n"
      ],
      "metadata": {
        "id": "GM1rYTV824Z-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame, Window\n",
        "from pyspark.sql.functions import lit, log, when, mean\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "### FOR REFERENCE: THIS IS THE CODE WE ARE TESTING\n",
        "def calculate_avg_price_for_similar_diamonds(df: DataFrame) -> DataFrame:\n",
        "    window = Window.partitionBy('cut', 'clarity', 'color').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "    df = df.withColumn('price', when(df.price.isNull(), df.moving_avg).otherwise(df.price))\n",
        "    return df\n",
        "\n",
        "def check_we_have_all_the_rows_we_need_for_the_behaviour(actual_df):\n",
        "    actual_df = actual_df.select('id', 'cut', 'clarity', 'color')\n",
        "    null_price_df = actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    mismatched_properties_df = actual_df.crossJoin(null_price_df.select(\n",
        "        col('id').alias('null_id'),\n",
        "        col('cut').alias('null_cut'),\n",
        "        col('clarity').alias('null_clarity'),\n",
        "        col('color').alias('null_color')\n",
        "    ))\n",
        "\n",
        "    mismatched_properties_df = mismatched_properties_df.filter(mismatched_properties_df.null_id != mismatched_properties_df.id)\n",
        "    mismatched_properties_df = mismatched_properties_df.filter(mismatched_properties_df.null_clarity == mismatched_properties_df.clarity)\n",
        "    mismatched_properties_df = mismatched_properties_df.filter(mismatched_properties_df.null_cut == mismatched_properties_df.cut)\n",
        "    mismatched_properties_df = mismatched_properties_df.filter(mismatched_properties_df.null_color != mismatched_properties_df.color)\n",
        "    assert mismatched_properties_df.count() >= 1\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    check_we_have_all_the_rows_we_need_for_the_behaviour(actual_df)\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = diamonds_df.withColumn('lprice', log('price'))  # <-- Delete this line\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(actual_df) # <-- Change this line to: actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n"
      ],
      "metadata": {
        "id": "KEoj9ZIiuIra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "129eed34-db54-4678-89c4-1f1f93258142"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of reading from a large JSON file directly, we can make a dataframe with only the values we need in order to reproduce the behaviour\n",
        "\n",
        "**our bug**: Diamonds of the same cut and clarity are influencing the calculated price of diamonds with a different color. Only diamonds with the same cut, clarity and color should be influencing the calculated price for diamonds with a null price.\n",
        "\n",
        "**expected behaviour**: An unpriced diamond with cut=Good, color=D and clarity=VVS1 in a dataset with other diamonds of the same cut, clarity and color all priced at 3333.0, will have it's price set to match the average price of those diamonds. It will ignore prices from diamonds with a different color, cut or clarity"
      ],
      "metadata": {
        "id": "xCqZLEY23Fn4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.B Create the minimum Inputs needed to reproduce the bug\n",
        "- [ ] Delete the line that reads in from diamonds.json\n",
        "- [ ] Replace it with a new spark dataframe with the minimum inputs needed to test the behaviour\n",
        "- [ ] Change the id that we are filtering on in the assert statement to match the id of the diamond without a price in the new spark dataframe.\n",
        "- [ ] Run your test. It should pass.\n"
      ],
      "metadata": {
        "id": "MTcFz54o2_i0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "############################################ THE NEW SPARK DATAFRAME ############################################\n",
        "\"\"\"\n",
        "diamonds_df = spark.createDataFrame([\n",
        "  {\n",
        "    \"id\": 1,\n",
        "    \"carat\": 0.23,\n",
        "    \"cut\": \"Ideal\",\n",
        "    \"color\": \"E\",\n",
        "    \"clarity\": \"SI2\",\n",
        "    \"depth\": 61.5,\n",
        "    \"table\": 55,\n",
        "    \"price\": 326,\n",
        "    \"x\": 3.95,\n",
        "    \"y\": 3.98,\n",
        "    \"z\": 2.43\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"minimum_inputs\",\n",
        "    \"carat\": 0.23,\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"F\",\n",
        "    \"clarity\": \"SI1\",\n",
        "    \"depth\": null,\n",
        "    \"table\": null,\n",
        "    \"price\": null,\n",
        "    \"x\": null,\n",
        "    \"y\": null,\n",
        "    \"z\": null\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"DI-26-null-price\",\n",
        "    \"carat\": 0.21,\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"D\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"depth\": null,\n",
        "    \"table\": null,\n",
        "    \"price\": null,\n",
        "    \"x\": null,\n",
        "    \"y\": null,\n",
        "    \"z\": null\n",
        "  },\n",
        "  {\"id\": \"DI-26\",\"carat\": 0.21,\"cut\": \"Good\",\"color\": \"D\",\"clarity\": \"VVS1\",\"depth\": null,\"table\": null,\"price\": 3333,\"x\": null,\"y\": null,\"z\": null},\n",
        "  {\"id\": \"DI-26\",\"carat\": 0.21,\"cut\": \"Good\",\"color\": \"D\",\"clarity\": \"VVS1\",\"depth\": null,\"table\": null,\"price\": 3333,\"x\": null,\"y\": null,\"z\": null},\n",
        "  {\"id\": \"DI-27\",\"carat\": 0.21,\"cut\": \"Very Good\",\"color\": \"D\",\"clarity\": \"VVS1\",\"depth\": null,\"table\": null,\"price\": 2692,\"x\": null,\"y\": null,\"z\": null},\n",
        "  {\"id\": \"DI-28\",\"carat\": 0.21,\"cut\": \"Good\",\"color\": \"G\",\"clarity\": \"VVS1\",\"depth\": null,\"table\": null,\"price\": 1665,\"x\": null,\"y\": null,\"z\": null},\n",
        "  {\"id\": \"DI-30\",\"carat\": 0.32,\"cut\": \"Good\",\"color\": \"D\",\"clarity\": \"I1\",\"depth\": 60.9,\"table\": 58,\"price\": 345,\"x\": 4.38,\"y\": 4.42,\"z\": 2.68}\n",
        "]\n",
        ")\n",
        "\"\"\"\n",
        "#################################################################################################################\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')  #<- Change this line to: actual_df=actual_df.filter(actual_df.id == 'no-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark) # <- Delete this line\n",
        "    ############################ PASTE THE NEW SPARK DATAFRAME HERE ##############################\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHXKgmUc4dU2",
        "outputId": "d7c89584-4fe5-4cdb-dc3c-666cd3c27904"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    json_text = Path(\"./tests/fixtures/diamonds.json\").read_text()\n",
        "    diamonds_df = spark.read.option(\"multiline\", \"true\").json(spark.sparkContext.parallelize([json_text]))\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06f37e73-bc1f-48d0-a5e8-c104974f136e",
        "id": "U3SETNbui19m"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    json_text = '''\n",
        "      PASTE CONTENTS OF tests/fixtures/diamonds.json HERE\n",
        "    '''\n",
        "    json_text = Path(\"./tests/fixtures/diamonds.json\").read_text()\n",
        "    diamonds_df = spark.read.option(\"multiline\", \"true\").json(spark.sparkContext.parallelize([json_text]))\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06f37e73-bc1f-48d0-a5e8-c104974f136e",
        "id": "Th_x8dR6mKbv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    json_text = '''\n",
        "[\n",
        "  {\n",
        "    \"id\": 1,\n",
        "    \"carat\": 0.23,\n",
        "    \"cut\": \"Ideal\",\n",
        "    \"color\": \"E\",\n",
        "    \"clarity\": \"SI2\",\n",
        "    \"depth\": 61.5,\n",
        "    \"table\": 55,\n",
        "    \"price\": 326,\n",
        "    \"x\": 3.95,\n",
        "    \"y\": 3.98,\n",
        "    \"z\": 2.43\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"minimum_inputs\",\n",
        "    \"carat\": 0.23,\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"F\",\n",
        "    \"clarity\": \"SI1\",\n",
        "    \"depth\": null,\n",
        "    \"table\": null,\n",
        "    \"price\": null,\n",
        "    \"x\": null,\n",
        "    \"y\": null,\n",
        "    \"z\": null\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"DI-26-null-price\",\n",
        "    \"carat\": 0.21,\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"D\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"depth\": null,\n",
        "    \"table\": null,\n",
        "    \"price\": null,\n",
        "    \"x\": null,\n",
        "    \"y\": null,\n",
        "    \"z\": null\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"DI-26\",\n",
        "    \"carat\": 0.21,\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"D\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"depth\": null,\n",
        "    \"table\": null,\n",
        "    \"price\": 3333,\n",
        "    \"x\": null,\n",
        "    \"y\": null,\n",
        "    \"z\": null\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"DI-26\",\n",
        "    \"carat\": 0.21,\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"D\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"depth\": null,\n",
        "    \"table\": null,\n",
        "    \"price\": 3333,\n",
        "    \"x\": null,\n",
        "    \"y\": null,\n",
        "    \"z\": null\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"DI-27\",\n",
        "    \"carat\": 0.21,\n",
        "    \"cut\": \"Very Good\",\n",
        "    \"color\": \"D\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"depth\": null,\n",
        "    \"table\": null,\n",
        "    \"price\": 2692,\n",
        "    \"x\": null,\n",
        "    \"y\": null,\n",
        "    \"z\": null\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"DI-28\",\n",
        "    \"carat\": 0.21,\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"G\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"depth\": null,\n",
        "    \"table\": null,\n",
        "    \"price\": 1665,\n",
        "    \"x\": null,\n",
        "    \"y\": null,\n",
        "    \"z\": null\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"DI-30\",\n",
        "    \"carat\": 0.32,\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"D\",\n",
        "    \"clarity\": \"I1\",\n",
        "    \"depth\": 60.9,\n",
        "    \"table\": 58,\n",
        "    \"price\": 345,\n",
        "    \"x\": 4.38,\n",
        "    \"y\": 4.42,\n",
        "    \"z\": 2.68\n",
        "  }\n",
        "]\n",
        "\n",
        "    '''\n",
        "    #json_text = Path(\"./tests/fixtures/diamonds.json\").read_text()\n",
        "    diamonds_df = spark.read.option(\"multiline\", \"true\").json(spark.sparkContext.parallelize([json_text]))\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4b44014-939b-4e3a-e9a5-1fc51357709a",
        "id": "gOlilwetmgPM"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    json_text = '''\n",
        "[\n",
        "  {\n",
        "    \"id\": \"DI-26-null-price\",\n",
        "    \"carat\": 0.21,\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"D\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"depth\": null,\n",
        "    \"table\": null,\n",
        "    \"price\": null,\n",
        "    \"x\": null,\n",
        "    \"y\": null,\n",
        "    \"z\": null\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"DI-26\",\n",
        "    \"carat\": 0.21,\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"D\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"depth\": null,\n",
        "    \"table\": null,\n",
        "    \"price\": 3333,\n",
        "    \"x\": null,\n",
        "    \"y\": null,\n",
        "    \"z\": null\n",
        "  }\n",
        "]\n",
        "\n",
        "    '''\n",
        "    #json_text = Path(\"./tests/fixtures/diamonds.json\").read_text()\n",
        "    diamonds_df = spark.read.option(\"multiline\", \"true\").json(spark.sparkContext.parallelize([json_text]))\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8057ef55-ae3a-48f1-ca39-c2b14e158b5b",
        "id": "fQIuk7Aum4Q0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    json_text = '''\n",
        "[\n",
        "  {\n",
        "    \"id\": \"DI-26-null-price\",\n",
        "\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"D\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"price\": null\n",
        "\n",
        "\n",
        "  },\n",
        "  {\n",
        "    \"id\": \"DI-26\",\n",
        "\n",
        "    \"cut\": \"Good\",\n",
        "    \"color\": \"D\",\n",
        "    \"clarity\": \"VVS1\",\n",
        "    \"price\": 3333\n",
        "\n",
        "  }\n",
        "]\n",
        "\n",
        "    '''\n",
        "    #json_text = Path(\"./tests/fixtures/diamonds.json\").read_text()\n",
        "    diamonds_df = spark.read.option(\"multiline\", \"true\").json(spark.sparkContext.parallelize([json_text]))\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bfe7c2e-7230-47a8-db3a-919ee8d8b197",
        "id": "zGMDjRwjnz6B"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Clean up!"
      ],
      "metadata": {
        "id": "u73U7To0xBvK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This test can still be cleaner and easy to read.\n",
        "\n",
        "It passes, so it satisfies the first rule of simple design - tests pass\n",
        "\n",
        "What about the other 3?"
      ],
      "metadata": {
        "id": "wjYANsWB5gnF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5A: Reveal Intent - Extract the unpriced diamond to a method\n",
        "\n",
        "- [ ]  This is our unpriced diamond. In the next cell, we will pull it out into a method."
      ],
      "metadata": {
        "id": "wE2StiSh5xd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'no-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = spark.createDataFrame([\n",
        "      ##### THE UNPRICED DIAMOND #####\n",
        "      {\"id\": \"no-price\",                       \"price\": None,  \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"},\n",
        "      ##### END OF THE UNPRICED DIAMOND #####\n",
        "      {\"id\": \"with-price\",                     \"price\": 3333.0,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"},\n",
        "      {\"id\": \"with-price-wrong-color\",         \"price\": 2000.0,\"color\": \"G\", \"cut\": \"Good\", \"clarity\": \"VVS1\"},\n",
        "      {\"id\": \"with-price-wrong-clarity\",       \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"S1\"},\n",
        "      {\"id\": \"with-price-wrong-cut\",           \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Very Good\", \"clarity\": \"VVS1\"},\n",
        "    ])\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJjI4Dsr458a",
        "outputId": "de687037-eee1-4117-ef03-9f38a6d3e0ba"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5B: Reveal Intent - Extract the unpriced diamond to a method\n",
        "\n",
        "- [ ] We've created a new method called unpriced_diamond to return the code creating the unpriced diamond. It is commented out.\n",
        "- [ ] Uncomment it.\n",
        "- [ ] Run the test. It should pass."
      ],
      "metadata": {
        "id": "5aw5dbMc647E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "from typing import Dict\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'no-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "##### UNCOMMENT THIS METHOD\n",
        "#def unpriced_diamond() -> Dict:\n",
        "#  return {\"id\": \"no-price\", \"price\": None,  \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = spark.createDataFrame([\n",
        "      ##### THE UNPRICED DIAMOND #####\n",
        "      unpriced_diamond(),\n",
        "      ##### END OF THE UNPRICED DIAMOND #####\n",
        "      {\"id\": \"with-price\",                     \"price\": 3333.0,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"},\n",
        "      {\"id\": \"with-price-wrong-color\",         \"price\": 2000.0,\"color\": \"G\", \"cut\": \"Good\", \"clarity\": \"VVS1\"},\n",
        "      {\"id\": \"with-price-wrong-clarity\",       \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"S1\"},\n",
        "      {\"id\": \"with-price-wrong-cut\",           \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Very Good\", \"clarity\": \"VVS1\"},\n",
        "    ])\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5caogkF7ASx",
        "outputId": "8c74623f-05ab-4fcf-f19e-94591b624f1d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5C: Reveal Intent - Extract the matching diamond to a method\n",
        "\n",
        "- [ ] Look at the second object in the JSON array. This is our matching diamond. In the next cell, we will pull it out into a method."
      ],
      "metadata": {
        "id": "VnOthS9a8M8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "from typing import Dict\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'no-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def unpriced_diamond() -> Dict:\n",
        "  return {\"id\": \"no-price\", \"price\": None,  \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = spark.createDataFrame([\n",
        "      unpriced_diamond(),\n",
        "      ##### THE MATCHING DIAMOND #####\n",
        "      {\"id\": \"with-price\",                     \"price\": 3333.0,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"},\n",
        "      ##### END OF THE MATCHING DIAMOND #####\n",
        "      {\"id\": \"with-price-wrong-color\",         \"price\": 2000.0,\"color\": \"G\", \"cut\": \"Good\", \"clarity\": \"VVS1\"},\n",
        "      {\"id\": \"with-price-wrong-clarity\",       \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"S1\"},\n",
        "      {\"id\": \"with-price-wrong-cut\",           \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Very Good\", \"clarity\": \"VVS1\"},\n",
        "    ])\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCnpkyyJ8c45",
        "outputId": "ea42a2e7-e218-4805-deb0-aed6bf05a2c7"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5D: Reveal Intent - Extract the matching diamond to a method\n",
        "\n",
        "- [ ] We've created a new method called matching_diamond to return the code creating the matching diamond.It is commented out.\n",
        "- [ ] Uncomment it.\n",
        "- [ ] Notice how we've set up the method interface so it takes a price. This lets us indicate we care about the price of the matching diamond.\n",
        "- [ ] The price of the matching diamond should be `3333.0`. Pass it into the method call.\n",
        "- [ ] Run the test. It should pass."
      ],
      "metadata": {
        "id": "aE3q7gEu9BVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "\n",
        "from typing import Dict\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'no-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def unpriced_diamond() -> Dict:\n",
        "  return {\"id\": \"no-price\", \"price\": None,  \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "#def matching_diamond(price: float) -> Dict:\n",
        "#  return {\"id\": \"with-price\", \"price\": price ,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = spark.createDataFrame([\n",
        "      unpriced_diamond(),\n",
        "      ##### THE MATCHING DIAMOND #####\n",
        "      matching_diamond(), # <- CHANGE THIS LINE TO: matching_diamond(price=3333.0),\n",
        "      ##### END OF THE MATCHING DIAMOND #####\n",
        "      {\"id\": \"with-price-wrong-color\",         \"price\": 2000.0,\"color\": \"G\", \"cut\": \"Good\", \"clarity\": \"VVS1\"},\n",
        "      {\"id\": \"with-price-wrong-clarity\",       \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"S1\"},\n",
        "      {\"id\": \"with-price-wrong-cut\",           \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Very Good\", \"clarity\": \"VVS1\"},\n",
        "    ])\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktPMcHy99MKr",
        "outputId": "8cc109a1-db12-417e-f60f-c567f72edb2b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5E: Reveal Intent - Extract the diamond with a different color to a method\n",
        "\n",
        "- [ ] Look at the third object in the JSON array. This is the diamond with a different color. In the next cell, we will pull it out into a method."
      ],
      "metadata": {
        "id": "F39cC4hgDTb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "\n",
        "from typing import Dict\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'no-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def unpriced_diamond() -> Dict:\n",
        "  return {\"id\": \"no-price\", \"price\": None,  \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def matching_diamond(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price\", \"price\": price ,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = spark.createDataFrame([\n",
        "      unpriced_diamond(),\n",
        "      matching_diamond(price=3333.0),\n",
        "      ##### THE DIAMOND WITH A DIFFERENT COLOR #####\n",
        "      {\"id\": \"with-price-wrong-color\",         \"price\": 2000.0,\"color\": \"G\", \"cut\": \"Good\", \"clarity\": \"VVS1\"},\n",
        "      ##### END OF THE DIAMOND WITH A DIFFERENT COLOR #####\n",
        "      {\"id\": \"with-price-wrong-clarity\",       \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"S1\"},\n",
        "      {\"id\": \"with-price-wrong-cut\",           \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Very Good\", \"clarity\": \"VVS1\"},\n",
        "    ])\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n"
      ],
      "metadata": {
        "outputId": "69325f3d-e77f-4cbc-a685-36d1e4a726c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBRWtL5zDugj"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5F: Reveal Intent - Extract the diamond with a different color to a method\n",
        "\n",
        "- [ ] We've created a new method called diamond_with_different_color to return the diamond with a different color.\n",
        "- [ ] Notice how we've set up the method interface so we can see we care about the price of the diamond.\n",
        "- [ ] We want to use the price we pass into the method. Replace the hardcoded `2000.0` with `price`\n",
        "- [ ] The price of this diamond should be `2000.0`. Pass it into the method call.\n",
        "- [ ] Run the test. It should pass."
      ],
      "metadata": {
        "id": "8tMW5y32FI3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "\n",
        "from typing import Dict\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'no-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def unpriced_diamond() -> Dict:\n",
        "  return {\"id\": \"no-price\", \"price\": None,  \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def matching_diamond(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price\", \"price\": price ,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def diamond_with_different_color(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price-wrong-color\", \"price\": 2000.0, \"color\": \"G\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}  # <- CHANGE \"price\": 2000.0 TO \"price\": price\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = spark.createDataFrame([\n",
        "      unpriced_diamond(),\n",
        "      matching_diamond(price=3333.0),\n",
        "      ##### THE DIAMOND WITH A DIFFERENT COLOR #####\n",
        "      diamond_with_different_color(), # <- CHANGE THIS LINE TO: diamond_with_different_color(price=2000.0),\n",
        "      ##### END OF THE DIAMOND WITH A DIFFERENT COLOR #####\n",
        "      {\"id\": \"with-price-wrong-clarity\",       \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"S1\"},\n",
        "      {\"id\": \"with-price-wrong-cut\",           \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Very Good\", \"clarity\": \"VVS1\"},\n",
        "    ])\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n"
      ],
      "metadata": {
        "outputId": "a2635672-594b-4cc8-b5c4-60a35c22ef18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yXFRNXJFhSd"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5G: Reveal Intent - Extract the diamond with a different clarity to a method\n",
        "\n",
        "- [ ] Look at the fourth object in the JSON array. This is the diamond with a different clarity. In the next cell, we will pull it out into a method."
      ],
      "metadata": {
        "id": "4uJl_hsDQvhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "\n",
        "from typing import Dict\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'no-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def unpriced_diamond() -> Dict:\n",
        "  return {\"id\": \"no-price\", \"price\": None,  \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def matching_diamond(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price\", \"price\": price ,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def diamond_with_different_color(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price-wrong-color\", \"price\": price, \"color\": \"G\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = spark.createDataFrame([\n",
        "      unpriced_diamond(),\n",
        "      matching_diamond(price=3333.0),\n",
        "      diamond_with_different_color(price=2000.0),\n",
        "      ##### THE DIAMOND WITH A DIFFERENT CLARITY #####\n",
        "      {\"id\": \"with-price-wrong-clarity\",       \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"S1\"},\n",
        "      ##### END OF THE DIAMOND WITH A DIFFERENT CLARITY #####\n",
        "      {\"id\": \"with-price-wrong-cut\",           \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Very Good\", \"clarity\": \"VVS1\"},\n",
        "    ])\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n"
      ],
      "metadata": {
        "outputId": "1caf8326-fad9-4e2f-813e-d0617c3a49f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jl2YouSpRD4b"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5H: Reveal Intent - Extract the diamond with a different clarity to a method\n",
        "\n",
        "- [ ] We've created a new method called diamond_with_different_clarity to return the diamond with a different clarity.\n",
        "- [ ] The method call that would call this method is commented.\n",
        "- [ ] Uncomment it.\n",
        "- [ ] Cut and paste the dict that represents the diamond with a different clarity after the return statement in diamond_with_different_clarity.\n",
        "- [ ] Change the hardcoded \"price\": 2000.0 to \"price\": price\n",
        "- [ ] Run the test. It should pass."
      ],
      "metadata": {
        "id": "TQCkzt92RWe3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "\n",
        "from typing import Dict\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'no-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def unpriced_diamond() -> Dict:\n",
        "  return {\"id\": \"no-price\", \"price\": None,  \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def matching_diamond(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price\", \"price\": price ,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def diamond_with_different_color(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price-wrong-color\", \"price\": price, \"color\": \"G\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def diamond_with_different_clarity(price: float) -> Dict:\n",
        "  return ####### PASTE THE DICT HERE AND CHANGE \"price\": 2000.0 TO \"price\": price #####\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = spark.createDataFrame([\n",
        "      unpriced_diamond(),\n",
        "      matching_diamond(price=3333.0),\n",
        "      diamond_with_different_color(price=2000.0),\n",
        "      ##### THE DIAMOND WITH A DIFFERENT CLARITY #####\n",
        "      # diamond_with_different_clarity(price=2000.0), # <- UNCOMMENT THIS LINE\n",
        "      {\"id\": \"with-price-wrong-clarity\", \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"S1\"}, # <- CUT THIS LINE AND PASTE IT AFTER THE RETURN IN diamond_with_different_clarity\n",
        "      ##### END OF THE DIAMOND WITH A DIFFERENT CLARITY #####\n",
        "      {\"id\": \"with-price-wrong-cut\",           \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Very Good\", \"clarity\": \"VVS1\"},\n",
        "    ])\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n"
      ],
      "metadata": {
        "outputId": "3e0f7527-6623-465a-9ed6-7150f151b447",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4u90QE5RyhS"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5I: Reveal Intent - Extract the diamond with a different cut to a method\n",
        "\n",
        "- [ ] Look at the fifth object in the JSON array. This is the diamond with a different cut. In the next cell, we will pull it out into a method."
      ],
      "metadata": {
        "id": "oKv6s0nQTDhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "\n",
        "from typing import Dict\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'no-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def unpriced_diamond() -> Dict:\n",
        "  return {\"id\": \"no-price\", \"price\": None,  \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def matching_diamond(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price\", \"price\": price ,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def diamond_with_different_color(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price-wrong-color\", \"price\": price, \"color\": \"G\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def diamond_with_different_clarity(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price-wrong-color\", \"price\": price, \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"S1\"}\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = spark.createDataFrame([\n",
        "      unpriced_diamond(),\n",
        "      matching_diamond(price=3333.0),\n",
        "      diamond_with_different_color(price=2000.0),\n",
        "      diamond_with_different_clarity(price=2000.0),\n",
        "      ##### THE DIAMOND WITH A DIFFERENT CUT #####\n",
        "      {\"id\": \"with-price-wrong-cut\",           \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Very Good\", \"clarity\": \"VVS1\"},\n",
        "      ##### END OF THE DIAMOND WITH A DIFFERENT CUT #####\n",
        "    ])\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n"
      ],
      "metadata": {
        "outputId": "1caf8326-fad9-4e2f-813e-d0617c3a49f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8P8yPdfTeQS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5J: Reveal Intent - Extract the diamond with a different cut to a method\n",
        "\n",
        "- [ ] We've created a new method called diamond_with_different_cut to return the diamond with a different cut.\n",
        "- [ ] Notice how we've set up the method interface so we can see we care about the price of the diamond.\n",
        "- [ ] Replace the Dict in between the comments with a method call to the new method.\n",
        "- [ ] Run the test. It should pass."
      ],
      "metadata": {
        "id": "9nObySWVT6gl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "\n",
        "from typing import Dict\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'no-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def unpriced_diamond() -> Dict:\n",
        "  return {\"id\": \"no-price\", \"price\": None,  \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def matching_diamond(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price\", \"price\": price ,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def diamond_with_different_color(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price-wrong-color\", \"price\": price, \"color\": \"G\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def diamond_with_different_clarity(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price-wrong-color\", \"price\": price, \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"S1\"}\n",
        "\n",
        "def diamond_with_different_cut(price: float) -> Dict:\n",
        "  return  {\"id\": \"with-price-wrong-cut\",           \"price\": price,\"color\": \"D\", \"cut\": \"Very Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = spark.createDataFrame([\n",
        "      unpriced_diamond(),\n",
        "      matching_diamond(price=3333.0),\n",
        "      diamond_with_different_color(price=2000.0),\n",
        "      diamond_with_different_clarity(price=2000.0),\n",
        "      ##### THE DIAMOND WITH A DIFFERENT CUT #####\n",
        "      {\"id\": \"with-price-wrong-cut\", \"price\": 2000.0,\"color\": \"D\", \"cut\": \"Very Good\", \"clarity\": \"VVS1\"},  # <- DELETE THIS\n",
        "      # CALL diamond_with_different_cut(price=2000.0) HERE\n",
        "      ##### END OF THE DIAMOND WITH A DIFFERENT CUT #####\n",
        "    ])\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n"
      ],
      "metadata": {
        "outputId": "3e0f7527-6623-465a-9ed6-7150f151b447",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_PBu4T_T_IP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5K: Reveal Intent - Make it obvious which price we want\n",
        "\n",
        "- [ ] Pass the price as an argument to your assert helper function\n",
        "- [ ] Use it in place of the hardcoded 3333.0 when you create the `expected_price` column\n",
        "- [ ] Run the test. It should pass."
      ],
      "metadata": {
        "id": "XwIvmhGrJ46K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "\n",
        "from typing import Dict\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame) -> None: # <- CHANGE THIS LINE TO: def assert_diamond_has_expected_price(actual_df: DataFrame, price: float) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'no-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(3333.0)) # <- CHANGE THIS LINE TO: actual_df=actual_df.withColumn('expected_price', lit(price))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def unpriced_diamond() -> Dict:\n",
        "  return {\"id\": \"no-price\", \"price\": None,  \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def matching_diamond(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price\", \"price\": price ,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def diamond_with_different_color(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price-wrong-color\", \"price\": price, \"color\": \"G\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def diamond_with_different_clarity(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price-wrong-color\", \"price\": price, \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"S1\"}\n",
        "\n",
        "def diamond_with_different_cut(price: float) -> Dict:\n",
        "  return  {\"id\": \"with-price-wrong-cut\",  \"price\": price, \"color\": \"D\", \"cut\": \"Very Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = spark.createDataFrame([\n",
        "      unpriced_diamond(),\n",
        "      matching_diamond(price=3333.0),\n",
        "      diamond_with_different_color(price=2000.0),\n",
        "      diamond_with_different_clarity(price=2000.0),\n",
        "      diamond_with_different_cut(price=2000.0)\n",
        "    ])\n",
        "\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)  # <- CHANGE THIS LINE TO: assert_diamond_has_expected_price(actual_df, price=3333.0)\n"
      ],
      "metadata": {
        "outputId": "750e20c2-e7fc-4afc-dd34-9bf780cb0dba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9nUrsnKJ0qv"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5L: Remove Duplication - Use the Mismatched Diamond Function\n",
        "\n",
        "There is duplication in the `diamond_with_different_color`, `diamond_with_different_clarity` and `diamond_with_different_cut` methods.\n",
        "- [ ] There is a new method `mismatched_diamond` that minimizes duplication. Have each of these methods call that method.\n",
        "- [ ] Run the test. It should pass."
      ],
      "metadata": {
        "id": "yNkX4CfqMn-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "\n",
        "from typing import Dict\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame, price: float) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'no-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(price))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def unpriced_diamond() -> Dict:\n",
        "  return {\"id\": \"no-price\", \"price\": None,  \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def matching_diamond(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price\", \"price\": price ,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def diamond_with_different_color(price: float) -> Dict:\n",
        "  # CHANGE THE LINE BELOW TO: return mismatched_diamond(price=price, different_columns={\"color\": \"G\"})\n",
        "  return {\"id\": \"with-price-wrong-color\", \"price\": price, \"color\": \"G\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def diamond_with_different_clarity(price: float) -> Dict:\n",
        "  # CHANGE THE LINE BELOW TO: return mismatched_diamond(price=price, different_columns={\"clarity\": \"S1\"})\n",
        "  return {\"id\": \"with-price-wrong-color\", \"price\": price, \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"S1\"}\n",
        "\n",
        "def diamond_with_different_cut(price: float) -> Dict:\n",
        "  # CHANGE THE LINE BELOW TO: return mismatched_diamond(price=price, different_columns={\"cut\": \"Very Good\"})\n",
        "  return  {\"id\": \"with-price-wrong-cut\",  \"price\": price, \"color\": \"D\", \"cut\": \"Very Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def mismatched_diamond(price: float, different_columns: Dict) -> Dict:\n",
        "  diamond = {\"id\": \"with-price\", \"price\": price ,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "  diamond = diamond | different_columns\n",
        "  return diamond\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = spark.createDataFrame([\n",
        "      unpriced_diamond(),\n",
        "      matching_diamond(price=3333.0),\n",
        "      diamond_with_different_color(price=2000.0),\n",
        "      diamond_with_different_clarity(price=2000.0),\n",
        "      diamond_with_different_cut(price=2000.0)\n",
        "    ])\n",
        "\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df, price=3333.0)\n"
      ],
      "metadata": {
        "outputId": "cf3b44d4-3216-4b81-9f21-bfa9191f641e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDv6GixHg2BM"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5M: Remove Duplication - Inline the duplicate functions\n",
        "\n",
        "There is duplication in the `diamond_with_different_color`, `diamond_with_different_clarity` and `diamond_with_different_cut` methods.\n",
        "- [ ] Replace the call to each of these functions in the test with their call to `mismatched_diamond`\n",
        "- [ ] Delete the duplicated functions"
      ],
      "metadata": {
        "id": "SVYtHusOp-n4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import lit, log\n",
        "\n",
        "from typing import Dict\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df: DataFrame, price: float) -> None:\n",
        "    actual_df=actual_df.filter(actual_df.id == 'no-price')\n",
        "    assert actual_df.count() == 1\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(price))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def unpriced_diamond() -> Dict:\n",
        "  return {\"id\": \"no-price\", \"price\": None,  \"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "def matching_diamond(price: float) -> Dict:\n",
        "  return {\"id\": \"with-price\", \"price\": price ,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "\n",
        "##### DELETE THESE FUNCTIONS #####\n",
        "def diamond_with_different_color(price: float) -> Dict:\n",
        "  return mismatched_diamond(price=price, different_columns={\"color\": \"G\"})\n",
        "\n",
        "def diamond_with_different_clarity(price: float) -> Dict:\n",
        "  return mismatched_diamond(price=price, different_columns={\"clarity\": \"S1\"})\n",
        "\n",
        "def diamond_with_different_cut(price: float) -> Dict:\n",
        "  return mismatched_diamond(price=price, different_columns={\"cut\": \"Very Good\"})\n",
        "##################################\n",
        "\n",
        "\n",
        "def mismatched_diamond(price: float, different_columns: Dict) -> Dict:\n",
        "  diamond = {\"id\": \"with-price\", \"price\": price ,\"color\": \"D\", \"cut\": \"Good\", \"clarity\": \"VVS1\"}\n",
        "  diamond = diamond | different_columns\n",
        "  return diamond\n",
        "\n",
        "def test_null_price_is_replaced_based_on_cut_clarity_and_color(spark: SparkSession):\n",
        "    diamonds_df = spark.createDataFrame([\n",
        "      unpriced_diamond(),\n",
        "      matching_diamond(price=3333.0),\n",
        "      # CHANGE THE LINE BELOW TO: mismatched_diamond(price=2000.0, different_columns={\"color\": \"G\"})\n",
        "      diamond_with_different_color(price=2000.0),\n",
        "      # CHANGE THE LINE BELOW TO: mismatched_diamond(price=2000.0, different_columns={\"clarity\": \"S1\"})\n",
        "      diamond_with_different_clarity(price=2000.0),\n",
        "      # CHANGE THE LINE BELOW TO: mismatched_diamond(price=2000.0, different_columns={\"cut\": \"Very Good\"})\n",
        "      diamond_with_different_cut(price=2000.0)\n",
        "    ])\n",
        "\n",
        "\n",
        "    actual_df = calculate_avg_price_for_similar_diamonds(diamonds_df)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df, price=3333.0)\n"
      ],
      "metadata": {
        "outputId": "cdaa0a11-938a-4b1b-8d3a-30196cbf7caa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKXNeMc_qhKy"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}