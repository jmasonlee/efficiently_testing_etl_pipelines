{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOp+hnNOtZI6IbGCk66NEar",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmasonlee/efficiently_testing_etl_pipelines/blob/main/fixing_a_big_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Notebook"
      ],
      "metadata": {
        "id": "aqYjZpizVD3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf efficiently_testing_etl_pipelines\n",
        "!git clone https://github.com/jmasonlee/efficiently_testing_etl_pipelines.git\n",
        "!cp -r /content/efficiently_testing_etl_pipelines/src/ .\n",
        "!cp -r /content/efficiently_testing_etl_pipelines/tests/ .\n",
        "!rm -rf efficiently_testing_etl_pipelines\n",
        "!rm -rf tests/diamond_pricing_test*\n",
        "!rm -rf tests/test_helpers/*verification_helpers.py\n",
        "!rm -rf tests/conftest.py\n",
        "!rm -rf sample_data\n"
      ],
      "metadata": {
        "id": "i4KRAp6vTEJm",
        "outputId": "bdf5b893-22df-483b-d5d0-e596e7013cb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'efficiently_testing_etl_pipelines'...\n",
            "remote: Enumerating objects: 550, done.\u001b[K\n",
            "remote: Counting objects: 100% (191/191), done.\u001b[K\n",
            "remote: Compressing objects: 100% (115/115), done.\u001b[K\n",
            "remote: Total 550 (delta 121), reused 111 (delta 70), pack-reused 359\u001b[K\n",
            "Receiving objects: 100% (550/550), 246.07 KiB | 8.48 MiB/s, done.\n",
            "Resolving deltas: 100% (327/327), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Tests"
      ],
      "metadata": {
        "id": "5cRRMTtEBYy0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Dependencies\n",
        "\n",
        "For the exercise, we will need some special dependencies to allow us to run lots of tests in a notebook."
      ],
      "metadata": {
        "id": "_h199h_XEAwT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`ipytest` lets us run our tests in a notebook.\n",
        "\n"
      ],
      "metadata": {
        "id": "DVAcSonZmslt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipytest"
      ],
      "metadata": {
        "id": "7v0kaWulDXi-",
        "outputId": "535eb069-721b-41d3-e392-6017185a6bc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipytest\n",
            "  Downloading ipytest-0.13.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipytest) (7.34.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ipytest) (23.1)\n",
            "Requirement already satisfied: pytest>=5.4 in /usr/local/lib/python3.10/dist-packages (from ipytest) (7.2.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=5.4->ipytest) (23.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=5.4->ipytest) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest>=5.4->ipytest) (1.2.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest>=5.4->ipytest) (1.1.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=5.4->ipytest) (2.0.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->ipytest)\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (3.0.38)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipytest) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipytest) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipytest) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipytest) (0.2.6)\n",
            "Installing collected packages: jedi, ipytest\n",
            "Successfully installed ipytest-0.13.3 jedi-0.18.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ipytest is what allows us to run our tests in a notebook. This next cell is not needed if you are writing tests in a separate pytest file."
      ],
      "metadata": {
        "id": "3_ILjU8goCNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipytest\n",
        "ipytest.autoconfig()"
      ],
      "metadata": {
        "id": "t7iwGQ4Le-Oe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are installing `pyspark` because it doesn't come with the base colab environment"
      ],
      "metadata": {
        "id": "HzwfHFGmm2Ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "QNnk84AsmmFQ",
        "outputId": "b3e05fd2-471c-45ba-cdfd-7138727cf1f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285398 sha256=13b8460b2c01651b31ebdfda3c116e8d7519284d585e49e934055dee2caf3462\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chispa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_EYg-cC1cD5",
        "outputId": "bb465641-1c45-4f2b-8736-52e709fec1eb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chispa\n",
            "  Downloading chispa-0.9.2-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: chispa\n",
            "Successfully installed chispa-0.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a local SparkSession\n",
        "\n",
        "Normally spark runs on a bunch of executors in the cloud. Since we want our tests to be able to run on a single dev machine, we make a fixture that gives us a local spark context."
      ],
      "metadata": {
        "id": "V_OJcnSiBgUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "from _pytest.fixtures import FixtureRequest\n",
        "from pyspark import SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "@pytest.fixture(scope=\"session\")\n",
        "def spark(request: FixtureRequest):\n",
        "    conf = (SparkConf()\n",
        "        .setMaster(\"local\")\n",
        "        .setAppName(\"sample_pyspark_testing_starter\"))\n",
        "\n",
        "    spark = SparkSession \\\n",
        "        .builder \\\n",
        "        .config(conf=conf) \\\n",
        "        .getOrCreate()\n",
        "\n",
        "    request.addfinalizer(lambda: spark.stop())\n",
        "    return spark"
      ],
      "metadata": {
        "id": "xXPLpebJ6iI2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Helpers\n",
        "\n",
        "This is a helper function that retrieves our test output from the expected.json file"
      ],
      "metadata": {
        "id": "actN5s7DCF9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def expected_json():\n",
        "    with open(\"tests/fixtures/expected.json\") as f:\n",
        "        return json.loads(f.read())"
      ],
      "metadata": {
        "id": "VO2-3px25xEl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Test"
      ],
      "metadata": {
        "id": "MjwHttFB5TB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from src.linear_regression_prep import transform\n",
        "from tests.test_helpers.json_helpers import create_df_from_json, data_frame_to_json\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def test_prep_for_linear_regression(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "    assert data_frame_to_json(actual_df) == expected_json()"
      ],
      "metadata": {
        "id": "lH1x9ZOi58X7",
        "outputId": "c4750b10-0079-4c8e-dbb9-4b5b30868b73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make The Assert Specific"
      ],
      "metadata": {
        "id": "cbCuKHDpso8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Right now, our test compares everything in the output dataframe to everything in a large json file. That's a lot of rows to compare and the assert is wrong anyways!\n",
        "\n",
        "Let's make this test assert on the thing we actually care about - the output price of the diamond!"
      ],
      "metadata": {
        "id": "X-xfpXMwstwN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's make our assert specific!\n",
        "### We can do the next step in one of 3 ways:\n",
        "#### With Chispa\n",
        "- [ ] Add these imports to the top of the cell, below the `%%ipytest -qq` line:  \n",
        "`from chispa import assert_column_equality`  \n",
        "`from pySpark.sql.functions import lit`\n",
        "- [ ] Filter the dataframe for the unique id of the diamond we care about:  \n",
        "`actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')`\n",
        "- [ ] Create a new column in our dataframe that contains our expected price:  \n",
        "`actual_df=actual_df.withColumn('expected_price', lit(2960.0))`\n",
        "- [ ] Assert the value in the price column matches the value we want:  \n",
        "`assert_column_equality(actual_df, 'price', 'expected_price')`\n"
      ],
      "metadata": {
        "id": "jz3ygb6GxcYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from src.linear_regression_prep import transform\n",
        "from tests.test_helpers.json_helpers import create_df_from_json, data_frame_to_json\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "\n",
        "def test_prep_for_linear_regression(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n"
      ],
      "metadata": {
        "outputId": "fa65b106-7d50-4264-883d-b314c40646ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiwYRKD0yXIW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With Pandas\n",
        "- [ ] import pandas:  \n",
        "`import pandas as pd`\n",
        "- [ ] Filter the dataframe for the unique id of the diamond we care about:  \n",
        "  `actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')`\n",
        "- [ ] Create your expected dataframe using Pandas:  \n",
        " `expected = pd.DataFrame(({'id': [\"DI-26-null-price\"], 'price':[2690.0] }))`\n",
        "- [ ] Select the column you care about:  \n",
        "  `actual_df=actual_df.select(['id', 'price'])\n",
        "- [ ] Assert for dataframe equality using pandas:  \n",
        "  `pd.testing.assert_frame_equal(actual_df, expected)`"
      ],
      "metadata": {
        "id": "wW0OfrWo8Qn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from src.linear_regression_prep import transform\n",
        "from tests.test_helpers.json_helpers import create_df_from_json, data_frame_to_json\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import lit\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def test_prep_for_linear_regression(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n"
      ],
      "metadata": {
        "outputId": "fb64b8ce-8309-4873-a2e2-aceeade45a2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a_ORvhl9CAd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mF\u001b[0m\u001b[31m                                                                                            [100%]\u001b[0m\n",
            "============================================= FAILURES =============================================\n",
            "\u001b[31m\u001b[1m_________________________________ test_prep_for_linear_regression __________________________________\u001b[0m\n",
            "\n",
            "spark = <pyspark.sql.session.SparkSession object at 0x7f09a86a93f0>\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_prep_for_linear_regression\u001b[39;49;00m(spark: SparkSession):\u001b[90m\u001b[39;49;00m\n",
            "        diamonds_df = create_df_from_json(\u001b[33m\"\u001b[39;49;00m\u001b[33mtests/fixtures/diamonds.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, spark)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        actual_df = transform(diamonds_df)\u001b[90m\u001b[39;49;00m\n",
            "        actual_df=actual_df.filter(actual_df.id == \u001b[33m'\u001b[39;49;00m\u001b[33mDI-26-null-price\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        expected = pd.DataFrame(({\u001b[33m'\u001b[39;49;00m\u001b[33mid\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [\u001b[33m\"\u001b[39;49;00m\u001b[33mDI-26-null-price\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m], \u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:[\u001b[94m2690.0\u001b[39;49;00m] }))\u001b[90m\u001b[39;49;00m\n",
            "        actual_df = actual_df.select([\u001b[33m'\u001b[39;49;00m\u001b[33mid\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]).where(actual_df.id == \u001b[33m\"\u001b[39;49;00m\u001b[33mDI-26-null-price\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            ">       pd.testing.assert_frame_equal(actual_df.toPandas(), expected)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31m<ipython-input-13-0be942c8d32b>\u001b[0m:17: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31mpandas/_libs/testing.pyx\u001b[0m:52: in pandas._libs.testing.assert_almost_equal\n",
            "    \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            ">   \u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[04m\u001b[91m?\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE   AssertionError: DataFrame.iloc[:, 1] (column name=\"price\") are different\u001b[0m\n",
            "\u001b[1m\u001b[31mE   \u001b[0m\n",
            "\u001b[1m\u001b[31mE   DataFrame.iloc[:, 1] (column name=\"price\") values are different (100.0 %)\u001b[0m\n",
            "\u001b[1m\u001b[31mE   [index]: [0]\u001b[0m\n",
            "\u001b[1m\u001b[31mE   [left]:  [2460.0]\u001b[0m\n",
            "\u001b[1m\u001b[31mE   [right]: [2690.0]\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31mpandas/_libs/testing.pyx\u001b[0m:167: AssertionError\n",
            "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m t_5f8a68b7935441de8636ef9c39afbe88.py::\u001b[1mtest_prep_for_linear_regression\u001b[0m - AssertionError: DataFrame.iloc[:, 1] (column name=\"price\") are different\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Assert on properties\n",
        "\n",
        "- [ ] Filter the dataframe for the unique id of the diamond we care about:  \n",
        "  `actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')`\n",
        "- [ ] Convert your dataframe to JSON:  \n",
        "`actual_df_json = data_frame_to_json(actual_df)`\n",
        "- [ ] Assert the price property of the first object matches your expected price:  \n",
        "`assert actual_df_json[0]['price'] == 2690.0`"
      ],
      "metadata": {
        "id": "lD-3MVVv9D9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from src.linear_regression_prep import transform\n",
        "from tests.test_helpers.json_helpers import create_df_from_json, data_frame_to_json\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import lit\n",
        "\n",
        "\n",
        "def test_prep_for_linear_regression(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "\n"
      ],
      "metadata": {
        "outputId": "d3700678-4a25-45ad-c2aa-5f9f2cee7152",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55eVJ0Ug9Pif"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mF\u001b[0m\u001b[31m                                                                                            [100%]\u001b[0m\n",
            "============================================= FAILURES =============================================\n",
            "\u001b[31m\u001b[1m_________________________________ test_prep_for_linear_regression __________________________________\u001b[0m\n",
            "\n",
            "spark = <pyspark.sql.session.SparkSession object at 0x7f09a86c1c60>\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_prep_for_linear_regression\u001b[39;49;00m(spark: SparkSession):\u001b[90m\u001b[39;49;00m\n",
            "        diamonds_df = create_df_from_json(\u001b[33m\"\u001b[39;49;00m\u001b[33mtests/fixtures/diamonds.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, spark)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        actual_df = transform(diamonds_df)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        actual_df=actual_df.filter(actual_df.id == \u001b[33m'\u001b[39;49;00m\u001b[33mDI-26-null-price\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        actual_df_json = data_frame_to_json(actual_df)\u001b[90m\u001b[39;49;00m\n",
            ">       \u001b[94massert\u001b[39;49;00m actual_df_json[\u001b[94m0\u001b[39;49;00m][\u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] == \u001b[94m2690.0\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE       assert 2460.0 == 2690.0\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m<ipython-input-14-e71ba456c136>\u001b[0m:15: AssertionError\n",
            "--------------------------------------- Captured stdout call ---------------------------------------\n",
            "[{'id': 'DI-26-null-price', 'carat': 0.21, 'clarity': 'VVS1', 'color': 'D', 'price': 2460.0, 'clarity_index': 0.0, 'color_index': 0.0, 'indep_vars': {'type': 0, 'size': 7, 'indices': [0, 1, 4], 'values': [0.21, 1.0, 1.0]}}]\n",
            "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m t_5f8a68b7935441de8636ef9c39afbe88.py::\u001b[1mtest_prep_for_linear_regression\u001b[0m - assert 2460.0 == 2690.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gXz5GQs_5SBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reduce Duplicate Coverage and Fix the Bug\n",
        "\n",
        "Right now, our test is running the entire transform function. Because there are multiple tests in `diamonds.json`, each test is running the same large block of code over and over again."
      ],
      "metadata": {
        "id": "sw4mvQYw5pkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Code\n",
        "This is the code that is executed when we run our test.\n",
        "\n",
        "Right now, all of it is being run by every test case in our diamonds.json input file.\n",
        "\n",
        "Execute both of these cells so that they are available in our test cell\n"
      ],
      "metadata": {
        "id": "0ze_hB2VCmC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The `replace_null_prices_with_floating_averages` Function"
      ],
      "metadata": {
        "id": "hMPuzaWi-UZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The `transform` Function"
      ],
      "metadata": {
        "id": "YgzlhOgV-LJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import DataFrame, Window, Column\n",
        "from pyspark.sql.functions import log, when, mean, col\n",
        "\n",
        "from src.build_indep_vars import build_indep_vars\n",
        "from src.diamond_pricing import replace_null_prices_with_floating_averages\n",
        "\n",
        "def replace_null(orig: Column, average: Column):\n",
        "    return when(orig.isNull(), average).otherwise(orig)\n",
        "\n",
        "def transform(df: DataFrame) -> DataFrame:\n",
        "\n",
        "    df = df.withColumn('lprice', log('price'))\n",
        "    window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(df['price']).over(window)\n",
        "    df = df.withColumn('moving_avg', moving_avg)\n",
        "\n",
        "    df_new = df.withColumn('price', replace_null(col('price'), col('moving_avg')))\n",
        "    df = df[['id', 'carat', 'clarity', 'color', 'price']]\n",
        "    df = build_indep_vars(df, ['carat', 'clarity', 'color'],\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "EqUboG2Y-HZE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Test\n",
        "\n",
        "Let's reduce the duplicate coverage.\n",
        "\n",
        "### Prep\n",
        "\n",
        "- [ ] Run the test. It should be failing.\n",
        "- [ ] Replace the line that calls the transform function with the body of the transform function.  \n",
        "- [ ] Rename `df` to `actual_df`, except the first place it's used. (Find and Replace is `ctrl-m-h`).  \n",
        "This line:  \n",
        "`df = df.withColumn('lprice', log('price'))`  \n",
        "should become  \n",
        "`actual_df = diamonds_df.withColumn('lprice', log('price'))`\n",
        "- [ ] Change your assert code so that it is testing _for_ the bug.\n",
        "```\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(2960.0))\n",
        "```\n",
        "becomes\n",
        "```\n",
        "  actual_df=actual_df.withColumn('expected_price', lit(2460.0))\n",
        "```\n",
        "\n",
        "\n",
        "- [ ] Extract your assert code into a one-line helper function:\n",
        "```\n",
        "def assert_diamond_has_expected_price(actual_df):\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(2460.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "```\n"
      ],
      "metadata": {
        "id": "DR41JwrwDPhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from src.linear_regression_prep import transform\n",
        "from tests.test_helpers.json_helpers import create_df_from_json, data_frame_to_json\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import lit\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "def test_prep_for_linear_regression(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = transform(diamonds_df)\n",
        "\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(2960.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')"
      ],
      "metadata": {
        "outputId": "a59f4e2c-0380-43e0-9e7e-917b95603ea3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ci_qnCgB57k9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mF\u001b[0m\u001b[31m                                                                                            [100%]\u001b[0m\n",
            "============================================= FAILURES =============================================\n",
            "\u001b[31m\u001b[1m_________________________________ test_prep_for_linear_regression __________________________________\u001b[0m\n",
            "\n",
            "spark = <pyspark.sql.session.SparkSession object at 0x7f09a83e0910>\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_prep_for_linear_regression\u001b[39;49;00m(spark: SparkSession):\u001b[90m\u001b[39;49;00m\n",
            "        diamonds_df = create_df_from_json(\u001b[33m\"\u001b[39;49;00m\u001b[33mtests/fixtures/diamonds.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, spark)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        actual_df = diamonds_df.withColumn(\u001b[33m'\u001b[39;49;00m\u001b[33mlprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, log(\u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        actual_df = replace_null_prices_with_floating_averages(actual_df)\u001b[90m\u001b[39;49;00m\n",
            "        actual_df = actual_df[[\u001b[33m'\u001b[39;49;00m\u001b[33mid\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcarat\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mclarity\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcolor\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]]\u001b[90m\u001b[39;49;00m\n",
            "        actual_df = build_indep_vars(actual_df, [\u001b[33m'\u001b[39;49;00m\u001b[33mcarat\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mclarity\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcolor\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
            "                                          categorical_vars=[\u001b[33m'\u001b[39;49;00m\u001b[33mclarity\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mcolor\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
            "                                          keep_intermediate=\u001b[94mFalse\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
            "                                          summarizer=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            ">       assert_diamond_has_expected_price(actual_df)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31m<ipython-input-20-8e4a349af9a6>\u001b[0m:24: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31m<ipython-input-20-8e4a349af9a6>\u001b[0m:11: in assert_diamond_has_expected_price\n",
            "    assert_column_equality(actual_df, \u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mexpected_price\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "df = DataFrame[id: string, carat: double, clarity: string, color: string, price: double, clarity_index: double, color_index: double, indep_vars: vector, expected_price: double]\n",
            "col_name1 = 'price', col_name2 = 'expected_price'\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92massert_column_equality\u001b[39;49;00m(df, col_name1, col_name2):\u001b[90m\u001b[39;49;00m\n",
            "        elements = df.select(col_name1, col_name2).collect()\u001b[90m\u001b[39;49;00m\n",
            "        colName1Elements = \u001b[96mlist\u001b[39;49;00m(\u001b[96mmap\u001b[39;49;00m(\u001b[94mlambda\u001b[39;49;00m x: x[\u001b[94m0\u001b[39;49;00m], elements))\u001b[90m\u001b[39;49;00m\n",
            "        colName2Elements = \u001b[96mlist\u001b[39;49;00m(\u001b[96mmap\u001b[39;49;00m(\u001b[94mlambda\u001b[39;49;00m x: x[\u001b[94m1\u001b[39;49;00m], elements))\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mif\u001b[39;49;00m colName1Elements != colName2Elements:\u001b[90m\u001b[39;49;00m\n",
            "            zipped = \u001b[96mlist\u001b[39;49;00m(\u001b[96mzip\u001b[39;49;00m(colName1Elements, colName2Elements))\u001b[90m\u001b[39;49;00m\n",
            "            t = PrettyTable([col_name1, col_name2])\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mfor\u001b[39;49;00m elements \u001b[95min\u001b[39;49;00m zipped:\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94mif\u001b[39;49;00m elements[\u001b[94m0\u001b[39;49;00m] == elements[\u001b[94m1\u001b[39;49;00m]:\u001b[90m\u001b[39;49;00m\n",
            "                    first = bcolors.LightBlue + \u001b[96mstr\u001b[39;49;00m(elements[\u001b[94m0\u001b[39;49;00m]) + bcolors.LightRed\u001b[90m\u001b[39;49;00m\n",
            "                    second = bcolors.LightBlue + \u001b[96mstr\u001b[39;49;00m(elements[\u001b[94m1\u001b[39;49;00m]) + bcolors.LightRed\u001b[90m\u001b[39;49;00m\n",
            "                    t.add_row([first, second])\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "                    t.add_row([\u001b[96mstr\u001b[39;49;00m(elements[\u001b[94m0\u001b[39;49;00m]), \u001b[96mstr\u001b[39;49;00m(elements[\u001b[94m1\u001b[39;49;00m])])\u001b[90m\u001b[39;49;00m\n",
            ">           \u001b[94mraise\u001b[39;49;00m ColumnsNotEqualError(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m + t.get_string())\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE           chispa.column_comparer.ColumnsNotEqualError: \u001b[0m\n",
            "\u001b[1m\u001b[31mE           +--------+----------------+\u001b[0m\n",
            "\u001b[1m\u001b[31mE           | price  | expected_price |\u001b[0m\n",
            "\u001b[1m\u001b[31mE           +--------+----------------+\u001b[0m\n",
            "\u001b[1m\u001b[31mE           | 2460.0 |     2960.0     |\u001b[0m\n",
            "\u001b[1m\u001b[31mE           +--------+----------------+\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.10/dist-packages/chispa/column_comparer.py\u001b[0m:24: ColumnsNotEqualError\n",
            "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m t_5f8a68b7935441de8636ef9c39afbe88.py::\u001b[1mtest_prep_for_linear_regression\u001b[0m - chispa.column_comparer.ColumnsNotEqualError: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Now we can start finding what's important!\n",
        "Remember, our bug is that diamonds of the same cut and clarity are influencing the calculated price of diamonds with a different color. Only diamonds with the same cut, clarity and color should be influencing the calculated price for diamonds with a null price.\n",
        "\n",
        "- [ ] Move your assert up one line at a time.  \n",
        " After each move, run your tests.  \n",
        " If it fails, figure out why it's failing.  \n",
        " If the test passes, the line wasn't important for the bug you wanted to catch. Delete it.\n",
        "- [ ] Continue until you find the source of the bug\n",
        "- [ ] You may need to rename columns in order to continue squeezing the bottom."
      ],
      "metadata": {
        "id": "5oBE2ZEAF2E2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest -qq\n",
        "from src.linear_regression_prep import transform\n",
        "from tests.test_helpers.json_helpers import create_df_from_json, data_frame_to_json\n",
        "\n",
        "from pyspark.sql import SparkSession, DataFrame, Window, Column\n",
        "from pyspark.sql.functions import lit, log, when, mean, col\n",
        "from chispa import assert_column_equality\n",
        "\n",
        "def assert_diamond_has_expected_price(actual_df):\n",
        "    actual_df=actual_df.filter(actual_df.id == 'DI-26-null-price')\n",
        "    actual_df=actual_df.withColumn('expected_price', lit(2460.0))\n",
        "    assert_column_equality(actual_df, 'price', 'expected_price')\n",
        "\n",
        "def test_prep_for_linear_regression(spark: SparkSession):\n",
        "    diamonds_df = create_df_from_json(\"tests/fixtures/diamonds.json\", spark)\n",
        "\n",
        "    actual_df = diamonds_df.withColumn('lprice', log('price'))\n",
        "    window = Window.partitionBy('cut', 'clarity').orderBy('price').rowsBetween(-3, 3)\n",
        "    moving_avg = mean(actual_df['price']).over(window)\n",
        "    actual_df = actual_df.withColumn('moving_avg', moving_avg)\n",
        "\n",
        "    actual_df = actual_df.withColumn('price', replace_null(col('price'), col('moving_avg')))\n",
        "    actual_df = actual_df[['id', 'carat', 'clarity', 'color', 'price']]\n",
        "    actual_df = build_indep_vars(actual_df, ['carat', 'clarity', 'color'],\n",
        "                                      categorical_vars=['clarity', 'color'],\n",
        "                                      keep_intermediate=False,\n",
        "                                      summarizer=True)\n",
        "\n",
        "    assert_diamond_has_expected_price(actual_df)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "outputId": "c5e6859f-43d5-43be-e521-e58898ec3569",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFv4b_9xFw-t"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mF\u001b[0m\u001b[31m                                                                                            [100%]\u001b[0m\n",
            "============================================= FAILURES =============================================\n",
            "\u001b[31m\u001b[1m_________________________________ test_prep_for_linear_regression __________________________________\u001b[0m\n",
            "\n",
            "spark = <pyspark.sql.session.SparkSession object at 0x7f09a85eef20>\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_prep_for_linear_regression\u001b[39;49;00m(spark: SparkSession):\u001b[90m\u001b[39;49;00m\n",
            "        diamonds_df = create_df_from_json(\u001b[33m\"\u001b[39;49;00m\u001b[33mtests/fixtures/diamonds.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, spark)\u001b[90m\u001b[39;49;00m\n",
            "    \u001b[90m\u001b[39;49;00m\n",
            "        actual_df = diamonds_df.withColumn(\u001b[33m'\u001b[39;49;00m\u001b[33mlprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, log(\u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
            "        window = Window.partitionBy(\u001b[33m'\u001b[39;49;00m\u001b[33mcut\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mclarity\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).orderBy(\u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).rowsBetween(-\u001b[94m3\u001b[39;49;00m, \u001b[94m3\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "        moving_avg = mean(actual_df[\u001b[33m'\u001b[39;49;00m\u001b[33mprice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]).over(window)\u001b[90m\u001b[39;49;00m\n",
            ">       assert_diamond_has_expected_price(actual_df)\u001b[90m\u001b[39;49;00m\n",
            "\n",
            "\u001b[1m\u001b[31m<ipython-input-30-775ca298baed>\u001b[0m:19: \n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\u001b[1m\u001b[31m<ipython-input-30-775ca298baed>\u001b[0m:11: in assert_diamond_has_expected_price\n",
            "    assert_column_equality(actual_df, \u001b[33m'\u001b[39;49;00m\u001b[33mmoving_avg\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mexpected_price\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.10/dist-packages/chispa/column_comparer.py\u001b[0m:11: in assert_column_equality\n",
            "    elements = df.select(col_name1, col_name2).collect()\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py\u001b[0m:3036: in select\n",
            "    jdf = \u001b[96mself\u001b[39;49;00m._jdf.select(\u001b[96mself\u001b[39;49;00m._jcols(*cols))\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m:1322: in __call__\n",
            "    return_value = get_return_value(\u001b[90m\u001b[39;49;00m\n",
            "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
            "\n",
            "a = ('xro4634', <py4j.clientserver.JavaClient object at 0x7f09aa186a10>, 'o4629', 'select'), kw = {}\n",
            "converted = AnalysisException()\n",
            "\n",
            "    \u001b[94mdef\u001b[39;49;00m \u001b[92mdeco\u001b[39;49;00m(*a: Any, **kw: Any) -> Any:\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mreturn\u001b[39;49;00m f(*a, **kw)\u001b[90m\u001b[39;49;00m\n",
            "        \u001b[94mexcept\u001b[39;49;00m Py4JJavaError \u001b[94mas\u001b[39;49;00m e:\u001b[90m\u001b[39;49;00m\n",
            "            converted = convert_exception(e.java_exception)\u001b[90m\u001b[39;49;00m\n",
            "            \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(converted, UnknownException):\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[90m# Hide where the exception came from that shows a non-Pythonic\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "                \u001b[90m# JVM exception message.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            ">               \u001b[94mraise\u001b[39;49;00m converted \u001b[94mfrom\u001b[39;49;00m \u001b[96mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
            "\u001b[1m\u001b[31mE               pyspark.errors.exceptions.captured.AnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `moving_avg` cannot be resolved. Did you mean one of the following? [`carat`, `color`, `id`, `lprice`, `price`].;\u001b[0m\n",
            "\u001b[1m\u001b[31mE               'Project ['moving_avg, expected_price#3710]\u001b[0m\n",
            "\u001b[1m\u001b[31mE               +- Project [carat#3673, clarity#3674, color#3675, cut#3676, depth#3677, id#3678, price#3679L, table#3680L, x#3681, y#3682, z#3683, lprice#3695, 2460.0 AS expected_price#3710]\u001b[0m\n",
            "\u001b[1m\u001b[31mE                  +- Filter (id#3678 = DI-26-null-price)\u001b[0m\n",
            "\u001b[1m\u001b[31mE                     +- Project [carat#3673, clarity#3674, color#3675, cut#3676, depth#3677, id#3678, price#3679L, table#3680L, x#3681, y#3682, z#3683, ln(cast(price#3679L as double)) AS lprice#3695]\u001b[0m\n",
            "\u001b[1m\u001b[31mE                        +- Relation [carat#3673,clarity#3674,color#3675,cut#3676,depth#3677,id#3678,price#3679L,table#3680L,x#3681,y#3682,z#3683] json\u001b[0m\n",
            "\n",
            "\u001b[1m\u001b[31m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m:175: AnalysisException\n",
            "\u001b[36m\u001b[1m===================================== short test summary info ======================================\u001b[0m\n",
            "\u001b[31mFAILED\u001b[0m t_5f8a68b7935441de8636ef9c39afbe88.py::\u001b[1mtest_prep_for_linear_regression\u001b[0m - pyspark.errors.exceptions.captured.AnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A col...\n"
          ]
        }
      ]
    }
  ]
}